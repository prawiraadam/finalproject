{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "df = pd.read_csv('data\\data_test.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Dataset Distribution')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grafik kiri\n",
    "label = df['label'].value_counts().sort_index(ascending=True)\n",
    "label_pt = label.index\n",
    "label_freq = label.values\n",
    "\n",
    "# Grafik tengah\n",
    "ed_level = df['edu_level'].value_counts()\n",
    "edu_level_pt = ed_level.index\n",
    "edu_level_freq = ed_level.values\n",
    "\n",
    "# Grafik kanan\n",
    "subject = df['subject'].value_counts()\n",
    "subject_pt = subject.index\n",
    "subject_freq = subject.values\n",
    "\n",
    "# Subplot dibuat 1 baris, 3 kolom. figsize=(x, y)\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Grafik kiri\n",
    "axs[0].bar(label_pt, label_freq)\n",
    "axs[0].set_xlabel(\"Cognitive Level\")\n",
    "axs[0].set_ylabel(\"Num Of Questions\")\n",
    "\n",
    "# Grafik tengah\n",
    "axs[1].bar(edu_level_pt, edu_level_freq)\n",
    "axs[1].set_xlabel(\"Education Level\")\n",
    "axs[1].set_ylabel(\"Num Of Questions\")\n",
    "\n",
    "# Grafik kanan\n",
    "axs[2].bar(subject_pt, subject_freq)\n",
    "axs[2].set_xlabel(\"Subject\")\n",
    "axs[2].set_ylabel(\"Num Of Questions\")\n",
    "\n",
    "fig.suptitle('Dataset Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Coding\\Software\\Anaconda\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-15 11:18:48,024 loading file resources/taggers/example-upos/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "import re\n",
    "\n",
    "# Loading trained model hasil dari FlairNLP untuk POS Tagging\n",
    "postagger = SequenceTagger.load('resources/taggers/example-upos/best-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tag(series):\n",
    "    word_tag = []\n",
    "    for i in range(series.shape[0]):\n",
    "        text = Sentence(series[i])\n",
    "        postagger.predict(text)\n",
    "        \n",
    "        # hasil dari FlairNLP berbentuk [WORD, <TAG>]\n",
    "        # karakter kurung sudut dihilangkan\n",
    "        x = re.split(r\"\\>\\s|>\", text.to_tagged_string())\n",
    "        res = []\n",
    "        \n",
    "        # Untuk split biar dapet pasangan kata-tag\n",
    "        for i in range(len(x)):\n",
    "            temp = re.split(r\"\\s\", x[i])\n",
    "            if(len(temp) > 1):\n",
    "                for char in temp[1]:\n",
    "                    if char == '<':\n",
    "                        temp[1] = temp[1].replace('<', \"\")\n",
    "                res.append(temp)\n",
    "        word_tag.append(res)\n",
    "    \n",
    "    return word_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>subject</th>\n",
       "      <th>edu_level</th>\n",
       "      <th>tag_pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Udang ronggeng memiliki duri-duri yang keras, ...</td>\n",
       "      <td>Makna istilah kata vulkanis pada kutipan teks ...</td>\n",
       "      <td>C2</td>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>SMA</td>\n",
       "      <td>[[Makna, NOUN], [istilah, NOUN], [kata, NOUN],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saya pun membandingkan perlakuan yang ibu beri...</td>\n",
       "      <td>Latar suasana pada paragraf pertama dalam kuti...</td>\n",
       "      <td>C2</td>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>SMA</td>\n",
       "      <td>[[Latar, NOUN], [suasana, NOUN], [pada, ADP], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bapakku bernama Narto. Biasa dipanggil Kang Na...</td>\n",
       "      <td>Makna frasa cokelat legam pada kutipan cerpen ...</td>\n",
       "      <td>C2</td>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>SMA</td>\n",
       "      <td>[[Makna, NOUN], [frasa, NOUN], [cokelat, NOUN]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kebakaran hutan akibat kelalaian manusia di be...</td>\n",
       "      <td>Maksud pernyataan Evakuasi akan dilakukan kepa...</td>\n",
       "      <td>C2</td>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>SMA</td>\n",
       "      <td>[[Maksud, NOUN], [pernyataan, NOUN], [Evakuasi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hal yang disarankan Mat agar dilakukan istriny...</td>\n",
       "      <td>Nilai moral pada kutipan novel tersebut adalah ….</td>\n",
       "      <td>C2</td>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>SMA</td>\n",
       "      <td>[[Nilai, NOUN], [moral, NOUN], [pada, ADP], [k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Udang ronggeng memiliki duri-duri yang keras, ...   \n",
       "1  Saya pun membandingkan perlakuan yang ibu beri...   \n",
       "2  Bapakku bernama Narto. Biasa dipanggil Kang Na...   \n",
       "3  Kebakaran hutan akibat kelalaian manusia di be...   \n",
       "4  Hal yang disarankan Mat agar dilakukan istriny...   \n",
       "\n",
       "                                            question label           subject  \\\n",
       "0  Makna istilah kata vulkanis pada kutipan teks ...    C2  bahasa indonesia   \n",
       "1  Latar suasana pada paragraf pertama dalam kuti...    C2  bahasa indonesia   \n",
       "2  Makna frasa cokelat legam pada kutipan cerpen ...    C2  bahasa indonesia   \n",
       "3  Maksud pernyataan Evakuasi akan dilakukan kepa...    C2  bahasa indonesia   \n",
       "4  Nilai moral pada kutipan novel tersebut adalah ….    C2  bahasa indonesia   \n",
       "\n",
       "  edu_level                                           tag_pair  \n",
       "0       SMA  [[Makna, NOUN], [istilah, NOUN], [kata, NOUN],...  \n",
       "1       SMA  [[Latar, NOUN], [suasana, NOUN], [pada, ADP], ...  \n",
       "2       SMA  [[Makna, NOUN], [frasa, NOUN], [cokelat, NOUN]...  \n",
       "3       SMA  [[Maksud, NOUN], [pernyataan, NOUN], [Evakuasi...  \n",
       "4       SMA  [[Nilai, NOUN], [moral, NOUN], [pada, ADP], [k...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tag_pair'] = add_tag(df.question)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full(df, num):\n",
    "    for i in range(num):\n",
    "        print(df[i])\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casefolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['makna', 'NOUN'], ['istilah', 'NOUN'], ['kata', 'NOUN'], ['vulkanis', 'NOUN'], ['pada', 'ADP'], ['kutipan', 'NOUN'], ['teks', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX'], ['…', 'PUNCT'], ['.', 'PUNCT']]\n",
      "\n",
      "[['latar', 'NOUN'], ['suasana', 'NOUN'], ['pada', 'ADP'], ['paragraf', 'NOUN'], ['pertama', 'ADJ'], ['dalam', 'ADP'], ['kutipan', 'NOUN'], ['cerpen', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX'], ['…', 'PUNCT'], ['.', 'PUNCT']]\n",
      "\n",
      "[['makna', 'NOUN'], ['frasa', 'NOUN'], ['cokelat', 'NOUN'], ['legam', 'ADJ'], ['pada', 'ADP'], ['kutipan', 'NOUN'], ['cerpen', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX'], ['…', 'PUNCT'], ['.', 'PUNCT']]\n",
      "\n",
      "[['maksud', 'NOUN'], ['pernyataan', 'NOUN'], ['evakuasi', 'NOUN'], ['akan', 'AUX'], ['dilakukan', 'VERB'], ['kepada', 'ADP'], ['masyarakat', 'NOUN'], ['yang', 'PRON'], ['daerahnya', 'NOUN'], ['telah', 'AUX'], ['dipenuhi', 'VERB'], ['kabut', 'NOUN'], ['asap', 'NOUN'], ['akibat', 'ADP'], ['kebakaran', 'NOUN'], ['hutan', 'NOUN'], ['pada', 'ADP'], ['paragraf', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX'], ['…', 'PUNCT'], ['.', 'PUNCT']]\n",
      "\n",
      "[['nilai', 'NOUN'], ['moral', 'NOUN'], ['pada', 'ADP'], ['kutipan', 'NOUN'], ['novel', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX'], ['…', 'PUNCT'], ['.', 'PUNCT']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Casefolding from column 'question'\n",
    "# df.question = df.question.str.lower()\n",
    "\n",
    "# Mengubah semua huruf kapital menjadi huruf kecil dari kolom 'tag_pair'\n",
    "for i in range(df.tag_pair.shape[0]):\n",
    "    for j in range(len(df['tag_pair'][i])):\n",
    "        df['tag_pair'][i][j][0] = df['tag_pair'][i][j][0].lower()\n",
    "        \n",
    "print_full(df.tag_pair, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(series):\n",
    "    no_punct = []\n",
    "    for i in range(series.shape[0]):\n",
    "        holder = series[i]\n",
    "        temp = []\n",
    "        for j in range(len(holder)):\n",
    "        \n",
    "            # Mapping punctuations dari string ke ''\n",
    "            holder[j][0] = holder[j][0].translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "            # Hapus tag bertanda 'PUNCT'\n",
    "            # Dibuat list baru untuk nampung non-PUNCT\n",
    "            if len(holder[j][0]) > 0 and holder[j][1] != 'PUNCT':\n",
    "                temp.append(holder[j])\n",
    "        \n",
    "        no_punct.append(temp)\n",
    "    return no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tag_pair'] = remove_punctuation(df['tag_pair'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['makna', 'NOUN'], ['istilah', 'NOUN'], ['kata', 'NOUN'], ['vulkanis', 'NOUN'], ['pada', 'ADP'], ['kutipan', 'NOUN'], ['teks', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX']]\n",
      "\n",
      "[['latar', 'NOUN'], ['suasana', 'NOUN'], ['pada', 'ADP'], ['paragraf', 'NOUN'], ['pertama', 'ADJ'], ['dalam', 'ADP'], ['kutipan', 'NOUN'], ['cerpen', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX']]\n",
      "\n",
      "[['makna', 'NOUN'], ['frasa', 'NOUN'], ['cokelat', 'NOUN'], ['legam', 'ADJ'], ['pada', 'ADP'], ['kutipan', 'NOUN'], ['cerpen', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX']]\n",
      "\n",
      "[['maksud', 'NOUN'], ['pernyataan', 'NOUN'], ['evakuasi', 'NOUN'], ['akan', 'AUX'], ['dilakukan', 'VERB'], ['kepada', 'ADP'], ['masyarakat', 'NOUN'], ['yang', 'PRON'], ['daerahnya', 'NOUN'], ['telah', 'AUX'], ['dipenuhi', 'VERB'], ['kabut', 'NOUN'], ['asap', 'NOUN'], ['akibat', 'ADP'], ['kebakaran', 'NOUN'], ['hutan', 'NOUN'], ['pada', 'ADP'], ['paragraf', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX']]\n",
      "\n",
      "[['nilai', 'NOUN'], ['moral', 'NOUN'], ['pada', 'ADP'], ['kutipan', 'NOUN'], ['novel', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_full(df.tag_pair, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bikin copy isi dataframe\n",
    "# Work-around karena value setelah pake df.copy() suka berubah sendiri\n",
    "def reserve(df_col):\n",
    "    res = []\n",
    "    for index in df_col.index:\n",
    "        holder = df_col[index]\n",
    "        temp = []\n",
    "        for i in range(len(holder)):\n",
    "            temp_2 = []\n",
    "            temp_2.append(holder[i][0])\n",
    "            temp_2.append(holder[i][1])\n",
    "            temp.append(temp_2)\n",
    "        res.append(temp)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tambah 0 ke list reserve untuk keperluan weighting\n",
    "def add_zero(list_2d):\n",
    "    for i in range(len(list_2d)):\n",
    "        for j in range(len(list_2d[i])):\n",
    "            list_2d[i][j].append(0)\n",
    "    return list_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_freq(corpus):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    features = vectorizer.get_feature_names_out()\n",
    "    features_with_0 = []\n",
    "    \n",
    "    for i in range(len(features)):\n",
    "        temp = []\n",
    "        temp.append(features[i])\n",
    "        temp.append(0)\n",
    "        features_with_0.append(temp)\n",
    "\n",
    "    wordfreq = X.toarray()\n",
    "    for i in range(len(wordfreq)):\n",
    "        for j in range(len(wordfreq[i])):\n",
    "            if wordfreq[i][j] != 0:\n",
    "                features_with_0[j][1] += wordfreq[i][j]\n",
    "    \n",
    "    return features_with_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(series, stopwords):\n",
    "    res = []\n",
    "    for i in range(series.shape[0]):\n",
    "        temp = []\n",
    "        holder = series[i]\n",
    "        for j in range(len(holder)):\n",
    "            if holder[j][0] in stopwords:\n",
    "                holder[j][0] = ''\n",
    "            if len(holder[j][0]) != 0:\n",
    "                temp.append(holder[j])\n",
    "        res.append(temp)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_factory = StopWordRemoverFactory()\n",
    "stopword = stopword_factory.create_stop_word_remover()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_default = stopword_factory.get_stop_words()\n",
    "\n",
    "sw_keep = ['adalah', 'apa', 'arti', 'artinya', 'berapa', 'berapakah', 'beri', \n",
    "           'berikan', 'diantaranya', 'disebut', 'jelaskan', 'karena',  \n",
    "           'mengapa', 'menunjukkan', 'merupakan', 'rupa', 'sebut']\n",
    "\n",
    "# List Comprehension buat exclude stopwords di sw_keep dari sw\n",
    "sw_modify = [x for x in sw_default if x not in sw_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplikat kolom tag_pair\n",
    "reserve_pair = reserve(df['tag_pair'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['makna', 'NOUN'], ['istilah', 'NOUN'], ['kata', 'NOUN'], ['vulkanis', 'NOUN'], ['pada', 'ADP'], ['kutipan', 'NOUN'], ['teks', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX']]\n"
     ]
    }
   ],
   "source": [
    "# tag_pair di-assign reserve soalnya habis buang stopword jadi rusak\n",
    "df['tag_pair_def'] = remove_stopword(df['tag_pair'], sw_default)\n",
    "df['tag_pair'] = reserve_pair\n",
    "print(df['tag_pair'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hapus stopwords dari tag_pair_mod\n",
    "df['tag_pair_mod'] = remove_stopword(df['tag_pair'], sw_modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['makna', 'NOUN'],\n",
       " ['istilah', 'NOUN'],\n",
       " ['vulkanis', 'NOUN'],\n",
       " ['kutipan', 'NOUN'],\n",
       " ['teks', 'NOUN']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tag_pair_def'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['makna', 'NOUN'],\n",
       " ['istilah', 'NOUN'],\n",
       " ['vulkanis', 'NOUN'],\n",
       " ['kutipan', 'NOUN'],\n",
       " ['teks', 'NOUN'],\n",
       " ['adalah', 'AUX']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tag_pair_mod'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# Mengubah kata ke bentuk dasarnya\n",
    "# Stemming setelah POSTagging karena sequence kata berguna dalam POSTagging\n",
    "def stem(series):\n",
    "    for i in range(series.shape[0]):\n",
    "        holder = series[i]\n",
    "        for j in range(len(holder)):\n",
    "            holder[j][0] = stemmer.stem(holder[j][0])\n",
    "    \n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_factory = StemmerFactory()\n",
    "stemmer = stem_factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['makna', 'NOUN'],\n",
       " ['istilah', 'NOUN'],\n",
       " ['vulkanis', 'NOUN'],\n",
       " ['kutip', 'NOUN'],\n",
       " ['teks', 'NOUN']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tag_pair_def = stem(df.tag_pair_def)\n",
    "df.tag_pair_def[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['makna', 'NOUN'],\n",
       " ['istilah', 'NOUN'],\n",
       " ['vulkanis', 'NOUN'],\n",
       " ['kutip', 'NOUN'],\n",
       " ['teks', 'NOUN'],\n",
       " ['adalah', 'AUX']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tag_pair_mod = stem(df.tag_pair_mod)\n",
    "df.tag_pair_mod[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "for TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_corpus(series):\n",
    "    corpus = []\n",
    "    for i in range(series.shape[0]):\n",
    "        holder = series[i]\n",
    "        temp = []\n",
    "        for j in range(len(holder)):\n",
    "            temp.append(holder[j][0])\n",
    "        corpus.append(' '.join(temp))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bikin corpus dari tag_pair_def & tag_pair_mod\n",
    "corpus_def = to_corpus(df.tag_pair_def)\n",
    "corpus_mod = to_corpus(df.tag_pair_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'makna istilah vulkanis kutip teks'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_def[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from itertools import chain\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(term_doc_matrix):\n",
    "    # Convert sparse matrix to list\n",
    "    temp = []\n",
    "    for i in range(term_doc_matrix.shape[0]):\n",
    "        holder = term_doc_matrix[i].toarray().tolist()\n",
    "        temp.append(holder[0])\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Buat ngitung nilai TF-IDF dari tiap term\n",
    "term_doc_matrix_def = vectorizer.fit_transform(corpus_def)\n",
    "# vocabulary_def = vectorizer.get_feature_names()\n",
    "\n",
    "term_doc_matrix_mod = vectorizer.fit_transform(corpus_mod)\n",
    "# vocabulary_mod = vectorizer.get_feature_names()\n",
    "\n",
    "# Convert hasil fit_transform dari sparse matrix ke list\n",
    "tfidf_def = flatten(term_doc_matrix_def)\n",
    "tfidf_mod = flatten(term_doc_matrix_mod)\n",
    "\n",
    "# Diubah ke dataframe untuk training & testing model\n",
    "df_tfidf_def = pd.DataFrame(tfidf_def)\n",
    "df_tfidf_mod = pd.DataFrame(tfidf_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576  0.5220918026519731\n",
      "723  0.34983840731204346\n",
      "792  0.465779484261717\n",
      "1219  0.28288115601620895\n",
      "1307  0.5550323972389433\n"
     ]
    }
   ],
   "source": [
    "a = tfidf_def[0]\n",
    "for i in range(len(a)):\n",
    "    if a[i] != 0:\n",
    "        print(str(i) + \"  \" + str(a[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "For TFPOS-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def termdoc_weighting(termdoc, features, tag_pair):\n",
    "    result = []\n",
    "    for i in range(len(termdoc)):\n",
    "        holder = termdoc[i]\n",
    "        holder_pair = tag_pair[i]\n",
    "        temp = []\n",
    "        for j in range(len(holder)):\n",
    "            if holder[j] != 0:\n",
    "                term = features[j]\n",
    "                weight = 1\n",
    "                for k in range(len(holder_pair)):\n",
    "                    if holder_pair[k][0] == term:\n",
    "                        if holder_pair[k][1] == 'VERB':\n",
    "                            weight = 5\n",
    "                        elif holder_pair[k][1] == 'ADJ' or holder_pair[k][1] == 'NOUN':\n",
    "                            weight = 3\n",
    "                        else:\n",
    "                            weight = 1\n",
    "                temp.append(holder[j] * weight)\n",
    "            else:\n",
    "                temp.append(holder[j])\n",
    "        result.append(temp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tfidf(termdoc_weighted, features, df):\n",
    "    result = []\n",
    "    for i in range(len(termdoc_weighted)):\n",
    "        holder = termdoc_weighted[i]\n",
    "        temp = []\n",
    "        denom = sum(termdoc_weighted[i])\n",
    "        for j in range(len(holder)):\n",
    "            if holder[j] != 0:\n",
    "                term = features[j]\n",
    "                idf = df.loc[df['word'] == term].idf\n",
    "                temp.append((holder[j]/denom) * (float(idf)))\n",
    "            else:\n",
    "                temp.append(holder[j])\n",
    "        result.append(temp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Coding\\Software\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Ambil nilai IDF tiap kata dari corpus\n",
    "term_doc_matrix_def = vectorizer.fit_transform(corpus_def)\n",
    "df_idf_def = pd.DataFrame(vectorizer.idf_, columns=['idf'])\n",
    "df_idf_def['word'] = vectorizer.get_feature_names()\n",
    "\n",
    "# Ambil nilai IDF tiap kata dari corpus\n",
    "term_doc_matrix_mod = vectorizer.fit_transform(corpus_mod)\n",
    "df_idf_mod = pd.DataFrame(vectorizer.idf_, columns=['idf'])\n",
    "df_idf_mod['word'] = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "# Bikin term-document matrix\n",
    "X_def = cv.fit_transform(corpus_def)\n",
    "features_def = cv.get_feature_names_out()\n",
    "termdoc_def = X_def.toarray()\n",
    "\n",
    "# Bikin term-document matrix\n",
    "X_mod = cv.fit_transform(corpus_mod)\n",
    "features_mod = cv.get_feature_names_out()\n",
    "termdoc_mod = X_mod.toarray()\n",
    "\n",
    "# dari term document dikali weightnya masing-masing\n",
    "termdoc_weighted_def = termdoc_weighting(termdoc_def, features_def, df.tag_pair_def)\n",
    "termdoc_weighted_mod = termdoc_weighting(termdoc_mod, features_mod, df.tag_pair_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFPOS-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFPOS-IDF\n",
    "ctfidf_def = count_tfidf(termdoc_weighted_def, features_def, df_idf_def)\n",
    "ctfidf_mod = count_tfidf(termdoc_weighted_mod, features_mod, df_idf_mod)\n",
    "\n",
    "# Normalisasi pake L2-Norm\n",
    "tfposidf_def = preprocessing.normalize(ctfidf_def, norm='l2').tolist()\n",
    "tfposidf_mod = preprocessing.normalize(ctfidf_mod, norm='l2').tolist()\n",
    "\n",
    "# Ubah list ke bentuk dataframe untuk training & testing\n",
    "df_tfposidf_def = pd.DataFrame(tfposidf_def)\n",
    "df_tfposidf_mod = pd.DataFrame(tfposidf_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['teladan', 'NOUN'], ['tokoh', 'NOUN'], ['dasar', 'ADP'], ['kutip', 'NOUN']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Untuk contoh hasil\n",
    "df.tag_pair_def[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 382)\t0.40174814472318027\n",
      "  (0, 1252)\t0.520511110095638\n",
      "  (0, 1220)\t0.6373892379778402\n",
      "  (0, 723)\t0.40174814472318027\n"
     ]
    }
   ],
   "source": [
    "# Kalo hasil dari tfidfvectorizer, urutan yg ditampilin sesuai sama urutan kata di dokumen (head--tail)\n",
    "print(term_doc_matrix_def[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 723)\t1\n",
      "  (0, 1220)\t1\n",
      "  (0, 1252)\t1\n",
      "  (0, 382)\t1\n"
     ]
    }
   ],
   "source": [
    "# Hasil countvectorizer, urutannya jadi kebalik dari kata di dokumen (tail--head)\n",
    "print(X_def[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382  1\n",
      "723  1\n",
      "1220  1\n",
      "1252  1\n"
     ]
    }
   ],
   "source": [
    "# Kalo countvectorizer dibikin toarray(), urutannya jadi alphabetical ngikutin method get_feature_names_out()\n",
    "a = termdoc_def[5]\n",
    "for i in range(len(a)):\n",
    "    if a[i] != 0:\n",
    "        print(str(i) + \"  \" + str(a[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382  0.40174814472318027\n",
      "723  0.40174814472318027\n",
      "1220  0.6373892379778402\n",
      "1252  0.520511110095638\n"
     ]
    }
   ],
   "source": [
    "# Kalo tfidfvectorizer di-apply flatten(), urutannya jadi alphabetical ngikutin method get_feature_names_out()\n",
    "a = tfidf_def[5]\n",
    "for i in range(len(a)):\n",
    "    if a[i] != 0:\n",
    "        print(str(i) + \"  \" + str(a[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382  0.43061538329752613\n",
      "723  1.2918461498925784\n",
      "1220  2.049564743185055\n",
      "1252  1.6737358526364445\n"
     ]
    }
   ],
   "source": [
    "# Hasil count_tfidf() sebelum normalisasi L2\n",
    "a = ctfidf_def[5]\n",
    "for i in range(len(a)):\n",
    "    if a[i] != 0:\n",
    "        print(str(i) + \"  \" + str(a[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382  0.1446974390994958\n",
      "723  0.4340923172984874\n",
      "1220  0.6887045403173292\n",
      "1252  0.5624167203477981\n"
     ]
    }
   ],
   "source": [
    "# Hasil TFPOS-IDF setelah normalisasi L2\n",
    "a = tfposidf_def[5]\n",
    "for i in range(len(a)):\n",
    "    if a[i] != 0:\n",
    "        print(str(i) + \"  \" + str(a[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Not majority karena cuma C3 yang banyak sendiri datanya\n",
    "ros = RandomOverSampler(sampling_strategy = 'not majority', random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling dari TF-IDF Reguler\n",
    "X_def, y_def = ros.fit_resample(tfidf_def, df['label'])\n",
    "X_mod, y_mod = ros.fit_resample(tfidf_mod, df['label'])\n",
    "\n",
    "df_tfidf_ros_def = pd.DataFrame(X_def)\n",
    "tfidf_ros_label_def = pd.DataFrame(y_def)\n",
    "df_tfidf_ros_mod = pd.DataFrame(X_mod)\n",
    "tfidf_ros_label_mod = pd.DataFrame(y_mod)\n",
    "\n",
    "# Resampling dari TFPOS-IDF\n",
    "X_def, y_def = ros.fit_resample(tfposidf_def, df['label'])\n",
    "X_mod, y_mod = ros.fit_resample(tfposidf_mod, df['label'])\n",
    "\n",
    "df_tfposidf_ros_def = pd.DataFrame(X_def)\n",
    "ros_tfposidf_label_def = pd.DataFrame(y_def)\n",
    "df_tfposidf_ros_mod = pd.DataFrame(X_mod)\n",
    "ros_tfposidf_label_mod = pd.DataFrame(y_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "C6       248\n",
       "C5       248\n",
       "C4       248\n",
       "C3       248\n",
       "C2       248\n",
       "C1       248\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_ros_label_def.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C3    248\n",
       "C2    134\n",
       "C1    130\n",
       "C4    113\n",
       "C5     37\n",
       "C6     19\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skenario pengujian\n",
    "1. TFIDF reguler, stopword PySastrawi ==> use df_tfidf_def\n",
    "2. TFIDF reguler, stopword modifikasi PySastrawi ==> use df_tfidf_mod\n",
    "3. TFIDF reguler, stopword PySastrawi, random over-sampling ==> df_tfidf_ros_def\n",
    "4. TFIDF reguler, stopword modifikasi PySastrawi, random over-sampling ==> df_tfidf_ros_mod\n",
    "5. TFPOS-IDF, stopword PySastrawi ==> use df_tfposidf_def\n",
    "6. TFPOS-IDF, stopword modifikasi PySastrawi ==> df_tfposidf_mod\n",
    "7. TFPOS-IDF, stopword PySastrawi, random over-sampling ==> df_tfposidf_ros_def\n",
    "8. TFPOS-IDF, stopword modifikasi PySastrawi, random over-sampling ==> df_tfposidf_ros_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(test, pred):\n",
    "    accuracy = metrics.accuracy_score(test, pred)\n",
    "    precision = metrics.precision_score(test, pred, average='weighted')\n",
    "    recall = metrics.recall_score(test, pred, average='weighted')\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 1 - SVM\n",
    "TFIDF reguler, stopword PySastrawi ==> use df_tfidf_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.453\n",
      "Precision:  0.407\n",
      "Recall:  0.453\n",
      "F1 Score:  0.429\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "SVC(C=1000, gamma=0.001)\n"
     ]
    }
   ],
   "source": [
    "X_train_svm1, X_test_svm1, y_train_svm1, y_test_svm1 = train_test_split(df_tfidf_def, \n",
    "                                                                        df['label'], \n",
    "                                                                        test_size=0.2, \n",
    "                                                                        random_state=23)\n",
    "clf_svm = svm.SVC(C=1, kernel='linear')\n",
    "clf_svm.fit(X_train_svm1, y_train_svm1)\n",
    "pred_svm_1 = clf_svm.predict(X_test_svm1)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm1, pred_svm_1)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "svm_grid_param = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001, 'auto'], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_svm = GridSearchCV(clf_svm, svm_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_svm.fit(X_train_svm1, y_train_svm1)\n",
    "\n",
    "print(gs_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.445\n",
      "Precision:  0.431\n",
      "Recall:  0.445\n",
      "F1 Score:  0.438\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(C=1000, gamma = 0.001)\n",
    "clf_svm.fit(X_train_svm1, y_train_svm1)\n",
    "pred_svm_1 = clf_svm.predict(X_test_svm1)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm1, pred_svm_1)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 1 - NB\n",
    "TFIDF reguler, stopword PySastrawi ==> use df_tfidf_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.423\n",
      "Precision:  0.419\n",
      "Recall:  0.423\n",
      "F1 Score:  0.421\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "MultinomialNB(alpha=0.3)\n"
     ]
    }
   ],
   "source": [
    "X_train_nb1, X_test_nb1, y_train_nb1, y_test_nb1 = train_test_split(df_tfidf_def, \n",
    "                                                                    df['label'], \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=23)\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train_nb1, y_train_nb1)\n",
    "pred_nb_1 = clf_nb.predict(X_test_nb1)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb1, pred_nb_1)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "nb_grid_param = [ {'alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "                  {'fit_prior' : [True, False]} ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_nb = GridSearchCV(clf_nb, nb_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_nb.fit(X_train_nb1, y_train_nb1)\n",
    "\n",
    "print(gs_nb.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.445\n",
      "Precision:  0.423\n",
      "Recall:  0.445\n",
      "F1 Score:  0.434\n"
     ]
    }
   ],
   "source": [
    "clf_nb = MultinomialNB(alpha=0.3)\n",
    "clf_nb.fit(X_train_nb1, y_train_nb1)\n",
    "pred_nb_1 = clf_nb.predict(X_test_nb1)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb1, pred_nb_1)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 2 - SVM\n",
    "TFIDF reguler, stopword modifikasi PySastrawi ==> use df_tfidf_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.474\n",
      "Precision:  0.432\n",
      "Recall:  0.474\n",
      "F1 Score:  0.452\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "SVC(C=100, gamma=0.01)\n"
     ]
    }
   ],
   "source": [
    "X_train_svm2, X_test_svm2, y_train_svm2, y_test_svm2 = train_test_split(df_tfidf_mod, \n",
    "                                                                        df['label'], \n",
    "                                                                        test_size=0.2, \n",
    "                                                                        random_state=23)\n",
    "\n",
    "clf_svm = svm.SVC(C=1, kernel='linear')\n",
    "clf_svm.fit(X_train_svm2, y_train_svm2)\n",
    "pred_svm_2 = clf_svm.predict(X_test_svm2)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm2, pred_svm_2)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "svm_grid_param = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001, 'auto'], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_svm = GridSearchCV(clf_svm, svm_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_svm.fit(X_train_svm2, y_train_svm2)\n",
    "\n",
    "print(gs_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.438\n",
      "Precision:  0.43\n",
      "Recall:  0.438\n",
      "F1 Score:  0.434\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(C=100, gamma = 0.01)\n",
    "clf_svm.fit(X_train_svm2, y_train_svm2)\n",
    "pred_svm_2 = clf_svm.predict(X_test_svm2)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm2, pred_svm_2)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 2 - NB\n",
    "TFIDF reguler, stopword modifikasi PySastrawi ==> use df_tfidf_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.401\n",
      "Precision:  0.443\n",
      "Recall:  0.401\n",
      "F1 Score:  0.421\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "MultinomialNB(alpha=0.1)\n"
     ]
    }
   ],
   "source": [
    "X_train_nb2, X_test_nb2, y_train_nb2, y_test_nb2 = train_test_split(df_tfidf_mod, \n",
    "                                                                    df['label'], \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=23)\n",
    "\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train_nb2, y_train_nb2)\n",
    "pred_nb_2 = clf_nb.predict(X_test_nb2)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb2, pred_nb_2)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "nb_grid_param = [ {'alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "                  {'fit_prior' : [True, False]} ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_nb = GridSearchCV(clf_nb, nb_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_nb.fit(X_train_nb2, y_train_nb2)\n",
    "\n",
    "print(gs_nb.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.467\n",
      "Precision:  0.491\n",
      "Recall:  0.467\n",
      "F1 Score:  0.479\n"
     ]
    }
   ],
   "source": [
    "clf_nb = MultinomialNB(alpha=0.1)\n",
    "clf_nb.fit(X_train_nb2, y_train_nb2)\n",
    "pred_nb_2 = clf_nb.predict(X_test_nb2)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb2, pred_nb_2)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 3 - SVM\n",
    "TFIDF reguler, stopword PySastrawi, random over-sampling  ==> df_tfidf_ros_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.799\n",
      "Precision:  0.797\n",
      "Recall:  0.799\n",
      "F1 Score:  0.798\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "SVC(C=10, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "X_train_svm3, X_test_svm3, y_train_svm3, y_test_svm3 = train_test_split(df_tfidf_ros_def, \n",
    "                                                                        tfidf_ros_label_def, \n",
    "                                                                        test_size=0.2, \n",
    "                                                                        random_state=23)\n",
    "clf_svm = svm.SVC(C=1, kernel='linear')\n",
    "clf_svm.fit(X_train_svm3, y_train_svm3)\n",
    "pred_svm_3 = clf_svm.predict(X_test_svm3)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm3, pred_svm_3)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "svm_grid_param = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001, 'auto'], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_svm = GridSearchCV(clf_svm, svm_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_svm.fit(X_train_svm3, y_train_svm3)\n",
    "\n",
    "print(gs_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.839\n",
      "Precision:  0.836\n",
      "Recall:  0.839\n",
      "F1 Score:  0.837\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(C=10, kernel='linear')\n",
    "clf_svm.fit(X_train_svm3, y_train_svm3)\n",
    "pred_svm_3 = clf_svm.predict(X_test_svm3)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm3, pred_svm_3)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 3 - NB\n",
    "TFIDF reguler, stopword PySastrawi, random over-sampling  ==> df_tfidf_ros_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.772\n",
      "Precision:  0.773\n",
      "Recall:  0.772\n",
      "F1 Score:  0.772\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "MultinomialNB(alpha=0.0)\n"
     ]
    }
   ],
   "source": [
    "X_train_nb3, X_test_nb3, y_train_nb3, y_test_nb3 = train_test_split(df_tfidf_ros_def, \n",
    "                                                                    tfidf_ros_label_def, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=23)\n",
    "\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train_nb3, y_train_nb3)\n",
    "pred_nb_3 = clf_nb.predict(X_test_nb3)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb3, pred_nb_3)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "nb_grid_param = [ {'alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "                  {'fit_prior' : [True, False]} ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_nb = GridSearchCV(clf_nb, nb_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_nb.fit(X_train_nb3, y_train_nb3)\n",
    "\n",
    "print(gs_nb.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.815\n",
      "Precision:  0.815\n",
      "Recall:  0.815\n",
      "F1 Score:  0.815\n"
     ]
    }
   ],
   "source": [
    "clf_nb = MultinomialNB(alpha=0.0)\n",
    "clf_nb.fit(X_train_nb3, y_train_nb3)\n",
    "pred_nb_3 = clf_nb.predict(X_test_nb3)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb3, pred_nb_3)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 4 - SVM\n",
    "TFIDF reguler, stopword modifikasi PySastrawi, random over-sampling  ==> df_tfidf_ros_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.819\n",
      "Precision:  0.817\n",
      "Recall:  0.819\n",
      "F1 Score:  0.818\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "SVC(C=10, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "X_train_svm4, X_test_svm4, y_train_svm4, y_test_svm4 = train_test_split(df_tfidf_ros_mod, \n",
    "                                                                        tfidf_ros_label_mod, \n",
    "                                                                        test_size=0.2, \n",
    "                                                                        random_state=23)\n",
    "\n",
    "clf_svm = svm.SVC(C=1, kernel='linear')\n",
    "clf_svm.fit(X_train_svm4, y_train_svm4)\n",
    "pred_svm_4 = clf_svm.predict(X_test_svm4)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm4, pred_svm_4)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "svm_grid_param = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001, 'auto'], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_svm = GridSearchCV(clf_svm, svm_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_svm.fit(X_train_svm4, y_train_svm4)\n",
    "\n",
    "print(gs_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.842\n",
      "Precision:  0.841\n",
      "Recall:  0.842\n",
      "F1 Score:  0.842\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(C=10, kernel='linear')\n",
    "clf_svm.fit(X_train_svm4, y_train_svm4)\n",
    "pred_svm_4 = clf_svm.predict(X_test_svm4)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm4, pred_svm_4)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 4 - NB\n",
    "TFIDF reguler, stopword modifikasi PySastrawi, random over-sampling  ==> df_tfidf_ros_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.782\n",
      "Precision:  0.78\n",
      "Recall:  0.782\n",
      "F1 Score:  0.781\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "MultinomialNB(alpha=0.0)\n"
     ]
    }
   ],
   "source": [
    "X_train_nb4, X_test_nb4, y_train_nb4, y_test_nb4 = train_test_split(df_tfidf_ros_mod, \n",
    "                                                                    tfidf_ros_label_mod, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=23)\n",
    "\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train_nb4, y_train_nb4)\n",
    "pred_nb_4 = clf_nb.predict(X_test_nb4)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb4, pred_nb_4)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "nb_grid_param = [ {'alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "                  {'fit_prior' : [True, False]} ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_nb = GridSearchCV(clf_nb, nb_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_nb.fit(X_train_nb4, y_train_nb4)\n",
    "\n",
    "print(gs_nb.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.829\n",
      "Precision:  0.828\n",
      "Recall:  0.829\n",
      "F1 Score:  0.829\n"
     ]
    }
   ],
   "source": [
    "clf_nb = MultinomialNB(alpha=0.0)\n",
    "clf_nb.fit(X_train_nb4, y_train_nb4)\n",
    "pred_nb_4 = clf_nb.predict(X_test_nb4)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb4, pred_nb_4)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 5 - SVM\n",
    "TFPOS-IDF, stopword PySastrawi ==> use df_tfposidf_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.438\n",
      "Precision:  0.423\n",
      "Recall:  0.438\n",
      "F1 Score:  0.43\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "SVC(C=1, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "X_train_svm5, X_test_svm5, y_train_svm5, y_test_svm5 = train_test_split(df_tfposidf_def, \n",
    "                                                                        df['label'], \n",
    "                                                                        test_size=0.2, \n",
    "                                                                        random_state=23)\n",
    "\n",
    "clf_svm = svm.SVC(C=1, kernel='linear')\n",
    "clf_svm.fit(X_train_svm5, y_train_svm5)\n",
    "pred_svm_5 = clf_svm.predict(X_test_svm5)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm5, pred_svm_5)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "svm_grid_param = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001, 'auto'], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_svm = GridSearchCV(clf_svm, svm_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_svm.fit(X_train_svm5, y_train_svm5)\n",
    "\n",
    "print(gs_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.438\n",
      "Precision:  0.423\n",
      "Recall:  0.438\n",
      "F1 Score:  0.43\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(C=1, kernel='linear')\n",
    "clf_svm.fit(X_train_svm5, y_train_svm5)\n",
    "pred_svm_5 = clf_svm.predict(X_test_svm5)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm5, pred_svm_5)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 5 - NB\n",
    "TFPOS-IDF, stopword PySastrawi ==> use df_tfposidf_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.431\n",
      "Precision:  0.5\n",
      "Recall:  0.431\n",
      "F1 Score:  0.463\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "MultinomialNB(alpha=0.2)\n"
     ]
    }
   ],
   "source": [
    "X_train_nb5, X_test_nb5, y_train_nb5, y_test_nb5 = train_test_split(df_tfposidf_def,\n",
    "                                                                    df['label'], \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=23)\n",
    "\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train_nb5, y_train_nb5)\n",
    "pred_nb_5 = clf_nb.predict(X_test_nb5)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb5, pred_nb_5)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "nb_grid_param = [ {'alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "                  {'fit_prior' : [True, False]} ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_nb = GridSearchCV(clf_nb, nb_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_nb.fit(X_train_nb5, y_train_nb5)\n",
    "\n",
    "print(gs_nb.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.453\n",
      "Precision:  0.448\n",
      "Recall:  0.453\n",
      "F1 Score:  0.45\n"
     ]
    }
   ],
   "source": [
    "clf_nb = MultinomialNB(alpha=0.2)\n",
    "clf_nb.fit(X_train_nb5, y_train_nb5)\n",
    "pred_nb_5 = clf_nb.predict(X_test_nb5)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb5, pred_nb_5)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 6 - SVM\n",
    "TFPOS-IDF, stopword modifikasi PySastrawi ==> df_tfposidf_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.445\n",
      "Precision:  0.417\n",
      "Recall:  0.445\n",
      "F1 Score:  0.431\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "SVC(C=1000, gamma='auto')\n"
     ]
    }
   ],
   "source": [
    "X_train_svm6, X_test_svm6, y_train_svm6, y_test_svm6 = train_test_split(df_tfposidf_mod, \n",
    "                                                                        df['label'], \n",
    "                                                                        test_size=0.2, \n",
    "                                                                        random_state=23)\n",
    "\n",
    "clf_svm = svm.SVC(C=1, kernel='linear')\n",
    "clf_svm.fit(X_train_svm6, y_train_svm6)\n",
    "pred_svm6 = clf_svm.predict(X_test_svm6)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm6, pred_svm6)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "svm_grid_param = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001, 'auto'], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_svm = GridSearchCV(clf_svm, svm_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_svm.fit(X_train_svm6, y_train_svm6)\n",
    "\n",
    "print(gs_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.504\n",
      "Precision:  0.478\n",
      "Recall:  0.504\n",
      "F1 Score:  0.491\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(C=1000, gamma='auto')\n",
    "clf_svm.fit(X_train_svm6, y_train_svm6)\n",
    "pred_svm6 = clf_svm.predict(X_test_svm6)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm6, pred_svm6)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 6 - NB\n",
    "TFPOS-IDF, stopword modifikasi PySastrawi ==> df_tfposidf_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.401\n",
      "Precision:  0.463\n",
      "Recall:  0.401\n",
      "F1 Score:  0.43\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "MultinomialNB(alpha=0.1)\n"
     ]
    }
   ],
   "source": [
    "X_train_nb6, X_test_nb6, y_train_nb6, y_test_nb6 = train_test_split(df_tfposidf_mod, \n",
    "                                                                    df['label'], \n",
    "                                                                    test_size=0.2,\n",
    "                                                                    random_state=23)\n",
    "\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train_nb6, y_train_nb6)\n",
    "pred_nb6 = clf_nb.predict(X_test_nb6)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb6, pred_nb6)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "nb_grid_param = [ {'alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "                  {'fit_prior' : [True, False]} ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_nb = GridSearchCV(clf_nb, nb_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_nb.fit(X_train_nb6, y_train_nb6)\n",
    "\n",
    "print(gs_nb.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.467\n",
      "Precision:  0.477\n",
      "Recall:  0.467\n",
      "F1 Score:  0.472\n"
     ]
    }
   ],
   "source": [
    "clf_nb = MultinomialNB(alpha=0.1)\n",
    "clf_nb.fit(X_train_nb6, y_train_nb6)\n",
    "pred_nb6 = clf_nb.predict(X_test_nb6)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb6, pred_nb6)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 7 - SVM\n",
    "TFPOS-IDF, stopword PySastrawi, random over-sampling ==> df_tfposidf_ros_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.815\n",
      "Precision:  0.813\n",
      "Recall:  0.815\n",
      "F1 Score:  0.814\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "SVC(C=10, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "X_train_svm7, X_test_svm7, y_train_svm7, y_test_svm7 = train_test_split(df_tfposidf_ros_def, \n",
    "                                                                        ros_tfposidf_label_def, \n",
    "                                                                        test_size=0.2, \n",
    "                                                                        random_state=23)\n",
    "\n",
    "clf_svm = svm.SVC(C=1, kernel='linear')\n",
    "clf_svm.fit(X_train_svm7, y_train_svm7)\n",
    "pred_svm_7 = clf_svm.predict(X_test_svm7)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm7, pred_svm_7)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "svm_grid_param = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001, 'auto'], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_svm = GridSearchCV(clf_svm, svm_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_svm.fit(X_train_svm7, y_train_svm7)\n",
    "\n",
    "print(gs_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.836\n",
      "Precision:  0.836\n",
      "Recall:  0.836\n",
      "F1 Score:  0.836\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(C=10, kernel='linear')\n",
    "clf_svm.fit(X_train_svm7, y_train_svm7)\n",
    "pred_svm_7 = clf_svm.predict(X_test_svm7)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm7, pred_svm_7)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 7 - NB\n",
    "TFPOS-IDF, stopword PySastrawi, random over-sampling ==> df_tfposidf_ros_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.735\n",
      "Precision:  0.73\n",
      "Recall:  0.735\n",
      "F1 Score:  0.732\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "MultinomialNB(alpha=0.0)\n"
     ]
    }
   ],
   "source": [
    "X_train_nb7, X_test_nb7, y_train_nb7, y_test_nb7 = train_test_split(df_tfposidf_ros_def, \n",
    "                                                                    ros_tfposidf_label_def, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=23)\n",
    "\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train_nb7, y_train_nb7)\n",
    "pred_nb7 = clf_nb.predict(X_test_nb7)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb7, pred_nb7)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "nb_grid_param = [ {'alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "                  {'fit_prior' : [True, False]} ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_nb = GridSearchCV(clf_nb, nb_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_nb.fit(X_train_nb7, y_train_nb7)\n",
    "\n",
    "print(gs_nb.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.795\n",
      "Precision:  0.79\n",
      "Recall:  0.795\n",
      "F1 Score:  0.793\n"
     ]
    }
   ],
   "source": [
    "clf_nb = MultinomialNB(alpha=0.0)\n",
    "clf_nb.fit(X_train_nb7, y_train_nb7)\n",
    "pred_nb7 = clf_nb.predict(X_test_nb7)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb7, pred_nb7)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 8 - SVM\n",
    "TFPOS-IDF, stopword modifikasi PySastrawi, random over-sampling ==> df_tfposidf_ros_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.826\n",
      "Precision:  0.824\n",
      "Recall:  0.826\n",
      "F1 Score:  0.825\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "SVC(C=10, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "X_train_svm8, X_test_svm8, y_train_svm8, y_test_svm8 = train_test_split(df_tfposidf_ros_mod, \n",
    "                                                                        ros_tfposidf_label_mod, \n",
    "                                                                        test_size=0.2, \n",
    "                                                                        random_state=23)\n",
    "\n",
    "clf_svm = svm.SVC(C=1, kernel='linear')\n",
    "clf_svm.fit(X_train_svm8, y_train_svm8)\n",
    "pred_svm8 = clf_svm.predict(X_test_svm8)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm8, pred_svm8)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "svm_grid_param = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001, 'auto'], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_svm = GridSearchCV(clf_svm, svm_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_svm.fit(X_train_svm8, y_train_svm8)\n",
    "\n",
    "print(gs_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.846\n",
      "Precision:  0.846\n",
      "Recall:  0.846\n",
      "F1 Score:  0.846\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(C=10, kernel='linear')\n",
    "clf_svm.fit(X_train_svm8, y_train_svm8)\n",
    "pred_svm8 = clf_svm.predict(X_test_svm8)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm8, pred_svm8)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 8 - NB\n",
    "TFPOS-IDF, stopword modifikasi PySastrawi, random over-sampling ==> df_tfposidf_ros_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.752\n",
      "Precision:  0.744\n",
      "Recall:  0.752\n",
      "F1 Score:  0.748\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "MultinomialNB(alpha=0.0)\n"
     ]
    }
   ],
   "source": [
    "X_train_nb8, X_test_nb8, y_train_nb8, y_test_nb8 = train_test_split(df_tfposidf_ros_mod, \n",
    "                                                                    ros_tfposidf_label_mod, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=23)\n",
    "\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train_nb8, y_train_nb8)\n",
    "pred_nb8 = clf_nb.predict(X_test_nb8)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb8, pred_nb8)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "nb_grid_param = [ {'alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "                  {'fit_prior' : [True, False]} ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_nb = GridSearchCV(clf_nb, nb_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_nb.fit(X_train_nb8, y_train_nb8)\n",
    "\n",
    "print(gs_nb.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.812\n",
      "Precision:  0.809\n",
      "Recall:  0.812\n",
      "F1 Score:  0.81\n"
     ]
    }
   ],
   "source": [
    "clf_nb = MultinomialNB(alpha=0.0)\n",
    "clf_nb.fit(X_train_nb8, y_train_nb8)\n",
    "pred_nb8 = clf_nb.predict(X_test_nb8)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb8, pred_nb8)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_false_idx(predicted, actual, df):\n",
    "    index = []\n",
    "    prediction = []\n",
    "    for i in range(len(predicted)):\n",
    "        temp = []\n",
    "        if predicted[i] != actual[i]:\n",
    "            index.append(df.index[i])\n",
    "            temp.append(predicted[i])\n",
    "            temp.append(actual[i])\n",
    "            prediction.append(temp)\n",
    "    return index, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_idx(false_index, df_resample, df):\n",
    "    real = []\n",
    "    for i in range(len(false_index)):\n",
    "        fidx = false_index[i]\n",
    "        holder = df_resample.iloc[fidx].tolist()\n",
    "        for j in range(df.shape[0]):\n",
    "            if holder == df.iloc[j].tolist():\n",
    "                real.append(j)\n",
    "                break\n",
    "    return real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_false_count(prediction):\n",
    "    result = []\n",
    "    checked = []\n",
    "    for i in range(len(prediction)):\n",
    "        temp = []\n",
    "        holder = prediction[i]\n",
    "        if holder[1] not in checked:\n",
    "            checked.append(holder[1])\n",
    "            count = 0\n",
    "            for j in range(len(prediction)):\n",
    "                holder_2 = prediction[j]\n",
    "                if holder[1] == holder_2[1]:\n",
    "                    count += 1\n",
    "            temp.append(holder[1])\n",
    "            temp.append(count)\n",
    "        if temp:\n",
    "            result.append(temp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_summary(real_index, df, predicted):\n",
    "    subject_summary = []\n",
    "    subjects = []\n",
    "    \n",
    "    for i in range(len(real_index)):\n",
    "        subjects.append(df.subject.iloc[real_index[i]])\n",
    "        \n",
    "    checked = []\n",
    "    for i in range(len(subjects)):\n",
    "        temp = []\n",
    "        if subjects[i] not in checked:\n",
    "            count = 0\n",
    "            temp.append(subjects[i])\n",
    "            checked.append(subjects[i])\n",
    "            for j in range(len(subjects)):\n",
    "                if subjects[i] == subjects[j]:\n",
    "                    count += 1\n",
    "            temp.append(count)\n",
    "        if temp:\n",
    "            subject_summary.append(temp)\n",
    "    return subject_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_detail(real_index, df, predicted):\n",
    "    result = []\n",
    "    \n",
    "    for i in range(len(real_index)):\n",
    "        temp = []\n",
    "        temp.append(df.subject.iloc[real_index[i]])\n",
    "        temp.append(df.label.iloc[real_index[i]])\n",
    "        temp.append(predicted[i])\n",
    "        result.append(temp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_false_pair_count(prediction):\n",
    "    result = []\n",
    "    checked = []\n",
    "    for i in range(len(prediction)):\n",
    "        temp = []\n",
    "        if prediction[i] not in checked:\n",
    "            checked.append(prediction[i])\n",
    "            temp.append(prediction[i])\n",
    "            count = 0\n",
    "            for j in range(len(prediction)):\n",
    "                if prediction[i] == prediction[j]:\n",
    "                    count += 1\n",
    "            temp.append(count)\n",
    "        if temp:\n",
    "            result.append(temp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question(real_index, prediction, df, predicted, actual):\n",
    "    result = []\n",
    "    for i in range(len(real_index)):\n",
    "        if prediction[i][0] == predicted and prediction[i][1] == actual:\n",
    "            result.append(df.question.iloc[real_index[i]])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_svm = pred_svm8.tolist()\n",
    "actual_svm = y_test_svm8.label.tolist()\n",
    "\n",
    "# ambil liat yang salah prediksi di index mana aja\n",
    "false_index_svm, prediction_svm = get_false_idx(predicted_svm, actual_svm, y_test_svm8)\n",
    "\n",
    "# ambil index asli di dataframe sebelum resampling\n",
    "real_idx_svm = get_real_idx(false_index_svm, df_tfposidf_ros_mod, df_tfposidf_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C3', 19], ['C2', 15], ['C4', 6], ['C1', 6]]\n"
     ]
    }
   ],
   "source": [
    "# hitung jumlah salah prediksi\n",
    "false_count_svm = sorted(get_false_count(prediction_svm), key=lambda l:l[1], reverse=True)\n",
    "print(false_count_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bahasa indonesia', 23], ['matematika', 17], ['ipa', 6]]\n"
     ]
    }
   ],
   "source": [
    "# Hasil salah prediksi per subject\n",
    "subject_sum_svm = sorted(get_subject_summary(real_idx_svm, df, predicted_svm), key=lambda l:l[1], reverse=True)\n",
    "print(subject_sum_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['C4', 'C3'], 8], [['C2', 'C3'], 7], [['C3', 'C2'], 7], [['C2', 'C1'], 5], [['C1', 'C3'], 4], [['C4', 'C2'], 4], [['C1', 'C2'], 4], [['C2', 'C4'], 3], [['C3', 'C4'], 3], [['C4', 'C1'], 1]]\n"
     ]
    }
   ],
   "source": [
    "# Hitung jumlah [predicted, actual] yang salah\n",
    "false_pair_count_svm = sorted(get_false_pair_count(prediction_svm), key=lambda l:l[1], reverse=True)\n",
    "print(false_pair_count_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Berikut merupakan contoh kalimat untuk iklan buku tulis..',\n",
       " 'Penulisan kalimat langsung yang benar pada kutipan fabel adalah ',\n",
       " 'Pada gambar di atas, dan . Panjang AB = 20cm, AC = 15cm, dan BC = 25cm. Panjang AD adalah . . .',\n",
       " 'Manakah tema yang tidak tepat untuk teks fabel di atas? ...',\n",
       " 'Pada kutipan cerita di atas, yang berupa kalimat pasif intransitif adalah ',\n",
       " ' Muatan tersebut memiliki energi sebesar….',\n",
       " 'Informasi yang terdapat pada paragraf di atas adalah ..']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_question(real_idx_svm, prediction_svm, df, 'C2', 'C3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jumlah semua suku pada deret geometri 4 9 + 4 3 + 4 + . . . . 108 adalah . . . .',\n",
       " 'Besar sudut terkecil yang dibentuk jarum jam pada pukul 04.00 sama dengan . . .',\n",
       " 'Bentuk sederhana dari 8x+7xy€“2x+xy adalah ...',\n",
       " 'Ayah akan membagikan uang sejumlah Rp 240.000,00 kepada Amir dan Budi dengan perbandingan 3 : 5. Maka jumlah uang yang diterima oleh Budi adalah',\n",
       " 'Sekar hanya mengerjakan 20 soal tes matematika dari total soal 25. Sebanyak 17 jawabannya benar dan sisanya salah. Jika jawaban benar bernilai 4, jawaban salah bernilai -1 dan tidak menjawab bernilai 0, maka nilai yang didapat Sekar adalah .',\n",
       " 'Seorang penjual daging pada bulan Januari menjual 120 kg, bulan Februari 130 kg, Maret dan seterusnya selama 10 bulan selalu bertambah 10kg dari bulan sebelumnya. Jumlah daging yang terjual selama 10 bulan adalah kg',\n",
       " 'Ditentukan sin A = ,maka nilai cos 2A adalah ........',\n",
       " 'Tentukan unsur yang ditanyakan pada jumlah deret geometri tak hingga berikut. a. a = 15, S∞ = 30, r = . . . . b. S∞ = 16, a = 4, r = . . . . c. S∞ = 4, r = 1 2 , a = . . . . d. S∞= -8, r = 2 3 , a = . . . .']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_question(real_idx_svm, prediction_svm, df, 'C4', 'C3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C2</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C4</td>\n",
       "      <td>C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject actual predicted\n",
       "0  matematika     C3        C6\n",
       "1  matematika     C2        C4\n",
       "2  matematika     C3        C4\n",
       "3  matematika     C4        C5\n",
       "4  matematika     C3        C1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ambil subject detail\n",
    "df_subject_detail_svm = pd.DataFrame(sorted(get_subject_detail(real_idx_svm, df, predicted_svm), \n",
    "                                            key=lambda l:l[0], \n",
    "                                            reverse=True), \n",
    "                                    columns = ['subject', 'actual', 'predicted'])\n",
    "\n",
    "df_subject_detail_svm.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_nb = pred_nb_4.tolist()\n",
    "actual_nb = y_test_nb4.label.tolist()\n",
    "\n",
    "# ambil liat yang salah prediksi di index mana aja\n",
    "false_index_nb, prediction_nb = get_false_idx(predicted_nb, actual_nb, y_test_nb4)\n",
    "\n",
    "# ambil index asli di dataframe sebelum resampling\n",
    "real_idx_nb = get_real_idx(false_index_nb, df_tfidf_ros_mod, df_tfidf_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C3', 21], ['C2', 14], ['C4', 9], ['C1', 5], ['C6', 2]]\n"
     ]
    }
   ],
   "source": [
    "# hitung jumlah salah prediksi\n",
    "false_count_nb = sorted(get_false_count(prediction_nb), key=lambda l:l[1], reverse=True)\n",
    "print(false_count_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bahasa indonesia', 26], ['matematika', 16], ['ipa', 9]]\n"
     ]
    }
   ],
   "source": [
    "# summary dari hasil salah prediksi per subject\n",
    "subject_sum_nb = sorted(get_subject_summary(real_idx_nb, df, predicted_nb), key=lambda l:l[1], reverse=True)\n",
    "print(subject_sum_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['C2', 'C3'], 9], [['C4', 'C3'], 7], [['C3', 'C2'], 4], [['C1', 'C2'], 4], [['C4', 'C2'], 4], [['C3', 'C4'], 3], [['C1', 'C3'], 3], [['C1', 'C4'], 2], [['C6', 'C3'], 2], [['C2', 'C4'], 2], [['C2', 'C1'], 2], [['C5', 'C4'], 2], [['C1', 'C6'], 2], [['C4', 'C1'], 2], [['C5', 'C2'], 2], [['C5', 'C1'], 1]]\n"
     ]
    }
   ],
   "source": [
    "# Hitung jumlah [predicted, actual] yang salah\n",
    "false_pair_count_nb = sorted(get_false_pair_count(prediction_nb), key=lambda l:l[1], reverse=True)\n",
    "print(false_pair_count_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Berikut merupakan contoh kalimat untuk iklan buku tulis..',\n",
       " '295 + ( - 142) + 69 = .',\n",
       " 'Penulisan kalimat langsung yang benar pada kutipan fabel adalah ',\n",
       " 'Manakah tema yang tidak tepat untuk teks fabel di atas? ...',\n",
       " 'Pada kutipan cerita di atas, yang berupa kalimat pasif intransitif adalah ',\n",
       " 'Konjungsi yang tepat untuk melengkapi paragraf tersebut adalah ….',\n",
       " 'Berdasarkan struktur teks hasil observasi, bagian nomor 2 merupakan ...',\n",
       " 'Jika puisi tersebut dimusikalisasi, musik yang cocok untuk mengiringi puisi itu adalah musik yang menunjukkan suasana .',\n",
       " ' Muatan tersebut memiliki energi sebesar….']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_question(real_idx_nb, prediction_nb, df, 'C2', 'C3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jumlah semua suku pada deret geometri 4 9 + 4 3 + 4 + . . . . 108 adalah . . . .',\n",
       " 'Besar sudut terkecil yang dibentuk jarum jam pada pukul 04.00 sama dengan . . .',\n",
       " 'Bentuk sederhana dari 8x+7xy€“2x+xy adalah ...',\n",
       " 'Ayah akan membagikan uang sejumlah Rp 240.000,00 kepada Amir dan Budi dengan perbandingan 3 : 5. Maka jumlah uang yang diterima oleh Budi adalah',\n",
       " 'Sekar hanya mengerjakan 20 soal tes matematika dari total soal 25. Sebanyak 17 jawabannya benar dan sisanya salah. Jika jawaban benar bernilai 4, jawaban salah bernilai -1 dan tidak menjawab bernilai 0, maka nilai yang didapat Sekar adalah .',\n",
       " 'Seorang penjual daging pada bulan Januari menjual 120 kg, bulan Februari 130 kg, Maret dan seterusnya selama 10 bulan selalu bertambah 10kg dari bulan sebelumnya. Jumlah daging yang terjual selama 10 bulan adalah kg',\n",
       " 'Ditentukan sin A = ,maka nilai cos 2A adalah ........',\n",
       " 'Tentukan unsur yang ditanyakan pada jumlah deret geometri tak hingga berikut. a. a = 15, S∞ = 30, r = . . . . b. S∞ = 16, a = 4, r = . . . . c. S∞ = 4, r = 1 2 , a = . . . . d. S∞= -8, r = 2 3 , a = . . . .']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_question(real_idx_svm, prediction_svm, df, 'C4', 'C3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C4</td>\n",
       "      <td>C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C2</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C2</td>\n",
       "      <td>C6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject actual predicted\n",
       "0  matematika     C4        C5\n",
       "1  matematika     C3        C2\n",
       "2  matematika     C2        C3\n",
       "3  matematika     C3        C3\n",
       "4  matematika     C2        C6"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ambil subject detail\n",
    "df_subject_detail_nb = pd.DataFrame(sorted(get_subject_detail(real_idx_nb, df, predicted_nb), \n",
    "                                            key=lambda l:l[0], \n",
    "                                            reverse=True), \n",
    "                                    columns = ['subject', 'actual', 'predicted'])\n",
    "\n",
    "df_subject_detail_nb.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Best Model (No resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_svm_nr = pred_svm6.tolist()\n",
    "actual_svm_nr = y_test_svm6.tolist()\n",
    "\n",
    "# ambil liat yang salah prediksi di index mana aja\n",
    "false_index_svm_nr, prediction_svm_nr = get_false_idx(predicted_svm_nr, actual_svm_nr, y_test_svm6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hitung jumlah salah prediksi\n",
    "false_count_svm_nr = sorted(get_false_count(prediction_svm_nr), key=lambda l:l[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ipa', 27], ['bahasa indonesia', 26], ['matematika', 15]]\n"
     ]
    }
   ],
   "source": [
    "# summary dari hasil salah prediksi per subject\n",
    "subject_sum_svm_nr = sorted(get_subject_summary(false_index_svm_nr, df, predicted_svm_nr), key=lambda l:l[1], reverse=True)\n",
    "print(subject_sum_svm_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C6</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C4</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C5</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C6</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C1</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C6</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C4</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C1</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             subject actual predicted\n",
       "0         matematika     C6        C4\n",
       "1         matematika     C3        C4\n",
       "2         matematika     C4        C2\n",
       "3         matematika     C5        C1\n",
       "4         matematika     C6        C2\n",
       "..               ...    ...       ...\n",
       "63  bahasa indonesia     C1        C3\n",
       "64  bahasa indonesia     C6        C3\n",
       "65  bahasa indonesia     C3        C4\n",
       "66  bahasa indonesia     C4        C1\n",
       "67  bahasa indonesia     C1        C3\n",
       "\n",
       "[68 rows x 3 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ambil subject detail\n",
    "df_subject_detail_svm_nr = pd.DataFrame(sorted(get_subject_detail(false_index_svm_nr, df, predicted_svm_nr), \n",
    "                                            key=lambda l:l[0], \n",
    "                                            reverse=True), \n",
    "                                    columns = ['subject', 'actual', 'predicted'])\n",
    "\n",
    "df_subject_detail_svm_nr.head(68)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB Best Model (No resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_nb_nr = pred_nb_2.tolist()\n",
    "actual_nb_nr = y_test_nb2.tolist()\n",
    "\n",
    "# ambil liat yang salah prediksi di index mana aja\n",
    "false_index_nb_nr, prediction_nb_nr = get_false_idx(predicted_nb_nr, actual_nb_nr, y_test_nb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C1', 20], ['C3', 20], ['C4', 14], ['C6', 8], ['C2', 7], ['C5', 4]]\n"
     ]
    }
   ],
   "source": [
    "# hitung jumlah salah prediksi\n",
    "false_count_nb_nr = sorted(get_false_count(prediction_nb_nr), key=lambda l:l[1], reverse=True)\n",
    "print(false_count_nb_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bahasa indonesia', 29], ['ipa', 27], ['matematika', 17]]\n"
     ]
    }
   ],
   "source": [
    "# summary dari hasil salah prediksi per subject\n",
    "subject_sum_nb_nr = sorted(get_subject_summary(false_index_nb_nr, df, predicted_nb_nr), key=lambda l:l[1], reverse=True)\n",
    "print(subject_sum_nb_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C6</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C4</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C1</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C5</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C6</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C1</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C4</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C1</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             subject actual predicted\n",
       "0         matematika     C6        C3\n",
       "1         matematika     C3        C1\n",
       "2         matematika     C4        C3\n",
       "3         matematika     C1        C3\n",
       "4         matematika     C5        C4\n",
       "..               ...    ...       ...\n",
       "68  bahasa indonesia     C6        C1\n",
       "69  bahasa indonesia     C3        C2\n",
       "70  bahasa indonesia     C1        C2\n",
       "71  bahasa indonesia     C4        C3\n",
       "72  bahasa indonesia     C1        C1\n",
       "\n",
       "[73 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ambil subject detail\n",
    "df_subject_detail_nb_nr = pd.DataFrame(sorted(get_subject_detail(false_index_nb_nr, df, predicted_nb_nr), \n",
    "                                            key=lambda l:l[0], \n",
    "                                            reverse=True), \n",
    "                                    columns = ['subject', 'actual', 'predicted'])\n",
    "\n",
    "df_subject_detail_nb_nr.head(73)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
