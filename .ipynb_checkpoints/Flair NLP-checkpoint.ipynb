{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "en9bUDg3P6Pm",
    "outputId": "828d7fe2-6674-4c2f-ac81-3cd3582657a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "  Downloading flair-0.10-py3-none-any.whl (322 kB)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in d:\\coding\\software\\anaconda\\lib\\site-packages (from flair) (4.61.2)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
      "Collecting gdown==3.12.2\n",
      "  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: torch!=1.8,>=1.5.0 in d:\\coding\\software\\anaconda\\lib\\site-packages (from flair) (1.7.0)\n",
      "Requirement already satisfied: regex in d:\\coding\\software\\anaconda\\lib\\site-packages (from flair) (2020.7.14)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in d:\\coding\\software\\anaconda\\lib\\site-packages (from flair) (2.8.1)\n",
      "Requirement already satisfied: lxml in d:\\coding\\software\\anaconda\\lib\\site-packages (from flair) (4.5.2)\n",
      "Collecting konoha<5.0.0,>=4.0.0\n",
      "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
      "Collecting mpld3==0.3\n",
      "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in d:\\coding\\software\\anaconda\\lib\\site-packages (from flair) (3.4.2)\n",
      "Collecting bpemb>=0.3.2\n",
      "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in d:\\coding\\software\\anaconda\\lib\\site-packages (from flair) (0.23.2)\n",
      "Collecting transformers>=4.0.0\n",
      "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
      "Requirement already satisfied: gensim>=3.4.0 in d:\\coding\\software\\anaconda\\lib\\site-packages (from flair) (3.4.0)\n",
      "Collecting deprecated>=1.2.4\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting sqlitedict>=1.6.0\n",
      "  Downloading sqlitedict-1.7.0.tar.gz (28 kB)\n",
      "Collecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "Collecting more-itertools~=8.8.0\n",
      "  Downloading more_itertools-8.8.0-py3-none-any.whl (48 kB)\n",
      "Collecting wikipedia-api\n",
      "  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
      "Collecting janome\n",
      "  Downloading Janome-0.4.1-py2.py3-none-any.whl (19.7 MB)\n",
      "Collecting segtok>=1.5.7\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Collecting sentencepiece==0.1.95\n",
      "  Downloading sentencepiece-0.1.95-cp37-cp37m-win_amd64.whl (1.2 MB)\n",
      "Collecting conllu>=4.0\n",
      "  Downloading conllu-4.4.1-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tqdm>=4.26.0->flair) (0.4.1)\n",
      "Requirement already satisfied: six in d:\\coding\\software\\anaconda\\lib\\site-packages (from langdetect->flair) (1.15.0)\n",
      "Requirement already satisfied: wcwidth in d:\\coding\\software\\anaconda\\lib\\site-packages (from ftfy->flair) (0.2.5)\n",
      "Requirement already satisfied: requests[socks] in d:\\coding\\software\\anaconda\\lib\\site-packages (from gdown==3.12.2->flair) (2.24.0)\n",
      "Requirement already satisfied: filelock in d:\\coding\\software\\anaconda\\lib\\site-packages (from gdown==3.12.2->flair) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions in d:\\coding\\software\\anaconda\\lib\\site-packages (from torch!=1.8,>=1.5.0->flair) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in d:\\coding\\software\\anaconda\\lib\\site-packages (from torch!=1.8,>=1.5.0->flair) (0.6)\n",
      "Requirement already satisfied: numpy in d:\\coding\\software\\anaconda\\lib\\site-packages (from torch!=1.8,>=1.5.0->flair) (1.19.5)\n",
      "Requirement already satisfied: future in d:\\coding\\software\\anaconda\\lib\\site-packages (from torch!=1.8,>=1.5.0->flair) (0.18.2)\n",
      "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
      "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
      "Collecting overrides<4.0.0,>=3.0.0\n",
      "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\coding\\software\\anaconda\\lib\\site-packages (from matplotlib>=2.2.3->flair) (1.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\coding\\software\\anaconda\\lib\\site-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\coding\\software\\anaconda\\lib\\site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\coding\\software\\anaconda\\lib\\site-packages (from matplotlib>=2.2.3->flair) (8.3.1)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\coding\\software\\anaconda\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\coding\\software\\anaconda\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\coding\\software\\anaconda\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (2.1.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\coding\\software\\anaconda\\lib\\site-packages (from transformers>=4.0.0->flair) (20.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\coding\\software\\anaconda\\lib\\site-packages (from transformers>=4.0.0->flair) (5.3.1)\n",
      "Requirement already satisfied: smart_open>=1.2.1 in d:\\coding\\software\\anaconda\\lib\\site-packages (from gensim>=3.4.0->flair) (2.2.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in d:\\coding\\software\\anaconda\\lib\\site-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in d:\\coding\\software\\anaconda\\lib\\site-packages (from requests[socks]->gdown==3.12.2->flair) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\coding\\software\\anaconda\\lib\\site-packages (from requests[socks]->gdown==3.12.2->flair) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\coding\\software\\anaconda\\lib\\site-packages (from requests[socks]->gdown==3.12.2->flair) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\coding\\software\\anaconda\\lib\\site-packages (from requests[socks]->gdown==3.12.2->flair) (1.25.10)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in d:\\coding\\software\\anaconda\\lib\\site-packages (from requests[socks]->gdown==3.12.2->flair) (1.7.1)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\coding\\software\\anaconda\\lib\\site-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.3.0)\n",
      "Requirement already satisfied: click in d:\\coding\\software\\anaconda\\lib\\site-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n",
      "Requirement already satisfied: boto3 in d:\\coding\\software\\anaconda\\lib\\site-packages (from smart_open>=1.2.1->gensim>=3.4.0->flair) (1.15.12)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in d:\\coding\\software\\anaconda\\lib\\site-packages (from boto3->smart_open>=1.2.1->gensim>=3.4.0->flair) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.19.0,>=1.18.12 in d:\\coding\\software\\anaconda\\lib\\site-packages (from boto3->smart_open>=1.2.1->gensim>=3.4.0->flair) (1.18.12)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in d:\\coding\\software\\anaconda\\lib\\site-packages (from boto3->smart_open>=1.2.1->gensim>=3.4.0->flair) (0.10.0)\n",
      "Building wheels for collected packages: langdetect, ftfy, gdown, mpld3, sqlitedict, wikipedia-api, overrides\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=4f8986a1cb24436cf91674a123d8b2c4c1dc682d54f383d7ccbb1b6284cb0572\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\c5\\96\\8a\\f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
      "  Building wheel for ftfy (setup.py): started\n",
      "  Building wheel for ftfy (setup.py): finished with status 'done'\n",
      "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41920 sha256=6c29bdfed97caa95e41756876cc300e246f1fea9950867b0f9cecfacfe1f2236\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\19\\f5\\38\\273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
      "  Building wheel for gdown (PEP 517): started\n",
      "  Building wheel for gdown (PEP 517): finished with status 'done'\n",
      "  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9692 sha256=96dfd1dfb783ba061e655fe64b9e3859a184dca881c6f85761e14f84b42b5d4e\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\ba\\e0\\7e\\726e872a53f7358b4b96a9975b04e98113b005cd8609a63abc\n",
      "  Building wheel for mpld3 (setup.py): started\n",
      "  Building wheel for mpld3 (setup.py): finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "nxviz 0.6.2 requires hypothesis==4.34.0, which is not installed.\n",
      "nxviz 0.6.2 requires sphinxcontrib-fulltoc==1.2.0, which is not installed.\n",
      "nxviz 0.6.2 requires cryptography==2.7, but you'll have cryptography 3.1.1 which is incompatible.\n",
      "nxviz 0.6.2 requires matplotlib==3.1.1, but you'll have matplotlib 3.4.2 which is incompatible.\n",
      "nxviz 0.6.2 requires more-itertools==7.2.0, but you'll have more-itertools 8.8.0 which is incompatible.\n",
      "nxviz 0.6.2 requires networkx==2.3, but you'll have networkx 2.5 which is incompatible.\n",
      "nxviz 0.6.2 requires numpy==1.17.1, but you'll have numpy 1.19.5 which is incompatible.\n",
      "nxviz 0.6.2 requires palettable==3.1.1, but you'll have palettable 3.3.0 which is incompatible.\n",
      "nxviz 0.6.2 requires pandas==0.25.1, but you'll have pandas 1.1.2 which is incompatible.\n",
      "nxviz 0.6.2 requires pytest==5.1.2, but you'll have pytest 0.0.0 which is incompatible.\n",
      "nxviz 0.6.2 requires PyYAML==5.1.2, but you'll have pyyaml 5.3.1 which is incompatible.\n",
      "nxviz 0.6.2 requires seaborn==0.9.0, but you'll have seaborn 0.11.0 which is incompatible.\n",
      "nxviz 0.6.2 requires setuptools==41.2.0, but you'll have setuptools 50.3.0.post20201006 which is incompatible.\n",
      "konoha 4.6.5 requires requests<3.0.0,>=2.25.1, but you'll have requests 2.24.0 which is incompatible.\n",
      "huggingface-hub 0.4.0 requires packaging>=20.9, but you'll have packaging 20.4 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116683 sha256=a076f09279e4d9d232acafb79569f71710655d600864ddd37b414b07cf24d1f1\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\26\\70\\6a\\1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
      "  Building wheel for sqlitedict (setup.py): started\n",
      "  Building wheel for sqlitedict (setup.py): finished with status 'done'\n",
      "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-py3-none-any.whl size=14381 sha256=32bf0dd88fbbd8def7cdf89a59253b3ff4c3b5a2a9929be0a00b2673616655c8\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\af\\94\\06\\18c0e83e9e227da8f3582810b51f319bbfd181e508676a56c8\n",
      "  Building wheel for wikipedia-api (setup.py): started\n",
      "  Building wheel for wikipedia-api (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13467 sha256=b885e3fe1a8d0bd1ed633d3877c543a3f4d09a288516962588e2138ba9767a92\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\d3\\24\\56\\58ba93cf78be162451144e7a9889603f437976ef1ae7013d04\n",
      "  Building wheel for overrides (setup.py): started\n",
      "  Building wheel for overrides (setup.py): finished with status 'done'\n",
      "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10179 sha256=8d7d24b54ea7d500c1a00e1983ac0cd3fc6291aceedece3612181383f86ea2ec\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\3a\\0d\\38\\01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
      "Successfully built langdetect ftfy gdown mpld3 sqlitedict wikipedia-api overrides\n",
      "Installing collected packages: tabulate, langdetect, ftfy, gdown, importlib-metadata, overrides, konoha, mpld3, sentencepiece, bpemb, sacremoses, tokenizers, huggingface-hub, transformers, deprecated, sqlitedict, more-itertools, wikipedia-api, janome, segtok, conllu, flair\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 1.7.0\n",
      "    Uninstalling importlib-metadata-1.7.0:\n",
      "      Successfully uninstalled importlib-metadata-1.7.0\n",
      "  Attempting uninstall: more-itertools\n",
      "    Found existing installation: more-itertools 8.5.0\n",
      "    Uninstalling more-itertools-8.5.0:\n",
      "      Successfully uninstalled more-itertools-8.5.0\n",
      "Successfully installed bpemb-0.3.3 conllu-4.4.1 deprecated-1.2.13 flair-0.10 ftfy-6.0.3 gdown-3.12.2 huggingface-hub-0.4.0 importlib-metadata-3.10.1 janome-0.4.1 konoha-4.6.5 langdetect-1.0.9 more-itertools-8.8.0 mpld3-0.3 overrides-3.1.0 sacremoses-0.0.47 segtok-1.5.11 sentencepiece-0.1.95 sqlitedict-1.7.0 tabulate-0.8.9 tokenizers-0.10.3 transformers-4.15.0 wikipedia-api-0.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Byjn8iEai1gu"
   },
   "outputs": [],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher, NLPTask\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, BertEmbeddings\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-N8O7y3ezxH2",
    "outputId": "07fcee7a-31f1-4cea-f29a-cbb8ef90211b"
   },
   "outputs": [],
   "source": [
    "# 1. get the corpus\n",
    "corpus = NLPTaskDataFetcher.load_corpus(NLPTask.UD_INDONESIAN)\n",
    "\n",
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'upos'\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary.idx2item)\n",
    "\n",
    "# 4. initialize embeddings\n",
    "embedding_types: List[TokenEmbeddings] = [\n",
    "    WordEmbeddings('id-crawl'),\n",
    "    WordEmbeddings('id'),\n",
    "    #WordEmbeddings('glove'),\n",
    "    #BertEmbeddings('bert-base-multilingual-cased')\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "# 5. initialize sequence tagger\n",
    "from flair.models import SequenceTagger\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)\n",
    "\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "# 7. start training\n",
    "trainer.train('resources/taggers/example-universal-pos',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "LqvmmuVf7cPs",
    "outputId": "154b4971-f37b-4973-e420-8395bc18c049"
   },
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "\n",
    "sentence = Sentence('saya dan dia kemarin pergi ke pasar bersama untuk membeli jeruk')\n",
    "tag_pos = SequenceTagger.load('resources/taggers/example-universal-pos/best-model.pt')\n",
    "tag_pos.predict(sentence)\n",
    "print(sentence.to_tagged_string())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Flair 2.0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
