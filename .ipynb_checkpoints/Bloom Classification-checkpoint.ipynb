{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "df = pd.read_csv('data\\data_test.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Dataset Distribution')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grafik kiri\n",
    "label = df['label'].value_counts().sort_index(ascending=True)\n",
    "label_pt = label.index\n",
    "label_freq = label.values\n",
    "\n",
    "# Grafik tengah\n",
    "ed_level = df['edu_level'].value_counts()\n",
    "edu_level_pt = ed_level.index\n",
    "edu_level_freq = ed_level.values\n",
    "\n",
    "# Grafik kanan\n",
    "subject = df['subject'].value_counts()\n",
    "subject_pt = subject.index\n",
    "subject_freq = subject.values\n",
    "\n",
    "# Subplot dibuat 1 baris, 3 kolom. figsize=(x, y)\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Grafik kiri\n",
    "axs[0].bar(label_pt, label_freq)\n",
    "axs[0].set_xlabel(\"Cognitive Level\")\n",
    "axs[0].set_ylabel(\"Num Of Questions\")\n",
    "\n",
    "# Grafik tengah\n",
    "axs[1].bar(edu_level_pt, edu_level_freq)\n",
    "axs[1].set_xlabel(\"Education Level\")\n",
    "axs[1].set_ylabel(\"Num Of Questions\")\n",
    "\n",
    "# Grafik kanan\n",
    "axs[2].bar(subject_pt, subject_freq)\n",
    "axs[2].set_xlabel(\"Subject\")\n",
    "axs[2].set_ylabel(\"Num Of Questions\")\n",
    "\n",
    "fig.suptitle('Dataset Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Coding\\Software\\Anaconda\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-05 08:15:23,207 loading file resources/taggers/example-upos/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "import re\n",
    "\n",
    "# Loading trained model hasil dari FlairNLP untuk POS Tagging\n",
    "postagger = SequenceTagger.load('resources/taggers/example-upos/best-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tag(series):\n",
    "    word_tag = []\n",
    "    for i in range(series.shape[0]):\n",
    "        text = Sentence(series[i])\n",
    "        postagger.predict(text)\n",
    "        \n",
    "        # hasil dari FlairNLP berbentuk [WORD, <TAG>]\n",
    "        # karakter kurung sudut dihilangkan\n",
    "        x = re.split(r\"\\>\\s|>\", text.to_tagged_string())\n",
    "        res = []\n",
    "        \n",
    "        # Untuk split biar dapet pasangan kata-tag\n",
    "        for i in range(len(x)):\n",
    "            temp = re.split(r\"\\s\", x[i])\n",
    "            if(len(temp) > 1):\n",
    "                for char in temp[1]:\n",
    "                    if char == '<':\n",
    "                        temp[1] = temp[1].replace('<', \"\")\n",
    "                res.append(temp)\n",
    "        word_tag.append(res)\n",
    "    \n",
    "    return word_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>subject</th>\n",
       "      <th>edu_level</th>\n",
       "      <th>tag_pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Udang ronggeng memiliki duri-duri yang keras, ...</td>\n",
       "      <td>Makna istilah kata vulkanis pada kutipan teks ...</td>\n",
       "      <td>C2</td>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>SMA</td>\n",
       "      <td>[[Makna, NOUN], [istilah, NOUN], [kata, NOUN],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saya pun membandingkan perlakuan yang ibu beri...</td>\n",
       "      <td>Latar suasana pada paragraf pertama dalam kuti...</td>\n",
       "      <td>C2</td>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>SMA</td>\n",
       "      <td>[[Latar, NOUN], [suasana, NOUN], [pada, ADP], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bapakku bernama Narto. Biasa dipanggil Kang Na...</td>\n",
       "      <td>Makna frasa cokelat legam pada kutipan cerpen ...</td>\n",
       "      <td>C2</td>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>SMA</td>\n",
       "      <td>[[Makna, NOUN], [frasa, NOUN], [cokelat, NOUN]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kebakaran hutan akibat kelalaian manusia di be...</td>\n",
       "      <td>Maksud pernyataan Evakuasi akan dilakukan kepa...</td>\n",
       "      <td>C2</td>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>SMA</td>\n",
       "      <td>[[Maksud, NOUN], [pernyataan, NOUN], [Evakuasi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hal yang disarankan Mat agar dilakukan istriny...</td>\n",
       "      <td>Nilai moral pada kutipan novel tersebut adalah ….</td>\n",
       "      <td>C2</td>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>SMA</td>\n",
       "      <td>[[Nilai, NOUN], [moral, NOUN], [pada, ADP], [k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Udang ronggeng memiliki duri-duri yang keras, ...   \n",
       "1  Saya pun membandingkan perlakuan yang ibu beri...   \n",
       "2  Bapakku bernama Narto. Biasa dipanggil Kang Na...   \n",
       "3  Kebakaran hutan akibat kelalaian manusia di be...   \n",
       "4  Hal yang disarankan Mat agar dilakukan istriny...   \n",
       "\n",
       "                                            question label           subject  \\\n",
       "0  Makna istilah kata vulkanis pada kutipan teks ...    C2  bahasa indonesia   \n",
       "1  Latar suasana pada paragraf pertama dalam kuti...    C2  bahasa indonesia   \n",
       "2  Makna frasa cokelat legam pada kutipan cerpen ...    C2  bahasa indonesia   \n",
       "3  Maksud pernyataan Evakuasi akan dilakukan kepa...    C2  bahasa indonesia   \n",
       "4  Nilai moral pada kutipan novel tersebut adalah ….    C2  bahasa indonesia   \n",
       "\n",
       "  edu_level                                           tag_pair  \n",
       "0       SMA  [[Makna, NOUN], [istilah, NOUN], [kata, NOUN],...  \n",
       "1       SMA  [[Latar, NOUN], [suasana, NOUN], [pada, ADP], ...  \n",
       "2       SMA  [[Makna, NOUN], [frasa, NOUN], [cokelat, NOUN]...  \n",
       "3       SMA  [[Maksud, NOUN], [pernyataan, NOUN], [Evakuasi...  \n",
       "4       SMA  [[Nilai, NOUN], [moral, NOUN], [pada, ADP], [k...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tag_pair'] = add_tag(df.question)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full(df, num):\n",
    "    for i in range(num):\n",
    "        print(df[i])\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casefolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['makna', 'NOUN'], ['istilah', 'NOUN'], ['kata', 'NOUN'], ['vulkanis', 'NOUN'], ['pada', 'ADP'], ['kutipan', 'NOUN'], ['teks', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX'], ['…', 'PUNCT'], ['.', 'PUNCT']]\n",
      "\n",
      "[['latar', 'NOUN'], ['suasana', 'NOUN'], ['pada', 'ADP'], ['paragraf', 'NOUN'], ['pertama', 'ADJ'], ['dalam', 'ADP'], ['kutipan', 'NOUN'], ['cerpen', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX'], ['…', 'PUNCT'], ['.', 'PUNCT']]\n",
      "\n",
      "[['makna', 'NOUN'], ['frasa', 'NOUN'], ['cokelat', 'NOUN'], ['legam', 'ADJ'], ['pada', 'ADP'], ['kutipan', 'NOUN'], ['cerpen', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX'], ['…', 'PUNCT'], ['.', 'PUNCT']]\n",
      "\n",
      "[['maksud', 'NOUN'], ['pernyataan', 'NOUN'], ['evakuasi', 'NOUN'], ['akan', 'AUX'], ['dilakukan', 'VERB'], ['kepada', 'ADP'], ['masyarakat', 'NOUN'], ['yang', 'PRON'], ['daerahnya', 'NOUN'], ['telah', 'AUX'], ['dipenuhi', 'VERB'], ['kabut', 'NOUN'], ['asap', 'NOUN'], ['akibat', 'ADP'], ['kebakaran', 'NOUN'], ['hutan', 'NOUN'], ['pada', 'ADP'], ['paragraf', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX'], ['…', 'PUNCT'], ['.', 'PUNCT']]\n",
      "\n",
      "[['nilai', 'NOUN'], ['moral', 'NOUN'], ['pada', 'ADP'], ['kutipan', 'NOUN'], ['novel', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX'], ['…', 'PUNCT'], ['.', 'PUNCT']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Casefolding from column 'question'\n",
    "# df.question = df.question.str.lower()\n",
    "\n",
    "# Mengubah semua huruf kapital menjadi huruf kecil dari kolom 'tag_pair'\n",
    "for i in range(df.tag_pair.shape[0]):\n",
    "    for j in range(len(df['tag_pair'][i])):\n",
    "        df['tag_pair'][i][j][0] = df['tag_pair'][i][j][0].lower()\n",
    "        \n",
    "print_full(df.tag_pair, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(series):\n",
    "    no_punct = []\n",
    "    for i in range(series.shape[0]):\n",
    "        holder = series[i]\n",
    "        temp = []\n",
    "        for j in range(len(holder)):\n",
    "        \n",
    "            # Mapping punctuations dari string ke ''\n",
    "            holder[j][0] = holder[j][0].translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "            # Hapus tag bertanda 'PUNCT'\n",
    "            # Dibuat list baru untuk nampung non-PUNCT\n",
    "            if len(holder[j][0]) > 0 and holder[j][1] != 'PUNCT':\n",
    "                temp.append(holder[j])\n",
    "        \n",
    "        no_punct.append(temp)\n",
    "    return no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tag_pair'] = remove_punctuation(df['tag_pair'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['makna', 'NOUN'], ['istilah', 'NOUN'], ['kata', 'NOUN'], ['vulkanis', 'NOUN'], ['pada', 'ADP'], ['kutipan', 'NOUN'], ['teks', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX']]\n",
      "\n",
      "[['latar', 'NOUN'], ['suasana', 'NOUN'], ['pada', 'ADP'], ['paragraf', 'NOUN'], ['pertama', 'ADJ'], ['dalam', 'ADP'], ['kutipan', 'NOUN'], ['cerpen', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX']]\n",
      "\n",
      "[['makna', 'NOUN'], ['frasa', 'NOUN'], ['cokelat', 'NOUN'], ['legam', 'ADJ'], ['pada', 'ADP'], ['kutipan', 'NOUN'], ['cerpen', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX']]\n",
      "\n",
      "[['maksud', 'NOUN'], ['pernyataan', 'NOUN'], ['evakuasi', 'NOUN'], ['akan', 'AUX'], ['dilakukan', 'VERB'], ['kepada', 'ADP'], ['masyarakat', 'NOUN'], ['yang', 'PRON'], ['daerahnya', 'NOUN'], ['telah', 'AUX'], ['dipenuhi', 'VERB'], ['kabut', 'NOUN'], ['asap', 'NOUN'], ['akibat', 'ADP'], ['kebakaran', 'NOUN'], ['hutan', 'NOUN'], ['pada', 'ADP'], ['paragraf', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX']]\n",
      "\n",
      "[['nilai', 'NOUN'], ['moral', 'NOUN'], ['pada', 'ADP'], ['kutipan', 'NOUN'], ['novel', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_full(df.tag_pair, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bikin copy isi dataframe\n",
    "# Work-around karena value setelah pake df.copy() suka berubah sendiri\n",
    "def reserve(df_col):\n",
    "    res = []\n",
    "    for index in df_col.index:\n",
    "        holder = df_col[index]\n",
    "        temp = []\n",
    "        for i in range(len(holder)):\n",
    "            temp_2 = []\n",
    "            temp_2.append(holder[i][0])\n",
    "            temp_2.append(holder[i][1])\n",
    "            temp.append(temp_2)\n",
    "        res.append(temp)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tambah 0 ke list reserve untuk keperluan weighting\n",
    "def add_zero(list_2d):\n",
    "    for i in range(len(list_2d)):\n",
    "        for j in range(len(list_2d[i])):\n",
    "            list_2d[i][j].append(0)\n",
    "    return list_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_freq(corpus):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    features = vectorizer.get_feature_names_out()\n",
    "    features_with_0 = []\n",
    "    \n",
    "    for i in range(len(features)):\n",
    "        temp = []\n",
    "        temp.append(features[i])\n",
    "        temp.append(0)\n",
    "        features_with_0.append(temp)\n",
    "\n",
    "    wordfreq = X.toarray()\n",
    "    for i in range(len(wordfreq)):\n",
    "        for j in range(len(wordfreq[i])):\n",
    "            if wordfreq[i][j] != 0:\n",
    "                features_with_0[j][1] += wordfreq[i][j]\n",
    "    \n",
    "    return features_with_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(series, stopwords):\n",
    "    res = []\n",
    "    for i in range(series.shape[0]):\n",
    "        temp = []\n",
    "        holder = series[i]\n",
    "        for j in range(len(holder)):\n",
    "            if holder[j][0] in stopwords:\n",
    "                holder[j][0] = ''\n",
    "            if len(holder[j][0]) != 0:\n",
    "                temp.append(holder[j])\n",
    "        res.append(temp)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_factory = StopWordRemoverFactory()\n",
    "stopword = stopword_factory.create_stop_word_remover()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_default = stopword_factory.get_stop_words()\n",
    "\n",
    "sw_keep = ['adalah', 'apa', 'arti', 'artinya', 'berapa', 'berapakah', 'beri', \n",
    "           'berikan', 'diantaranya', 'disebut', 'jelaskan', 'karena',  \n",
    "           'mengapa', 'menunjukkan', 'merupakan', 'rupa', 'sebut']\n",
    "\n",
    "# List Comprehension buat exclude stopwords di sw_keep dari sw\n",
    "sw_modify = [x for x in sw_default if x not in sw_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplikat kolom tag_pair\n",
    "reserve_pair = reserve(df['tag_pair'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['makna', 'NOUN'], ['istilah', 'NOUN'], ['kata', 'NOUN'], ['vulkanis', 'NOUN'], ['pada', 'ADP'], ['kutipan', 'NOUN'], ['teks', 'NOUN'], ['tersebut', 'DET'], ['adalah', 'AUX']]\n"
     ]
    }
   ],
   "source": [
    "# tag_pair di-assign reserve soalnya habis buang stopword jadi rusak\n",
    "df['tag_pair_def'] = remove_stopword(df['tag_pair'], sw_default)\n",
    "df['tag_pair'] = reserve_pair\n",
    "print(df['tag_pair'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hapus stopwords dari tag_pair_mod\n",
    "df['tag_pair_mod'] = remove_stopword(df['tag_pair'], sw_modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['makna', 'NOUN'],\n",
       " ['istilah', 'NOUN'],\n",
       " ['vulkanis', 'NOUN'],\n",
       " ['kutipan', 'NOUN'],\n",
       " ['teks', 'NOUN']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tag_pair_def'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['makna', 'NOUN'],\n",
       " ['istilah', 'NOUN'],\n",
       " ['vulkanis', 'NOUN'],\n",
       " ['kutipan', 'NOUN'],\n",
       " ['teks', 'NOUN'],\n",
       " ['adalah', 'AUX']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tag_pair_mod'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# Mengubah kata ke bentuk dasarnya\n",
    "# Stemming setelah POSTagging karena sequence kata berguna dalam POSTagging\n",
    "def stem(series):\n",
    "    for i in range(series.shape[0]):\n",
    "        holder = series[i]\n",
    "        for j in range(len(holder)):\n",
    "            holder[j][0] = stemmer.stem(holder[j][0])\n",
    "    \n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_factory = StemmerFactory()\n",
    "stemmer = stem_factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['makna', 'NOUN'],\n",
       " ['istilah', 'NOUN'],\n",
       " ['vulkanis', 'NOUN'],\n",
       " ['kutip', 'NOUN'],\n",
       " ['teks', 'NOUN']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tag_pair_def = stem(df.tag_pair_def)\n",
    "df.tag_pair_def[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['makna', 'NOUN'],\n",
       " ['istilah', 'NOUN'],\n",
       " ['vulkanis', 'NOUN'],\n",
       " ['kutip', 'NOUN'],\n",
       " ['teks', 'NOUN'],\n",
       " ['adalah', 'AUX']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tag_pair_mod = stem(df.tag_pair_mod)\n",
    "df.tag_pair_mod[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "for TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_corpus(series):\n",
    "    corpus = []\n",
    "    for i in range(series.shape[0]):\n",
    "        holder = series[i]\n",
    "        temp = []\n",
    "        for j in range(len(holder)):\n",
    "            temp.append(holder[j][0])\n",
    "        corpus.append(' '.join(temp))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bikin corpus dari tag_pair_def & tag_pair_mod\n",
    "corpus_def = to_corpus(df.tag_pair_def)\n",
    "corpus_mod = to_corpus(df.tag_pair_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'makna istilah vulkanis kutip teks'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_def[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from itertools import chain\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(term_doc_matrix):\n",
    "    # Convert sparse matrix to list\n",
    "    temp = []\n",
    "    for i in range(term_doc_matrix.shape[0]):\n",
    "        holder = term_doc_matrix[i].toarray().tolist()\n",
    "        temp.append(holder[0])\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Buat ngitung nilai TF-IDF dari tiap term\n",
    "term_doc_matrix_def = vectorizer.fit_transform(corpus_def)\n",
    "# vocabulary_def = vectorizer.get_feature_names()\n",
    "\n",
    "term_doc_matrix_mod = vectorizer.fit_transform(corpus_mod)\n",
    "# vocabulary_mod = vectorizer.get_feature_names()\n",
    "\n",
    "# Convert hasil fit_transform dari sparse matrix ke list\n",
    "tfidf_def = flatten(term_doc_matrix_def)\n",
    "tfidf_mod = flatten(term_doc_matrix_mod)\n",
    "\n",
    "# Diubah ke dataframe untuk training & testing model\n",
    "df_tfidf_def = pd.DataFrame(tfidf_def)\n",
    "df_tfidf_mod = pd.DataFrame(tfidf_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576  0.5220918026519731\n",
      "723  0.34983840731204346\n",
      "792  0.465779484261717\n",
      "1219  0.28288115601620895\n",
      "1307  0.5550323972389433\n"
     ]
    }
   ],
   "source": [
    "a = tfidf_def[0]\n",
    "for i in range(len(a)):\n",
    "    if a[i] != 0:\n",
    "        print(str(i) + \"  \" + str(a[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "For TFPOS-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def termdoc_weighting(termdoc, features, tag_pair):\n",
    "    result = []\n",
    "    for i in range(len(termdoc)):\n",
    "        holder = termdoc[i]\n",
    "        holder_pair = tag_pair[i]\n",
    "        temp = []\n",
    "        for j in range(len(holder)):\n",
    "            if holder[j] != 0:\n",
    "                term = features[j]\n",
    "                weight = 1\n",
    "                for k in range(len(holder_pair)):\n",
    "                    if holder_pair[k][0] == term:\n",
    "                        if holder_pair[k][1] == 'VERB':\n",
    "                            weight = 5\n",
    "                        elif holder_pair[k][1] == 'ADJ' or holder_pair[k][1] == 'NOUN':\n",
    "                            weight = 3\n",
    "                        else:\n",
    "                            weight = 1\n",
    "                temp.append(holder[j] * weight)\n",
    "            else:\n",
    "                temp.append(holder[j])\n",
    "        result.append(temp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tfidf(termdoc_weighted, features, df):\n",
    "    result = []\n",
    "    for i in range(len(termdoc_weighted)):\n",
    "        holder = termdoc_weighted[i]\n",
    "        temp = []\n",
    "        denom = sum(termdoc_weighted[i])\n",
    "        for j in range(len(holder)):\n",
    "            if holder[j] != 0:\n",
    "                term = features[j]\n",
    "                idf = df.loc[df['word'] == term].idf\n",
    "                temp.append((holder[j]/denom) * (float(idf)))\n",
    "            else:\n",
    "                temp.append(holder[j])\n",
    "        result.append(temp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Coding\\Software\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Ambil nilai IDF tiap kata dari corpus\n",
    "term_doc_matrix_def = vectorizer.fit_transform(corpus_def)\n",
    "df_idf_def = pd.DataFrame(vectorizer.idf_, columns=['idf'])\n",
    "df_idf_def['word'] = vectorizer.get_feature_names()\n",
    "\n",
    "# Ambil nilai IDF tiap kata dari corpus\n",
    "term_doc_matrix_mod = vectorizer.fit_transform(corpus_mod)\n",
    "df_idf_mod = pd.DataFrame(vectorizer.idf_, columns=['idf'])\n",
    "df_idf_mod['word'] = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "# Bikin term-document matrix\n",
    "X_def = cv.fit_transform(corpus_def)\n",
    "features_def = cv.get_feature_names_out()\n",
    "termdoc_def = X_def.toarray()\n",
    "\n",
    "# Bikin term-document matrix\n",
    "X_mod = cv.fit_transform(corpus_mod)\n",
    "features_mod = cv.get_feature_names_out()\n",
    "termdoc_mod = X_mod.toarray()\n",
    "\n",
    "# dari term document dikali weightnya masing-masing\n",
    "termdoc_weighted_def = termdoc_weighting(termdoc_def, features_def, df.tag_pair_def)\n",
    "termdoc_weighted_mod = termdoc_weighting(termdoc_mod, features_mod, df.tag_pair_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFPOS-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFPOS-IDF\n",
    "ctfidf_def = count_tfidf(termdoc_weighted_def, features_def, df_idf_def)\n",
    "ctfidf_mod = count_tfidf(termdoc_weighted_mod, features_mod, df_idf_mod)\n",
    "\n",
    "# Normalisasi pake L2-Norm\n",
    "tfposidf_def = preprocessing.normalize(ctfidf_def, norm='l2').tolist()\n",
    "tfposidf_mod = preprocessing.normalize(ctfidf_mod, norm='l2').tolist()\n",
    "\n",
    "# Ubah list ke bentuk dataframe untuk training & testing\n",
    "df_tfposidf_def = pd.DataFrame(tfposidf_def)\n",
    "df_tfposidf_mod = pd.DataFrame(tfposidf_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['teladan', 'NOUN'], ['tokoh', 'NOUN'], ['dasar', 'ADP'], ['kutip', 'NOUN']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Untuk contoh hasil\n",
    "df.tag_pair_def[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 382)\t0.40174814472318027\n",
      "  (0, 1252)\t0.520511110095638\n",
      "  (0, 1220)\t0.6373892379778402\n",
      "  (0, 723)\t0.40174814472318027\n"
     ]
    }
   ],
   "source": [
    "# Kalo hasil dari tfidfvectorizer, urutan yg ditampilin sesuai sama urutan kata di dokumen (head--tail)\n",
    "print(term_doc_matrix_def[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 723)\t1\n",
      "  (0, 1220)\t1\n",
      "  (0, 1252)\t1\n",
      "  (0, 382)\t1\n"
     ]
    }
   ],
   "source": [
    "# Hasil countvectorizer, urutannya jadi kebalik dari kata di dokumen (tail--head)\n",
    "print(X_def[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382  1\n",
      "723  1\n",
      "1220  1\n",
      "1252  1\n"
     ]
    }
   ],
   "source": [
    "# Kalo countvectorizer dibikin toarray(), urutannya jadi alphabetical ngikutin method get_feature_names_out()\n",
    "a = termdoc_def[5]\n",
    "for i in range(len(a)):\n",
    "    if a[i] != 0:\n",
    "        print(str(i) + \"  \" + str(a[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382  0.40174814472318027\n",
      "723  0.40174814472318027\n",
      "1220  0.6373892379778402\n",
      "1252  0.520511110095638\n"
     ]
    }
   ],
   "source": [
    "# Kalo tfidfvectorizer di-apply flatten(), urutannya jadi alphabetical ngikutin method get_feature_names_out()\n",
    "a = tfidf_def[5]\n",
    "for i in range(len(a)):\n",
    "    if a[i] != 0:\n",
    "        print(str(i) + \"  \" + str(a[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382  0.43061538329752613\n",
      "723  1.2918461498925784\n",
      "1220  2.049564743185055\n",
      "1252  1.6737358526364445\n"
     ]
    }
   ],
   "source": [
    "# Hasil count_tfidf() sebelum normalisasi L2\n",
    "a = ctfidf_def[5]\n",
    "for i in range(len(a)):\n",
    "    if a[i] != 0:\n",
    "        print(str(i) + \"  \" + str(a[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382  0.1446974390994958\n",
      "723  0.4340923172984874\n",
      "1220  0.6887045403173292\n",
      "1252  0.5624167203477981\n"
     ]
    }
   ],
   "source": [
    "# Hasil TFPOS-IDF setelah normalisasi L2\n",
    "a = tfposidf_def[5]\n",
    "for i in range(len(a)):\n",
    "    if a[i] != 0:\n",
    "        print(str(i) + \"  \" + str(a[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Not majority karena cuma C3 yang banyak sendiri datanya\n",
    "ros = RandomOverSampler(sampling_strategy = 'not majority', random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling dari TF-IDF Reguler\n",
    "X_def, y_def = ros.fit_resample(tfidf_def, df['label'])\n",
    "X_mod, y_mod = ros.fit_resample(tfidf_mod, df['label'])\n",
    "\n",
    "df_tfidf_ros_def = pd.DataFrame(X_def)\n",
    "tfidf_ros_label_def = pd.DataFrame(y_def)\n",
    "df_tfidf_ros_mod = pd.DataFrame(X_mod)\n",
    "tfidf_ros_label_mod = pd.DataFrame(y_mod)\n",
    "\n",
    "# Resampling dari TFPOS-IDF\n",
    "X_def, y_def = ros.fit_resample(tfposidf_def, df['label'])\n",
    "X_mod, y_mod = ros.fit_resample(tfposidf_mod, df['label'])\n",
    "\n",
    "df_tfposidf_ros_def = pd.DataFrame(X_def)\n",
    "ros_tfposidf_label_def = pd.DataFrame(y_def)\n",
    "df_tfposidf_ros_mod = pd.DataFrame(X_mod)\n",
    "ros_tfposidf_label_mod = pd.DataFrame(y_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "C6       248\n",
       "C5       248\n",
       "C4       248\n",
       "C3       248\n",
       "C2       248\n",
       "C1       248\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_ros_label_def.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C3    248\n",
       "C2    134\n",
       "C1    130\n",
       "C4    113\n",
       "C5     37\n",
       "C6     19\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skenario pengujian\n",
    "1. TFIDF reguler, stopword PySastrawi ==> use df_tfidf_def\n",
    "2. TFIDF reguler, stopword modifikasi PySastrawi ==> use df_tfidf_mod\n",
    "3. TFIDF reguler, stopword PySastrawi, random over-sampling ==> df_tfidf_ros_def\n",
    "4. TFIDF reguler, stopword modifikasi PySastrawi, random over-sampling ==> df_tfidf_ros_mod\n",
    "5. TFPOS-IDF, stopword PySastrawi ==> use df_tfposidf_def\n",
    "6. TFPOS-IDF, stopword modifikasi PySastrawi ==> df_tfposidf_mod\n",
    "7. TFPOS-IDF, stopword PySastrawi, random over-sampling ==> df_tfposidf_ros_def\n",
    "8. TFPOS-IDF, stopword modifikasi PySastrawi, random over-sampling ==> df_tfposidf_ros_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(test, pred):\n",
    "    accuracy = metrics.accuracy_score(test, pred)\n",
    "    precision = metrics.precision_score(test, pred, average='weighted')\n",
    "    recall = metrics.recall_score(test, pred, average='weighted')\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 1 - SVM\n",
    "TFIDF reguler, stopword PySastrawi ==> use df_tfidf_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.453\n",
      "Precision:  0.407\n",
      "Recall:  0.453\n",
      "F1 Score:  0.429\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "SVC(C=1000, gamma=0.001)\n"
     ]
    }
   ],
   "source": [
    "X_train_svm1, X_test_svm1, y_train_svm1, y_test_svm1 = train_test_split(df_tfidf_def, \n",
    "                                                                        df['label'], \n",
    "                                                                        test_size=0.2, \n",
    "                                                                        random_state=23)\n",
    "clf_svm = svm.SVC(C=1, kernel='linear')\n",
    "clf_svm.fit(X_train_svm1, y_train_svm1)\n",
    "pred_svm_1 = clf_svm.predict(X_test_svm1)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm1, pred_svm_1)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "svm_grid_param = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001, 'auto'], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_svm = GridSearchCV(clf_svm, svm_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_svm.fit(X_train_svm1, y_train_svm1)\n",
    "\n",
    "print(gs_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.445\n",
      "Precision:  0.431\n",
      "Recall:  0.445\n",
      "F1 Score:  0.438\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(C=1000, gamma = 0.001)\n",
    "clf_svm.fit(X_train_svm1, y_train_svm1)\n",
    "pred_svm_1 = clf_svm.predict(X_test_svm1)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm1, pred_svm_1)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 1 - NB\n",
    "TFIDF reguler, stopword PySastrawi ==> use df_tfidf_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.423\n",
      "Precision:  0.419\n",
      "Recall:  0.423\n",
      "F1 Score:  0.421\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "MultinomialNB(alpha=0.3)\n"
     ]
    }
   ],
   "source": [
    "X_train_nb1, X_test_nb1, y_train_nb1, y_test_nb1 = train_test_split(df_tfidf_def, \n",
    "                                                                    df['label'], \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=23)\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train_nb1, y_train_nb1)\n",
    "pred_nb_1 = clf_nb.predict(X_test_nb1)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb1, pred_nb_1)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "nb_grid_param = [ {'alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "                  {'fit_prior' : [True, False]} ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_nb = GridSearchCV(clf_nb, nb_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_nb.fit(X_train_nb1, y_train_nb1)\n",
    "\n",
    "print(gs_nb.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.445\n",
      "Precision:  0.423\n",
      "Recall:  0.445\n",
      "F1 Score:  0.434\n"
     ]
    }
   ],
   "source": [
    "clf_nb = MultinomialNB(alpha=0.3)\n",
    "clf_nb.fit(X_train_nb1, y_train_nb1)\n",
    "pred_nb_1 = clf_nb.predict(X_test_nb1)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb1, pred_nb_1)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 2 - SVM\n",
    "TFIDF reguler, stopword modifikasi PySastrawi ==> use df_tfidf_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.474\n",
      "Precision:  0.432\n",
      "Recall:  0.474\n",
      "F1 Score:  0.452\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "SVC(C=100, gamma=0.01)\n"
     ]
    }
   ],
   "source": [
    "X_train_svm2, X_test_svm2, y_train_svm2, y_test_svm2 = train_test_split(df_tfidf_mod, \n",
    "                                                                        df['label'], \n",
    "                                                                        test_size=0.2, \n",
    "                                                                        random_state=23)\n",
    "\n",
    "clf_svm = svm.SVC(C=1, kernel='linear')\n",
    "clf_svm.fit(X_train_svm2, y_train_svm2)\n",
    "pred_svm_2 = clf_svm.predict(X_test_svm2)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm2, pred_svm_2)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "svm_grid_param = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001, 'auto'], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_svm = GridSearchCV(clf_svm, svm_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_svm.fit(X_train_svm2, y_train_svm2)\n",
    "\n",
    "print(gs_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.438\n",
      "Precision:  0.43\n",
      "Recall:  0.438\n",
      "F1 Score:  0.434\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(C=100, gamma = 0.01)\n",
    "clf_svm.fit(X_train_svm2, y_train_svm2)\n",
    "pred_svm_2 = clf_svm.predict(X_test_svm2)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm2, pred_svm_2)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 2 - NB\n",
    "TFIDF reguler, stopword modifikasi PySastrawi ==> use df_tfidf_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.401\n",
      "Precision:  0.443\n",
      "Recall:  0.401\n",
      "F1 Score:  0.421\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "MultinomialNB(alpha=0.1)\n"
     ]
    }
   ],
   "source": [
    "X_train_nb2, X_test_nb2, y_train_nb2, y_test_nb2 = train_test_split(df_tfidf_mod, \n",
    "                                                                    df['label'], \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=23)\n",
    "\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train_nb2, y_train_nb2)\n",
    "pred_nb_2 = clf_nb.predict(X_test_nb2)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb2, pred_nb_2)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "nb_grid_param = [ {'alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "                  {'fit_prior' : [True, False]} ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_nb = GridSearchCV(clf_nb, nb_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_nb.fit(X_train_nb2, y_train_nb2)\n",
    "\n",
    "print(gs_nb.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.467\n",
      "Precision:  0.491\n",
      "Recall:  0.467\n",
      "F1 Score:  0.479\n"
     ]
    }
   ],
   "source": [
    "clf_nb = MultinomialNB(alpha=0.1)\n",
    "clf_nb.fit(X_train_nb2, y_train_nb2)\n",
    "pred_nb_2 = clf_nb.predict(X_test_nb2)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb2, pred_nb_2)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 3 - SVM\n",
    "TFIDF reguler, stopword PySastrawi, random over-sampling  ==> df_tfidf_ros_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.799\n",
      "Precision:  0.797\n",
      "Recall:  0.799\n",
      "F1 Score:  0.798\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "SVC(C=10, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "X_train_svm3, X_test_svm3, y_train_svm3, y_test_svm3 = train_test_split(df_tfidf_ros_def, \n",
    "                                                                        tfidf_ros_label_def, \n",
    "                                                                        test_size=0.2, \n",
    "                                                                        random_state=23)\n",
    "clf_svm = svm.SVC(C=1, kernel='linear')\n",
    "clf_svm.fit(X_train_svm3, y_train_svm3)\n",
    "pred_svm_3 = clf_svm.predict(X_test_svm3)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm3, pred_svm_3)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "svm_grid_param = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001, 'auto'], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_svm = GridSearchCV(clf_svm, svm_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_svm.fit(X_train_svm3, y_train_svm3)\n",
    "\n",
    "print(gs_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.839\n",
      "Precision:  0.836\n",
      "Recall:  0.839\n",
      "F1 Score:  0.837\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(C=10, kernel='linear')\n",
    "clf_svm.fit(X_train_svm3, y_train_svm3)\n",
    "pred_svm_3 = clf_svm.predict(X_test_svm3)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm3, pred_svm_3)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 3 - NB\n",
    "TFIDF reguler, stopword PySastrawi, random over-sampling  ==> df_tfidf_ros_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.772\n",
      "Precision:  0.773\n",
      "Recall:  0.772\n",
      "F1 Score:  0.772\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "MultinomialNB(alpha=0.0)\n"
     ]
    }
   ],
   "source": [
    "X_train_nb3, X_test_nb3, y_train_nb3, y_test_nb3 = train_test_split(df_tfidf_ros_def, \n",
    "                                                                    tfidf_ros_label_def, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=23)\n",
    "\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train_nb3, y_train_nb3)\n",
    "pred_nb_3 = clf_nb.predict(X_test_nb3)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb3, pred_nb_3)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "nb_grid_param = [ {'alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "                  {'fit_prior' : [True, False]} ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_nb = GridSearchCV(clf_nb, nb_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_nb.fit(X_train_nb3, y_train_nb3)\n",
    "\n",
    "print(gs_nb.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.815\n",
      "Precision:  0.815\n",
      "Recall:  0.815\n",
      "F1 Score:  0.815\n"
     ]
    }
   ],
   "source": [
    "clf_nb = MultinomialNB(alpha=0.0)\n",
    "clf_nb.fit(X_train_nb3, y_train_nb3)\n",
    "pred_nb_3 = clf_nb.predict(X_test_nb3)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb3, pred_nb_3)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 4 - SVM\n",
    "TFIDF reguler, stopword modifikasi PySastrawi, random over-sampling  ==> df_tfidf_ros_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.819\n",
      "Precision:  0.817\n",
      "Recall:  0.819\n",
      "F1 Score:  0.818\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "SVC(C=10, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "X_train_svm4, X_test_svm4, y_train_svm4, y_test_svm4 = train_test_split(df_tfidf_ros_mod, \n",
    "                                                                        tfidf_ros_label_mod, \n",
    "                                                                        test_size=0.2, \n",
    "                                                                        random_state=23)\n",
    "\n",
    "clf_svm = svm.SVC(C=1, kernel='linear')\n",
    "clf_svm.fit(X_train_svm4, y_train_svm4)\n",
    "pred_svm_4 = clf_svm.predict(X_test_svm4)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm4, pred_svm_4)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "svm_grid_param = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001, 'auto'], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_svm = GridSearchCV(clf_svm, svm_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_svm.fit(X_train_svm4, y_train_svm4)\n",
    "\n",
    "print(gs_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.842\n",
      "Precision:  0.841\n",
      "Recall:  0.842\n",
      "F1 Score:  0.842\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(C=10, kernel='linear')\n",
    "clf_svm.fit(X_train_svm4, y_train_svm4)\n",
    "pred_svm_4 = clf_svm.predict(X_test_svm4)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm4, pred_svm_4)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 4 - NB\n",
    "TFIDF reguler, stopword modifikasi PySastrawi, random over-sampling  ==> df_tfidf_ros_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.782\n",
      "Precision:  0.78\n",
      "Recall:  0.782\n",
      "F1 Score:  0.781\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "MultinomialNB(alpha=0.0)\n"
     ]
    }
   ],
   "source": [
    "X_train_nbb, X_test_nbb, y_train_nbb, y_test_nbb = train_test_split(df_tfidf_ros_mod, \n",
    "                                                                    tfidf_ros_label_mod, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=23)\n",
    "\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train_nbb, y_train_nbb)\n",
    "pred_nb_best = clf_nb.predict(X_test_nbb)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nbb, pred_nb_best)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "nb_grid_param = [ {'alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "                  {'fit_prior' : [True, False]} ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_nb = GridSearchCV(clf_nb, nb_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_nb.fit(X_train_nbb, y_train_nbb)\n",
    "\n",
    "print(gs_nb.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.829\n",
      "Precision:  0.828\n",
      "Recall:  0.829\n",
      "F1 Score:  0.829\n"
     ]
    }
   ],
   "source": [
    "clf_nb = MultinomialNB(alpha=0.0)\n",
    "clf_nb.fit(X_train_nbb, y_train_nbb)\n",
    "pred_nb_best = clf_nb.predict(X_test_nbb)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nbb, pred_nb_best)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 5 - SVM\n",
    "TFPOS-IDF, stopword PySastrawi ==> use df_tfposidf_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.438\n",
      "Precision:  0.423\n",
      "Recall:  0.438\n",
      "F1 Score:  0.43\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "SVC(C=1, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "X_train_svm5, X_test_svm5, y_train_svm5, y_test_svm5 = train_test_split(df_tfposidf_def, \n",
    "                                                                        df['label'], \n",
    "                                                                        test_size=0.2, \n",
    "                                                                        random_state=23)\n",
    "\n",
    "clf_svm = svm.SVC(C=1, kernel='linear')\n",
    "clf_svm.fit(X_train_svm5, y_train_svm5)\n",
    "pred_svm_5 = clf_svm.predict(X_test_svm5)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm5, pred_svm_5)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "svm_grid_param = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001, 'auto'], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_svm = GridSearchCV(clf_svm, svm_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_svm.fit(X_train_svm5, y_train_svm5)\n",
    "\n",
    "print(gs_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.438\n",
      "Precision:  0.423\n",
      "Recall:  0.438\n",
      "F1 Score:  0.43\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(C=1, kernel='linear')\n",
    "clf_svm.fit(X_train_svm5, y_train_svm5)\n",
    "pred_svm_5 = clf_svm.predict(X_test_svm5)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm5, pred_svm_5)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 5 - NB\n",
    "TFPOS-IDF, stopword PySastrawi ==> use df_tfposidf_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.431\n",
      "Precision:  0.5\n",
      "Recall:  0.431\n",
      "F1 Score:  0.463\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "MultinomialNB(alpha=0.2)\n"
     ]
    }
   ],
   "source": [
    "X_train_nb5, X_test_nb5, y_train_nb5, y_test_nb5 = train_test_split(df_tfposidf_def,\n",
    "                                                                    df['label'], \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=23)\n",
    "\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train_nb5, y_train_nb5)\n",
    "pred_nb_5 = clf_nb.predict(X_test_nb5)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb5, pred_nb_5)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "nb_grid_param = [ {'alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "                  {'fit_prior' : [True, False]} ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_nb = GridSearchCV(clf_nb, nb_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_nb.fit(X_train_nb5, y_train_nb5)\n",
    "\n",
    "print(gs_nb.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.453\n",
      "Precision:  0.448\n",
      "Recall:  0.453\n",
      "F1 Score:  0.45\n"
     ]
    }
   ],
   "source": [
    "clf_nb = MultinomialNB(alpha=0.2)\n",
    "clf_nb.fit(X_train_nb5, y_train_nb5)\n",
    "pred_nb_5 = clf_nb.predict(X_test_nb5)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb5, pred_nb_5)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 6 - SVM\n",
    "TFPOS-IDF, stopword modifikasi PySastrawi ==> df_tfposidf_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.445\n",
      "Precision:  0.417\n",
      "Recall:  0.445\n",
      "F1 Score:  0.431\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "SVC(C=1000, gamma='auto')\n"
     ]
    }
   ],
   "source": [
    "X_train_svm6, X_test_svm6, y_train_svm6, y_test_svm6 = train_test_split(df_tfposidf_mod, \n",
    "                                                                        df['label'], \n",
    "                                                                        test_size=0.2, \n",
    "                                                                        random_state=23)\n",
    "\n",
    "clf_svm = svm.SVC(C=1, kernel='linear')\n",
    "clf_svm.fit(X_train_svm6, y_train_svm6)\n",
    "pred_svm6 = clf_svm.predict(X_test_svm6)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm6, pred_svm6)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "svm_grid_param = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001, 'auto'], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_svm = GridSearchCV(clf_svm, svm_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_svm.fit(X_train_svm6, y_train_svm6)\n",
    "\n",
    "print(gs_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.504\n",
      "Precision:  0.478\n",
      "Recall:  0.504\n",
      "F1 Score:  0.491\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(C=1000, gamma='auto')\n",
    "clf_svm.fit(X_train_svm6, y_train_svm6)\n",
    "pred_svm6 = clf_svm.predict(X_test_svm6)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm6, pred_svm6)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 6 - NB\n",
    "TFPOS-IDF, stopword modifikasi PySastrawi ==> df_tfposidf_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.401\n",
      "Precision:  0.463\n",
      "Recall:  0.401\n",
      "F1 Score:  0.43\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "MultinomialNB(alpha=0.1)\n"
     ]
    }
   ],
   "source": [
    "X_train_nb6, X_test_nb6, y_train_nb6, y_test_nb6 = train_test_split(df_tfposidf_mod, \n",
    "                                                                    df['label'], \n",
    "                                                                    test_size=0.2,\n",
    "                                                                    random_state=23)\n",
    "\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train_nb6, y_train_nb6)\n",
    "pred_nb6 = clf_nb.predict(X_test_nb6)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb6, pred_nb6)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "nb_grid_param = [ {'alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "                  {'fit_prior' : [True, False]} ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_nb = GridSearchCV(clf_nb, nb_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_nb.fit(X_train_nb6, y_train_nb6)\n",
    "\n",
    "print(gs_nb.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.467\n",
      "Precision:  0.477\n",
      "Recall:  0.467\n",
      "F1 Score:  0.472\n"
     ]
    }
   ],
   "source": [
    "clf_nb = MultinomialNB(alpha=0.1)\n",
    "clf_nb.fit(X_train_nb6, y_train_nb6)\n",
    "pred_nb6 = clf_nb.predict(X_test_nb6)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb6, pred_nb6)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 7 - SVM\n",
    "TFPOS-IDF, stopword PySastrawi, random over-sampling ==> df_tfposidf_ros_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.815\n",
      "Precision:  0.813\n",
      "Recall:  0.815\n",
      "F1 Score:  0.814\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "SVC(C=10, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "X_train_svmb, X_test_svmb, y_train_svmb, y_test_svmb = train_test_split(df_tfposidf_ros_def, \n",
    "                                                                        ros_tfposidf_label_def, \n",
    "                                                                        test_size=0.2, \n",
    "                                                                        random_state=23)\n",
    "\n",
    "clf_svm = svm.SVC(C=1, kernel='linear')\n",
    "clf_svm.fit(X_train_svmb, y_train_svmb)\n",
    "pred_svm_best = clf_svm.predict(X_test_svmb)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svmb, pred_svm_best)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "svm_grid_param = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001, 'auto'], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_svm = GridSearchCV(clf_svm, svm_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_svm.fit(X_train_svmb, y_train_svmb)\n",
    "\n",
    "print(gs_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.836\n",
      "Precision:  0.836\n",
      "Recall:  0.836\n",
      "F1 Score:  0.836\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(C=10, kernel='linear')\n",
    "clf_svm.fit(X_train_svmb, y_train_svmb)\n",
    "pred_svm_best = clf_svm.predict(X_test_svmb)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svmb, pred_svm_best)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 7 - NB\n",
    "TFPOS-IDF, stopword PySastrawi, random over-sampling ==> df_tfposidf_ros_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.735\n",
      "Precision:  0.73\n",
      "Recall:  0.735\n",
      "F1 Score:  0.732\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "MultinomialNB(alpha=0.0)\n"
     ]
    }
   ],
   "source": [
    "X_train_nb7, X_test_nb7, y_train_nb7, y_test_nb7 = train_test_split(df_tfposidf_ros_def, \n",
    "                                                                    ros_tfposidf_label_def, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=23)\n",
    "\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train_nb7, y_train_nb7)\n",
    "pred_nb7 = clf_nb.predict(X_test_nb7)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb7, pred_nb7)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "nb_grid_param = [ {'alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "                  {'fit_prior' : [True, False]} ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_nb = GridSearchCV(clf_nb, nb_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_nb.fit(X_train_nb7, y_train_nb7)\n",
    "\n",
    "print(gs_nb.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.795\n",
      "Precision:  0.79\n",
      "Recall:  0.795\n",
      "F1 Score:  0.793\n"
     ]
    }
   ],
   "source": [
    "clf_nb = MultinomialNB(alpha=0.0)\n",
    "clf_nb.fit(X_train_nb7, y_train_nb7)\n",
    "pred_nb7 = clf_nb.predict(X_test_nb7)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb7, pred_nb7)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 8 - SVM\n",
    "TFPOS-IDF, stopword modifikasi PySastrawi, random over-sampling ==> df_tfposidf_ros_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.826\n",
      "Precision:  0.824\n",
      "Recall:  0.826\n",
      "F1 Score:  0.825\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "SVC(C=10, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "X_train_svm8, X_test_svm8, y_train_svm8, y_test_svm8 = train_test_split(df_tfposidf_ros_mod, \n",
    "                                                                        ros_tfposidf_label_mod, \n",
    "                                                                        test_size=0.2, \n",
    "                                                                        random_state=23)\n",
    "\n",
    "clf_svm = svm.SVC(C=1, kernel='linear')\n",
    "clf_svm.fit(X_train_svm8, y_train_svm8)\n",
    "pred_svm8 = clf_svm.predict(X_test_svm8)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm8, pred_svm8)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "svm_grid_param = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001, 'auto'], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_svm = GridSearchCV(clf_svm, svm_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_svm.fit(X_train_svm8, y_train_svm8)\n",
    "\n",
    "print(gs_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.846\n",
      "Precision:  0.846\n",
      "Recall:  0.846\n",
      "F1 Score:  0.846\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(C=10, kernel='linear')\n",
    "clf_svm.fit(X_train_svm8, y_train_svm8)\n",
    "pred_svm8 = clf_svm.predict(X_test_svm8)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_svm8, pred_svm8)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario 8 - NB\n",
    "TFPOS-IDF, stopword modifikasi PySastrawi, random over-sampling ==> df_tfposidf_ros_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.752\n",
      "Precision:  0.744\n",
      "Recall:  0.752\n",
      "F1 Score:  0.748\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "MultinomialNB(alpha=0.0)\n"
     ]
    }
   ],
   "source": [
    "X_train_nb8, X_test_nb8, y_train_nb8, y_test_nb8 = train_test_split(df_tfposidf_ros_mod, \n",
    "                                                                    ros_tfposidf_label_mod, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=23)\n",
    "\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train_nb8, y_train_nb8)\n",
    "pred_nb8 = clf_nb.predict(X_test_nb8)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb8, pred_nb8)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "nb_grid_param = [ {'alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "                  {'fit_prior' : [True, False]} ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_nb = GridSearchCV(clf_nb, nb_grid_param, cv = 5, verbose = 3, scoring='f1_micro', n_jobs = -2)\n",
    "gs_nb.fit(X_train_nb8, y_train_nb8)\n",
    "\n",
    "print(gs_nb.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.812\n",
      "Precision:  0.809\n",
      "Recall:  0.812\n",
      "F1 Score:  0.81\n"
     ]
    }
   ],
   "source": [
    "clf_nb = MultinomialNB(alpha=0.0)\n",
    "clf_nb.fit(X_train_nb8, y_train_nb8)\n",
    "pred_nb8 = clf_nb.predict(X_test_nb8)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test_nb8, pred_nb8)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"F1 Score: \", round(f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_false_idx(predicted, actual, df):\n",
    "    index = []\n",
    "    prediction = []\n",
    "    for i in range(len(predicted)):\n",
    "        temp = []\n",
    "        if predicted[i] != actual[i]:\n",
    "            index.append(df.index[i])\n",
    "            temp.append(predicted[i])\n",
    "            temp.append(actual[i])\n",
    "            prediction.append(temp)\n",
    "    return index, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_idx(false_index, df_resample, df):\n",
    "    real = []\n",
    "    for i in range(len(false_index)):\n",
    "        fidx = false_index[i]\n",
    "        holder = df_resample.iloc[fidx].tolist()\n",
    "        for j in range(df.shape[0]):\n",
    "            if holder == df.iloc[j].tolist():\n",
    "                real.append(j)\n",
    "                break\n",
    "    return real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_summary(real_index, df, predicted):\n",
    "    subject_summary = []\n",
    "    subjects = []\n",
    "    \n",
    "    for i in range(len(real_index)):\n",
    "        subjects.append(df.subject.iloc[real_index[i]])\n",
    "        \n",
    "    checked = []\n",
    "    for i in range(len(subjects)):\n",
    "        temp = []\n",
    "        if subjects[i] not in checked:\n",
    "            count = 0\n",
    "            temp.append(subjects[i])\n",
    "            checked.append(subjects[i])\n",
    "            for j in range(len(subjects)):\n",
    "                if subjects[i] == subjects[j]:\n",
    "                    count += 1\n",
    "            temp.append(count)\n",
    "        if temp:\n",
    "            subject_summary.append(temp)\n",
    "    return subject_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_detail(real_index, df, predicted):\n",
    "    result = []\n",
    "    \n",
    "    for i in range(len(real_index)):\n",
    "        temp = []\n",
    "        temp.append(df.subject.iloc[real_index[i]])\n",
    "        temp.append(df.label.iloc[real_index[i]])\n",
    "        temp.append(predicted[i])\n",
    "        result.append(temp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_false_count(prediction):\n",
    "    result = []\n",
    "    checked = []\n",
    "    for i in range(len(prediction)):\n",
    "        temp = []\n",
    "        holder = prediction[i]\n",
    "        if holder[1] not in checked:\n",
    "            checked.append(holder[1])\n",
    "            count = 0\n",
    "            for j in range(len(prediction)):\n",
    "                holder_2 = prediction[j]\n",
    "                if holder[1] == holder_2[1]:\n",
    "                    count += 1\n",
    "            temp.append(holder[1])\n",
    "            temp.append(count)\n",
    "        if temp:\n",
    "            result.append(temp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_svm = pred_svm_best.tolist()\n",
    "actual_svm = y_test_svmb.label.tolist()\n",
    "\n",
    "# ambil liat yang salah prediksi di index mana aja\n",
    "false_index_svm, prediction_svm = get_false_idx(predicted_svm, actual_svm, y_test_svmb)\n",
    "\n",
    "# ambil index asli di dataframe sebelum resampling\n",
    "real_idx_svm = get_real_idx(false_index_svm, df_tfposidf_ros_mod, df_tfposidf_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C3', 21], ['C2', 16], ['C4', 8], ['C1', 4]]\n"
     ]
    }
   ],
   "source": [
    "# hitung jumlah salah prediksi\n",
    "false_count_svm = sorted(get_false_count(prediction_svm), key=lambda l:l[1], reverse=True)\n",
    "print(false_count_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bahasa indonesia', 22], ['matematika', 18], ['ipa', 9]]\n"
     ]
    }
   ],
   "source": [
    "# summary dari hasil salah prediksi per subject\n",
    "subject_sum_svm = sorted(get_subject_summary(real_idx_svm, df, predicted_svm), key=lambda l:l[1], reverse=True)\n",
    "print(subject_sum_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C2</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C4</td>\n",
       "      <td>C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C2</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C4</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C2</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C2</td>\n",
       "      <td>C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C2</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ipa</td>\n",
       "      <td>C4</td>\n",
       "      <td>C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ipa</td>\n",
       "      <td>C3</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ipa</td>\n",
       "      <td>C3</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ipa</td>\n",
       "      <td>C4</td>\n",
       "      <td>C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ipa</td>\n",
       "      <td>C2</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ipa</td>\n",
       "      <td>C4</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ipa</td>\n",
       "      <td>C3</td>\n",
       "      <td>C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ipa</td>\n",
       "      <td>C1</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ipa</td>\n",
       "      <td>C4</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C4</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C2</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C2</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C2</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C2</td>\n",
       "      <td>C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C1</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C2</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C2</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C1</td>\n",
       "      <td>C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C2</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C1</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C2</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C2</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C2</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C4</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             subject actual predicted\n",
       "0         matematika     C3        C2\n",
       "1         matematika     C2        C3\n",
       "2         matematika     C3        C2\n",
       "3         matematika     C4        C5\n",
       "4         matematika     C3        C1\n",
       "5         matematika     C3        C5\n",
       "6         matematika     C3        C4\n",
       "7         matematika     C3        C4\n",
       "8         matematika     C3        C5\n",
       "9         matematika     C2        C2\n",
       "10        matematika     C3        C4\n",
       "11        matematika     C3        C4\n",
       "12        matematika     C4        C2\n",
       "13        matematika     C3        C1\n",
       "14        matematika     C2        C3\n",
       "15        matematika     C2        C5\n",
       "16        matematika     C3        C5\n",
       "17        matematika     C2        C1\n",
       "18               ipa     C4        C5\n",
       "19               ipa     C3        C3\n",
       "20               ipa     C3        C4\n",
       "21               ipa     C4        C6\n",
       "22               ipa     C2        C1\n",
       "23               ipa     C4        C3\n",
       "24               ipa     C3        C5\n",
       "25               ipa     C1        C3\n",
       "26               ipa     C4        C3\n",
       "27  bahasa indonesia     C3        C6\n",
       "28  bahasa indonesia     C3        C3\n",
       "29  bahasa indonesia     C4        C2\n",
       "30  bahasa indonesia     C2        C1\n",
       "31  bahasa indonesia     C2        C4\n",
       "32  bahasa indonesia     C2        C3\n",
       "33  bahasa indonesia     C2        C6\n",
       "34  bahasa indonesia     C1        C1\n",
       "35  bahasa indonesia     C3        C4\n",
       "36  bahasa indonesia     C2        C1\n",
       "37  bahasa indonesia     C2        C2\n",
       "38  bahasa indonesia     C1        C5\n",
       "39  bahasa indonesia     C2        C1\n",
       "40  bahasa indonesia     C3        C3\n",
       "41  bahasa indonesia     C1        C4\n",
       "42  bahasa indonesia     C2        C2\n",
       "43  bahasa indonesia     C3        C6\n",
       "44  bahasa indonesia     C3        C2\n",
       "45  bahasa indonesia     C2        C2\n",
       "46  bahasa indonesia     C2        C4\n",
       "47  bahasa indonesia     C4        C3\n",
       "48  bahasa indonesia     C3        C5"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ambil subject detail\n",
    "df_subject_detail_svm = pd.DataFrame(sorted(get_subject_detail(real_idx_svm, df, predicted_svm), \n",
    "                                            key=lambda l:l[0], \n",
    "                                            reverse=True), \n",
    "                                    columns = ['subject', 'actual', 'predicted'])\n",
    "\n",
    "df_subject_detail_svm.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Best Model (No resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_svm_nr = pred_svm6.tolist()\n",
    "actual_svm_nr = y_test_svm6.tolist()\n",
    "\n",
    "# ambil liat yang salah prediksi di index mana aja\n",
    "false_index_svm_nr, prediction_svm_nr = get_false_idx(predicted_svm_nr, actual_svm_nr, y_test_svm6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hitung jumlah salah prediksi\n",
    "false_count_svm_nr = sorted(get_false_count(prediction_svm_nr), key=lambda l:l[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ipa', 27], ['bahasa indonesia', 26], ['matematika', 15]]\n"
     ]
    }
   ],
   "source": [
    "# summary dari hasil salah prediksi per subject\n",
    "subject_sum_svm_nr = sorted(get_subject_summary(false_index_svm_nr, df, predicted_svm_nr), key=lambda l:l[1], reverse=True)\n",
    "print(subject_sum_svm_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C6</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C4</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C5</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C6</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C1</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C6</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C4</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C1</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             subject actual predicted\n",
       "0         matematika     C6        C4\n",
       "1         matematika     C3        C4\n",
       "2         matematika     C4        C2\n",
       "3         matematika     C5        C1\n",
       "4         matematika     C6        C2\n",
       "..               ...    ...       ...\n",
       "63  bahasa indonesia     C1        C3\n",
       "64  bahasa indonesia     C6        C3\n",
       "65  bahasa indonesia     C3        C4\n",
       "66  bahasa indonesia     C4        C1\n",
       "67  bahasa indonesia     C1        C3\n",
       "\n",
       "[68 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ambil subject detail\n",
    "df_subject_detail_svm_nr = pd.DataFrame(sorted(get_subject_detail(false_index_svm_nr, df, predicted_svm_nr), \n",
    "                                            key=lambda l:l[0], \n",
    "                                            reverse=True), \n",
    "                                    columns = ['subject', 'actual', 'predicted'])\n",
    "\n",
    "df_subject_detail_svm_nr.head(68)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_nb = pred_nb_best.tolist()\n",
    "actual_nb = y_test_nbb.label.tolist()\n",
    "\n",
    "# ambil liat yang salah prediksi di index mana aja\n",
    "false_index_nb, prediction_nb = get_false_idx(predicted_nb, actual_nb, y_test_nbb)\n",
    "\n",
    "# ambil index asli di dataframe sebelum resampling\n",
    "real_idx_nb = get_real_idx(false_index_nb, df_tfidf_ros_mod, df_tfidf_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C3', 21], ['C2', 14], ['C4', 9], ['C1', 5], ['C6', 2]]\n"
     ]
    }
   ],
   "source": [
    "# hitung jumlah salah prediksi\n",
    "false_count_nb = sorted(get_false_count(prediction_nb), key=lambda l:l[1], reverse=True)\n",
    "print(false_count_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bahasa indonesia', 26], ['matematika', 16], ['ipa', 9]]\n"
     ]
    }
   ],
   "source": [
    "# summary dari hasil salah prediksi per subject\n",
    "subject_sum_nb = sorted(get_subject_summary(real_idx_nb, df, predicted_nb), key=lambda l:l[1], reverse=True)\n",
    "print(subject_sum_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C4</td>\n",
       "      <td>C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C2</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C2</td>\n",
       "      <td>C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C4</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C2</td>\n",
       "      <td>C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C4</td>\n",
       "      <td>C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C2</td>\n",
       "      <td>C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C2</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C2</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ipa</td>\n",
       "      <td>C3</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ipa</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ipa</td>\n",
       "      <td>C4</td>\n",
       "      <td>C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ipa</td>\n",
       "      <td>C6</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ipa</td>\n",
       "      <td>C6</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ipa</td>\n",
       "      <td>C2</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ipa</td>\n",
       "      <td>C4</td>\n",
       "      <td>C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ipa</td>\n",
       "      <td>C3</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ipa</td>\n",
       "      <td>C3</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C4</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C2</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C4</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C4</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C2</td>\n",
       "      <td>C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C1</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C1</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C2</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C2</td>\n",
       "      <td>C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C1</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C2</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C1</td>\n",
       "      <td>C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C2</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C2</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C4</td>\n",
       "      <td>C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C1</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             subject actual predicted\n",
       "0         matematika     C4        C5\n",
       "1         matematika     C3        C2\n",
       "2         matematika     C2        C3\n",
       "3         matematika     C3        C3\n",
       "4         matematika     C2        C6\n",
       "5         matematika     C4        C1\n",
       "6         matematika     C3        C3\n",
       "7         matematika     C3        C4\n",
       "8         matematika     C3        C4\n",
       "9         matematika     C3        C6\n",
       "10        matematika     C3        C2\n",
       "11        matematika     C2        C5\n",
       "12        matematika     C4        C5\n",
       "13        matematika     C2        C5\n",
       "14        matematika     C2        C3\n",
       "15        matematika     C2        C3\n",
       "16               ipa     C3        C4\n",
       "17               ipa     C3        C2\n",
       "18               ipa     C4        C5\n",
       "19               ipa     C6        C1\n",
       "20               ipa     C6        C4\n",
       "21               ipa     C2        C4\n",
       "22               ipa     C4        C6\n",
       "23               ipa     C3        C1\n",
       "24               ipa     C3        C4\n",
       "25  bahasa indonesia     C3        C6\n",
       "26  bahasa indonesia     C3        C4\n",
       "27  bahasa indonesia     C4        C2\n",
       "28  bahasa indonesia     C2        C1\n",
       "29  bahasa indonesia     C4        C2\n",
       "30  bahasa indonesia     C4        C3\n",
       "31  bahasa indonesia     C2        C5\n",
       "32  bahasa indonesia     C1        C1\n",
       "33  bahasa indonesia     C3        C5\n",
       "34  bahasa indonesia     C1        C4\n",
       "35  bahasa indonesia     C2        C2\n",
       "36  bahasa indonesia     C2        C5\n",
       "37  bahasa indonesia     C1        C3\n",
       "38  bahasa indonesia     C2        C1\n",
       "39  bahasa indonesia     C3        C2\n",
       "40  bahasa indonesia     C1        C6\n",
       "41  bahasa indonesia     C2        C3\n",
       "42  bahasa indonesia     C3        C1\n",
       "43  bahasa indonesia     C3        C1\n",
       "44  bahasa indonesia     C3        C2\n",
       "45  bahasa indonesia     C3        C2\n",
       "46  bahasa indonesia     C3        C1\n",
       "47  bahasa indonesia     C2        C3\n",
       "48  bahasa indonesia     C4        C5\n",
       "49  bahasa indonesia     C3        C2\n",
       "50  bahasa indonesia     C1        C2"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ambil subject detail\n",
    "df_subject_detail_nb = pd.DataFrame(sorted(get_subject_detail(real_idx_nb, df, predicted_nb), \n",
    "                                            key=lambda l:l[0], \n",
    "                                            reverse=True), \n",
    "                                    columns = ['subject', 'actual', 'predicted'])\n",
    "\n",
    "df_subject_detail_nb.head(52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB Best Model (No resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_nb_nr = pred_nb_2.tolist()\n",
    "actual_nb_nr = y_test_nb2.tolist()\n",
    "\n",
    "# ambil liat yang salah prediksi di index mana aja\n",
    "false_index_nb_nr, prediction_nb_nr = get_false_idx(predicted_nb_nr, actual_nb_nr, y_test_nb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C1', 20], ['C3', 20], ['C4', 14], ['C6', 8], ['C2', 7], ['C5', 4]]\n"
     ]
    }
   ],
   "source": [
    "# hitung jumlah salah prediksi\n",
    "false_count_nb_nr = sorted(get_false_count(prediction_nb_nr), key=lambda l:l[1], reverse=True)\n",
    "print(false_count_nb_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bahasa indonesia', 29], ['ipa', 27], ['matematika', 17]]\n"
     ]
    }
   ],
   "source": [
    "# summary dari hasil salah prediksi per subject\n",
    "subject_sum_nb_nr = sorted(get_subject_summary(false_index_nb_nr, df, predicted_nb_nr), key=lambda l:l[1], reverse=True)\n",
    "print(subject_sum_nb_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C6</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C3</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C4</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C1</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>matematika</td>\n",
       "      <td>C5</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C6</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C1</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C4</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>bahasa indonesia</td>\n",
       "      <td>C1</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             subject actual predicted\n",
       "0         matematika     C6        C3\n",
       "1         matematika     C3        C1\n",
       "2         matematika     C4        C3\n",
       "3         matematika     C1        C3\n",
       "4         matematika     C5        C4\n",
       "..               ...    ...       ...\n",
       "68  bahasa indonesia     C6        C1\n",
       "69  bahasa indonesia     C3        C2\n",
       "70  bahasa indonesia     C1        C2\n",
       "71  bahasa indonesia     C4        C3\n",
       "72  bahasa indonesia     C1        C1\n",
       "\n",
       "[73 rows x 3 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ambil subject detail\n",
    "df_subject_detail_nb_nr = pd.DataFrame(sorted(get_subject_detail(false_index_nb_nr, df, predicted_nb_nr), \n",
    "                                            key=lambda l:l[0], \n",
    "                                            reverse=True), \n",
    "                                    columns = ['subject', 'actual', 'predicted'])\n",
    "\n",
    "df_subject_detail_nb_nr.head(73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
