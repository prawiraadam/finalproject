{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data\\data_test.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Num of questions')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "data = df['Label'].value_counts().sort_index(ascending=True)\n",
    "points = data.index\n",
    "freq = data.values\n",
    "\n",
    "ax.bar(points, freq)\n",
    "ax.set_title('Exam questions difficulty distribution')\n",
    "ax.set_xlabel('Cognitive level')\n",
    "ax.set_ylabel('Num of questions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casefolding from column 'question'\n",
    "df.question = df.question.str.lower()\n",
    "\n",
    "# Remove punctuation from column 'question'\n",
    "df['punc_remove'] = df.question.str.replace('[^\\w\\s]', ' ')\n",
    "\n",
    "# Stemming\n",
    "stem_factory = StemmerFactory()\n",
    "stemmer = stem_factory.create_stemmer()\n",
    "df['stemmed'] = df.apply(lambda row: stemmer.stem(row['punc_remove']), axis = 1)\n",
    "\n",
    "# Remove stopwords\n",
    "stopword_factory = StopWordRemoverFactory()\n",
    "stopword = stopword_factory.create_stop_word_remover()\n",
    "df['sw_remove'] = df.apply(lambda row: stopword.remove(row['stemmed']), axis = 1)\n",
    "\n",
    "# Tokenization\n",
    "# df['tokenized'] = df.apply(lambda row: nltk.word_tokenize(row['sw_remove']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow(wordlist, df):\n",
    "    # check if word exist in bow\n",
    "    bow = {}\n",
    "    for index, row in df.iterrows():\n",
    "        txt = row['stemmed'].split()\n",
    "        for i in range(len(txt)):\n",
    "            if txt[i] in bow:\n",
    "                bow[txt[i]] += 1\n",
    "            else:\n",
    "                bow[txt[i]] = 1\n",
    "            \n",
    "    # sort bow by value\n",
    "    sorted_bow = {}\n",
    "    for i in sorted(bow.items(), key=lambda x: x[1], reverse=True):\n",
    "        sorted_bow[i[0]] = i[1]\n",
    "        \n",
    "    return sorted_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(term_doc_matrix):\n",
    "    # Convert sparse matrix to list\n",
    "    temp = []\n",
    "    for i in range(term_doc_matrix.shape[0]):\n",
    "        temp.append(term_doc_matrix[i].toarray().tolist())\n",
    "\n",
    "    # Flatten list\n",
    "    res = list(chain.from_iterable(temp))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postag_weighting(tfidf, term_dict):\n",
    "    # Fungsi untuk weighting tfidf based on POS Tag. Weight optimal ada di paper\n",
    "    \n",
    "    # cek di list TF-IDF, mana yg ga 0\n",
    "    # indeks di list TF-IDF dicocokin sama indeks di term_dictionary\n",
    "    # ambil nilai weight dari dict\n",
    "    result = []\n",
    "    \n",
    "    for i in range(len(tfidf)):\n",
    "        elem = []\n",
    "        for j in range(len(tfidf[i])):\n",
    "            if tfidf[i][j] > 0:\n",
    "                temp = list(term_dict.values())[j]\n",
    "                weight = 1\n",
    "#                 Uncomment below if POS tagger is available\n",
    "#                 if temp == 'N':\n",
    "#                     weight = 3\n",
    "#                 elif temp == 'ADJ':\n",
    "#                     weight = 2\n",
    "#                 else:\n",
    "#                     weight = 1\n",
    "            elem.append(tfidf[i][j] * weight)\n",
    "        result.append(elem)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(test, pred):\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(test, pred)\n",
    "    precision = metrics.precision_score(test, pred, average='weighted')\n",
    "    recall = metrics.recall_score(test, pred, average='weighted')\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>543</th>\n",
       "      <th>544</th>\n",
       "      <th>545</th>\n",
       "      <th>546</th>\n",
       "      <th>547</th>\n",
       "      <th>548</th>\n",
       "      <th>549</th>\n",
       "      <th>550</th>\n",
       "      <th>551</th>\n",
       "      <th>552</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.192530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 553 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5         6    7    8    9    ...  543  544  \\\n",
       "166  0.0  0.0  0.0  0.0  0.0  0.0  0.183273  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "167  0.0  0.0  0.0  0.0  0.0  0.0  0.192530  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "168  0.0  0.0  0.0  0.0  0.0  0.0  0.209466  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "169  0.0  0.0  0.0  0.0  0.0  0.0  0.209522  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "170  0.0  0.0  0.0  0.0  0.0  0.0  0.204318  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "     545  546  547  548       549  550  551  552  \n",
       "166  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  \n",
       "167  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  \n",
       "168  0.0  0.0  0.0  0.0  0.186082  0.0  0.0  0.0  \n",
       "169  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  \n",
       "170  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 553 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "\n",
    "# Buat ngitung nilai TF-IDF dari tiap term\n",
    "vectorizer = TfidfVectorizer()\n",
    "term_doc_matrix = vectorizer.fit_transform(df['stemmed'])\n",
    "\n",
    "# Daftar kata yang dipake di corpus\n",
    "# TODO: Bikin list isinya POSTag, urutan sama kaya vocabulary\n",
    "#       Gabungin 2 list itu jadi 1 dict\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "\n",
    "# Convert hasil fit_transform dari sparse matrix ke list\n",
    "tfidf = flatten(term_doc_matrix)\n",
    "\n",
    "# Apply weighting untuk TF-IDF\n",
    "# tfpos_idf = postag_weighting(tfidf, term_dict)\n",
    "\n",
    "# Convert TFPOS-IDF ke dataframe\n",
    "# Ini yang dipake buat model\n",
    "df_dataset = pd.DataFrame(tfidf)\n",
    "df_dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_dataset, df['Label'], test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.45714285714285713\n",
      "Precision:  0.5932234432234432\n",
      "Recall:  0.45714285714285713\n",
      "F1 Score:  0.5163681654004234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Coding\\Software\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "clf_svm.fit(X_train, y_train)\n",
    "pred_svm = clf_svm.predict(X_test)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test, pred_svm)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Coding\\Software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] .................. C=1, kernel=linear, score=0.536, total=   0.0s\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] .................. C=1, kernel=linear, score=0.519, total=   0.0s\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] .................. C=1, kernel=linear, score=0.444, total=   0.0s\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] .................. C=1, kernel=linear, score=0.593, total=   0.0s\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] .................. C=1, kernel=linear, score=0.481, total=   0.0s\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] ................. C=10, kernel=linear, score=0.536, total=   0.0s\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] ................. C=10, kernel=linear, score=0.481, total=   0.0s\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] ................. C=10, kernel=linear, score=0.444, total=   0.0s\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] ................. C=10, kernel=linear, score=0.593, total=   0.0s\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] ................. C=10, kernel=linear, score=0.593, total=   0.0s\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ................ C=100, kernel=linear, score=0.536, total=   0.0s\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ................ C=100, kernel=linear, score=0.481, total=   0.0s\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ................ C=100, kernel=linear, score=0.444, total=   0.0s\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ................ C=100, kernel=linear, score=0.593, total=   0.0s\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ................ C=100, kernel=linear, score=0.556, total=   0.0s\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] ............... C=1000, kernel=linear, score=0.536, total=   0.0s\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] ............... C=1000, kernel=linear, score=0.481, total=   0.0s\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] ............... C=1000, kernel=linear, score=0.444, total=   0.0s\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] ............... C=1000, kernel=linear, score=0.593, total=   0.0s\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] ............... C=1000, kernel=linear, score=0.556, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.321, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.321, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.321, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.321, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.321, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.321, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.536, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.481, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.481, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.556, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.593, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.321, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.333, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.333, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(kernel='linear'),\n",
       "             param_grid=[{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
       "                         {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001],\n",
       "                          'kernel': ['rbf']}],\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svm_grid_param = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_svm = GridSearchCV(clf_svm, svm_grid_param, cv = 5, verbose = 3)\n",
    "\n",
    "gs_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "print(gs_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5142857142857142\n",
      "Precision:  0.6460317460317461\n",
      "Recall:  0.5142857142857142\n",
      "F1 Score:  0.5726793042798515\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(C=10, kernel='linear')\n",
    "clf_svm.fit(X_train, y_train)\n",
    "pred_svm = clf_svm.predict(X_test)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test, pred_svm)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4\n",
      "Precision:  0.5471916971916971\n",
      "Recall:  0.4\n",
      "F1 Score:  0.462159200773445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Coding\\Software\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train, y_train)\n",
    "pred_nb = clf_nb.predict(X_test)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test, pred_nb)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] alpha=0.1 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Coding\\Software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................... alpha=0.1, score=0.500, total=   0.0s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ........................... alpha=0.1, score=0.556, total=   0.0s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ........................... alpha=0.1, score=0.407, total=   0.0s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ........................... alpha=0.1, score=0.519, total=   0.0s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ........................... alpha=0.1, score=0.556, total=   0.0s\n",
      "[CV] alpha=0.2 .......................................................\n",
      "[CV] ........................... alpha=0.2, score=0.536, total=   0.0s\n",
      "[CV] alpha=0.2 .......................................................\n",
      "[CV] ........................... alpha=0.2, score=0.556, total=   0.0s\n",
      "[CV] alpha=0.2 .......................................................\n",
      "[CV] ........................... alpha=0.2, score=0.407, total=   0.0s\n",
      "[CV] alpha=0.2 .......................................................\n",
      "[CV] ........................... alpha=0.2, score=0.519, total=   0.0s\n",
      "[CV] alpha=0.2 .......................................................\n",
      "[CV] ........................... alpha=0.2, score=0.556, total=   0.0s\n",
      "[CV] alpha=0.3 .......................................................\n",
      "[CV] ........................... alpha=0.3, score=0.607, total=   0.0s\n",
      "[CV] alpha=0.3 .......................................................\n",
      "[CV] ........................... alpha=0.3, score=0.444, total=   0.0s\n",
      "[CV] alpha=0.3 .......................................................\n",
      "[CV] ........................... alpha=0.3, score=0.407, total=   0.0s\n",
      "[CV] alpha=0.3 .......................................................\n",
      "[CV] ........................... alpha=0.3, score=0.519, total=   0.0s\n",
      "[CV] alpha=0.3 .......................................................\n",
      "[CV] ........................... alpha=0.3, score=0.556, total=   0.0s\n",
      "[CV] alpha=0.4 .......................................................\n",
      "[CV] ........................... alpha=0.4, score=0.571, total=   0.0s\n",
      "[CV] alpha=0.4 .......................................................\n",
      "[CV] ........................... alpha=0.4, score=0.444, total=   0.0s\n",
      "[CV] alpha=0.4 .......................................................\n",
      "[CV] ........................... alpha=0.4, score=0.444, total=   0.0s\n",
      "[CV] alpha=0.4 .......................................................\n",
      "[CV] ........................... alpha=0.4, score=0.481, total=   0.0s\n",
      "[CV] alpha=0.4 .......................................................\n",
      "[CV] ........................... alpha=0.4, score=0.519, total=   0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] ........................... alpha=0.5, score=0.571, total=   0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] ........................... alpha=0.5, score=0.481, total=   0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] ........................... alpha=0.5, score=0.481, total=   0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] ........................... alpha=0.5, score=0.481, total=   0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] ........................... alpha=0.5, score=0.519, total=   0.0s\n",
      "[CV] alpha=0.6 .......................................................\n",
      "[CV] ........................... alpha=0.6, score=0.571, total=   0.0s\n",
      "[CV] alpha=0.6 .......................................................\n",
      "[CV] ........................... alpha=0.6, score=0.481, total=   0.0s\n",
      "[CV] alpha=0.6 .......................................................\n",
      "[CV] ........................... alpha=0.6, score=0.481, total=   0.0s\n",
      "[CV] alpha=0.6 .......................................................\n",
      "[CV] ........................... alpha=0.6, score=0.481, total=   0.0s\n",
      "[CV] alpha=0.6 .......................................................\n",
      "[CV] ........................... alpha=0.6, score=0.519, total=   0.0s\n",
      "[CV] alpha=0.7 .......................................................\n",
      "[CV] ........................... alpha=0.7, score=0.571, total=   0.0s\n",
      "[CV] alpha=0.7 .......................................................\n",
      "[CV] ........................... alpha=0.7, score=0.444, total=   0.0s\n",
      "[CV] alpha=0.7 .......................................................\n",
      "[CV] ........................... alpha=0.7, score=0.481, total=   0.0s\n",
      "[CV] alpha=0.7 .......................................................\n",
      "[CV] ........................... alpha=0.7, score=0.481, total=   0.0s\n",
      "[CV] alpha=0.7 .......................................................\n",
      "[CV] ........................... alpha=0.7, score=0.556, total=   0.0s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "[CV] ........................... alpha=0.8, score=0.536, total=   0.0s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "[CV] ........................... alpha=0.8, score=0.444, total=   0.0s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "[CV] ........................... alpha=0.8, score=0.444, total=   0.0s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "[CV] ........................... alpha=0.8, score=0.481, total=   0.0s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "[CV] ........................... alpha=0.8, score=0.556, total=   0.0s\n",
      "[CV] alpha=0.9 .......................................................\n",
      "[CV] ........................... alpha=0.9, score=0.536, total=   0.0s\n",
      "[CV] alpha=0.9 .......................................................\n",
      "[CV] ........................... alpha=0.9, score=0.444, total=   0.0s\n",
      "[CV] alpha=0.9 .......................................................\n",
      "[CV] ........................... alpha=0.9, score=0.481, total=   0.0s\n",
      "[CV] alpha=0.9 .......................................................\n",
      "[CV] ........................... alpha=0.9, score=0.519, total=   0.0s\n",
      "[CV] alpha=0.9 .......................................................\n",
      "[CV] ........................... alpha=0.9, score=0.444, total=   0.0s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] ........................... alpha=1.0, score=0.500, total=   0.0s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] ........................... alpha=1.0, score=0.444, total=   0.0s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] ........................... alpha=1.0, score=0.481, total=   0.0s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] ........................... alpha=1.0, score=0.519, total=   0.0s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] ........................... alpha=1.0, score=0.519, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MultinomialNB(),\n",
       "             param_grid=[{'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
       "                                    1.0]}],\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_grid_param = [ {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]} ]\n",
    "\n",
    "# make a GridSearchCV object\n",
    "gs_nb = GridSearchCV(clf_nb, nb_grid_param, cv = 5, verbose = 3)\n",
    "\n",
    "gs_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=0.2)\n"
     ]
    }
   ],
   "source": [
    "print(gs_nb.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5142857142857142\n",
      "Precision:  0.6813186813186813\n",
      "Recall:  0.5142857142857142\n",
      "F1 Score:  0.5861344537815125\n"
     ]
    }
   ],
   "source": [
    "clf_nb = MultinomialNB(alpha = 0.2)\n",
    "clf_nb.fit(X_train, y_train)\n",
    "pred_nb = clf_nb.predict(X_test)\n",
    "\n",
    "accuracy, precision, recall, f1_score = get_score(y_test, pred_nb)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "swlist = ['a', 'ada', 'adanya', 'adapun', 'agak', 'agaknya', 'agar', 'akan', \n",
    "           'akankah', 'akhir', 'akhiri', 'akhirnya', 'aku', 'akulah', 'amat', 'amatlah', \n",
    "           'anda', 'andalah', 'antar', 'antara', 'antaranya',  'apaan', 'apabila', \n",
    "           'apalagi', 'apatah',  'asal', 'asalkan', 'atas', 'atau', 'ataukah', 'ataupun', 'awal',\n",
    "           'awalnya', 'b', 'bagai', 'bagaikan', 'bagaimanapun', 'bagi', 'bagian', 'bahkan','bahwa',\n",
    "           'bahwasannya', 'bahwasanya', 'baik', 'baiklah', 'bakal', 'bakalan', 'balik', 'banyak', 'bapak', 'baru', 'bawah',\n",
    "           'beberapa', 'begini', 'beginian', 'beginikah', 'beginilah', 'begitu', 'begitukah',\n",
    "           'begitulah', 'begitupun', 'bekerja', 'belakang', 'belakangan', 'belum', 'belumlah',\n",
    "           'benar', 'benarlah', 'berada', 'berakhir', 'berakhirlah', 'berakhirnya',\n",
    "           'berapalah', 'berapapun', 'berarti', 'berawal', 'berbagai', 'berdatangan', 'berikut',\n",
    "           'berikutnya', 'berkali-kali', 'berkata', 'berkehendak', 'berkeinginan', 'berkenaan',\n",
    "           'berlainan', 'berlalu', 'berlangsung', 'berlebihan', 'bermacam', 'bermacam-macam',\n",
    "           'bermaksud', 'bermula', 'bersama', 'bersama-sama', 'bersiap', 'bersiap-siap',\n",
    "           'bertanya', 'bertanya-tanya', 'berturut', 'berturut-turut', 'bertutur', 'berujar',\n",
    "           'berupa', 'besar', 'betul', 'biasa', 'biasanya', 'bila', 'bilakah', 'bisa', 'boleh', 'bolehkah', 'bolehlah', 'buat',\n",
    "           'bukan', 'bukankah', 'bukanlah', 'bukannya', 'bulan', 'bung', 'c', 'cara', 'caranya', 'cukup', 'cukupkah',\n",
    "           'cukuplah', 'cuma', 'd', 'dahulu', 'dalam', 'dan', 'dapat', 'dari', 'daripada', 'datang', 'dekat', 'demi',\n",
    "           'demikian', 'demikianlah', 'dengan', 'depan', 'di', 'dia', 'diakhiri', 'diakhirinya',\n",
    "           'dialah', 'diantara', 'diberi', 'diberikan', 'diberikannya', 'dibuat', 'dibuatnya', 'didapat',\n",
    "           'didatangkan', 'digunakan', 'diibaratkan', 'diibaratkannya', 'diingat', 'diingatkan', 'diinginkan',\n",
    "           'dijawab', 'dijelaskan', 'dijelaskannya', 'dikarenakan', 'dikatakan', 'dikatakannya', 'dikerjakan',\n",
    "           'diketahui', 'diketahuinya', 'dikira', 'dilakukan', 'dilalui', 'dilihat', 'dimaksud', 'dimaksudkan',\n",
    "           'dimaksudkannya', 'dimaksudnya', 'diminta', 'dimintai', 'dimisalkan', 'dimulai', 'dimulailah',\n",
    "           'dimulainya', 'dimungkinkan', 'dini', 'dipastikan', 'diperbuat', 'diperbuatnya', 'dipergunakan',\n",
    "           'diperkirakan', 'diperlihatkan', 'diperlukan', 'diperlukannya', 'dipersoalkan', 'dipertanyakan',\n",
    "           'dipunyai', 'diri', 'dirinya', 'disampaikan', 'disebutkan', 'disebutkannya', 'disini', 'disinilah',\n",
    "           'ditambahkan', 'ditandaskan', 'ditanya', 'ditanyai', 'ditanyakan', 'ditegaskan', 'ditujukan', 'ditunjuk',\n",
    "           'ditunjuki', 'ditunjukkan', 'ditunjukkannya', 'ditunjuknya', 'dituturkan', 'dituturkannya', 'diucapkan',\n",
    "           'diucapkannya', 'diungkapkan', 'dong', 'dua', 'dulu', 'e', 'empat', 'enak', 'enggak', 'enggaknya',\n",
    "           'entah', 'entahlah', 'f', 'g', 'guna', 'gunakan', 'h', 'hadap', 'hai', 'hal', 'halo', 'hallo',\n",
    "           'hampir', 'hanya', 'hanyalah', 'hari', 'harus', 'haruslah', 'harusnya', 'helo', 'hello', 'hendak',\n",
    "           'hendaklah', 'hendaknya', 'hingga', 'i', 'ia', 'ialah', 'ibarat', 'ibaratkan', 'ibaratnya', 'ibu', 'ikut',\n",
    "           'ingat', 'ingat-ingat', 'ingin', 'inginkah', 'inginkan', 'ini', 'inikah', 'inilah', 'itu', 'itukah', 'itulah',\n",
    "           'j', 'jadi', 'jadilah', 'jadinya', 'jangan', 'jangankan', 'janganlah', 'jauh', 'jawab', 'jawaban',\n",
    "           'jawabnya', 'jelas', 'jelaslah', 'jelasnya', 'jika', 'jikalau', 'juga', 'jumlah', 'jumlahnya', 'justru',\n",
    "           'k', 'kadar', 'kala', 'kalau', 'kalaulah', 'kalaupun', 'kali', 'kalian', 'kami', 'kamilah', 'kamu',\n",
    "           'kamulah', 'kan', 'kapankah', 'kapanpun',  'karenanya', 'kasus', 'kata', 'katakan', 'katakanlah', 'katanya',\n",
    "           'ke', 'keadaan', 'kebetulan', 'kecil', 'kedua', 'keduanya', 'keinginan', 'kelamaan', 'kelihatan',\n",
    "           'kelihatannya', 'kelima', 'keluar', 'kembali', 'kemudian', 'kemungkinan', 'kemungkinannya', 'kena',\n",
    "           'kepada', 'kepadanya', 'kerja', 'kesampaian', 'keseluruhan', 'keseluruhannya', 'keterlaluan', 'ketika',\n",
    "           'khusus', 'khususnya', 'kini', 'kinilah', 'kira', 'kira-kira', 'kiranya', 'kita', 'kitalah', 'kok', 'kurang',\n",
    "           'l', 'lagi', 'lagian', 'lah', 'lain', 'lainnya', 'laku', 'lalu', 'lama', 'lamanya', 'langsung', 'lanjut',\n",
    "           'lanjutnya', 'lebih', 'lewat', 'lihat', 'lima', 'luar', 'm', 'macam', 'maka', 'makanya', 'makin', 'maksud',\n",
    "           'malah', 'malahan', 'mampu', 'mampukah', 'mana', 'manakala', 'manalagi', 'masa', 'masalah', 'masalahnya',\n",
    "           'masih', 'masihkah', 'masing', 'masing-masing', 'masuk', 'mata', 'mau', 'maupun', 'melainkan', 'melakukan',\n",
    "           'melalui', 'melihat', 'melihatnya', 'memang', 'memastikan', 'memberi', 'memberikan', 'membuat',\n",
    "           'memerlukan', 'memihak', 'meminta', 'memintakan', 'memisalkan', 'memperbuat', 'mempergunakan',\n",
    "           'memperkirakan', 'memperlihatkan', 'mempersiapkan', 'mempersoalkan', 'mempertanyakan', 'mempunyai',\n",
    "           'memulai', 'memungkinkan', 'menaiki', 'menambahkan', 'menandaskan', 'menanti', 'menanti-nanti',\n",
    "           'menantikan', 'menanya', 'menanyai', 'menanyakan', 'mendapat', 'mendapatkan', 'mendatang', 'mendatangi',\n",
    "           'mendatangkan', 'menegaskan', 'mengakhiri', 'mengatakan', 'mengatakannya', 'mengenai', 'mengerjakan',\n",
    "           'mengetahui', 'menggunakan', 'menghendaki', 'mengibaratkan', 'mengibaratkannya', 'mengingat', 'mengingatkan',\n",
    "           'menginginkan', 'mengira', 'mengucapkan', 'mengucapkannya', 'mengungkapkan', 'menjadi', 'menjawab',\n",
    "           'menjelaskan', 'menuju', 'menunjuk', 'menunjuki', 'menunjuknya', 'menurut', 'menuturkan', 'menyampaikan',\n",
    "           'menyangkut', 'menyatakan', 'menyebutkan', 'menyeluruh', 'menyiapkan', 'merasa', 'mereka', 'merekalah',\n",
    "           'meski', 'meskipun', 'meyakini', 'meyakinkan', 'minta', 'mirip', 'misal', 'misalkan', 'misalnya',\n",
    "           'mohon', 'mula', 'mulai', 'mulailah', 'mulanya', 'mungkin', 'mungkinkah', 'n', 'nah', 'naik', 'namun',\n",
    "           'nanti', 'nantinya', 'nya', 'nyaris', 'nyata', 'nyatanya', 'o', 'oleh', 'olehnya', 'orang', 'p', 'pada',\n",
    "           'padahal', 'padanya', 'pak', 'paling', 'panjang', 'pantas', 'para', 'pasti', 'pastilah', 'penting',\n",
    "           'pentingnya', 'per', 'percuma', 'perlu', 'perlukah', 'perlunya', 'pernah', 'persoalan', 'pertama',\n",
    "           'pertama-tama', 'pertanyaan', 'pertanyakan', 'pihak', 'pihaknya', 'pukul', 'pula', 'pun', 'punya', 'q', 'r',\n",
    "           'rasa', 'rasanya', 'rupanya', 's', 'saat', 'saatnya', 'saja', 'sajalah', 'salam', 'saling', 'sama',\n",
    "           'sama-sama', 'sambil', 'sampai', 'sampai-sampai', 'sampaikan', 'sana', 'sangat', 'sangatlah', 'sangkut',\n",
    "           'satu', 'saya', 'sayalah', 'se', 'sebab', 'sebabnya', 'sebagai', 'sebagaimana', 'sebagainya', 'sebagian',\n",
    "           'sebaik', 'sebaik-baiknya', 'sebaiknya', 'sebaliknya', 'sebanyak', 'sebegini', 'sebegitu', 'sebelum',\n",
    "           'sebelumnya', 'sebenarnya', 'seberapa', 'sebesar', 'sebetulnya', 'sebisanya', 'sebuah', \n",
    "           'sebutnya', 'secara', 'secukupnya', 'sedang', 'sedangkan', 'sedemikian', 'sedikit', 'sedikitnya', 'seenaknya',\n",
    "           'segala', 'segalanya', 'segera', 'seharusnya', 'sehingga', 'seingat', 'sejak', 'sejauh', 'sejenak', 'sejumlah',\n",
    "           'sekadar', 'sekadarnya', 'sekali', 'sekali-kali', 'sekalian', 'sekaligus', 'sekalipun', 'sekarang', 'sekaranglah',\n",
    "           'sekecil', 'seketika', 'sekiranya', 'sekitar', 'sekitarnya', 'sekurang-kurangnya', 'sekurangnya', 'sela',\n",
    "           'selain', 'selaku', 'selalu', 'selama', 'selama-lamanya', 'selamanya', 'selanjutnya', 'seluruh', 'seluruhnya',\n",
    "           'semacam', 'semakin', 'semampu', 'semampunya', 'semasa', 'semasih', 'semata', 'semata-mata', 'semaunya',\n",
    "           'sementara', 'semisal', 'semisalnya', 'sempat', 'semua', 'semuanya', 'semula', 'sendiri', 'sendirian',\n",
    "           'sendirinya', 'seolah', 'seolah-olah', 'seorang', 'sepanjang', 'sepantasnya', 'sepantasnyalah', 'seperlunya',\n",
    "           'seperti', 'sepertinya', 'sepihak', 'sering', 'seringnya', 'serta', 'serupa', 'sesaat', 'sesama', 'sesampai',\n",
    "           'sesegera', 'sesekali', 'seseorang', 'sesuatu', 'sesuatunya', 'sesudah', 'sesudahnya', 'setelah', 'setempat',\n",
    "           'setengah', 'seterusnya', 'setiap', 'setiba', 'setibanya', 'setidak-tidaknya', 'setidaknya', 'setinggi', 'seusai',\n",
    "           'sewaktu', 'siap', 'siapa', 'siapakah', 'siapapun', 'sini', 'sinilah', 'soal', 'soalnya', 'suatu', 'sudah', \n",
    "           'sudahkah', 'sudahlah', 'supaya', 't', 'tadi', 'tadinya', 'tahu', 'tak', 'tambah', 'tambahnya', 'tampak',\n",
    "           'tampaknya', 'tandas', 'tandasnya', 'tanpa', 'tanya', 'tanyakan', 'tanyanya', 'tapi', 'tegas', 'tegasnya',\n",
    "           'telah', 'tempat', 'tentang', 'tentu', 'tentulah', 'tentunya', 'tepat', 'terakhir', 'terasa', 'terbanyak',\n",
    "           'terdahulu', 'terdapat', 'terdiri', 'terhadap', 'terhadapnya', 'teringat', 'teringat-ingat', 'terjadi',\n",
    "           'terjadilah', 'terjadinya', 'terkira', 'terlalu', 'terlebih', 'terlihat', 'termasuk', 'ternyata', 'tersampaikan',\n",
    "           'tersebut', 'tersebutlah', 'tertentu', 'tertuju', 'terus', 'terutama', 'tetap', 'tetapi', 'tiap', 'tiba',\n",
    "           'tiba-tiba', 'tidak', 'tidakkah', 'tidaklah', 'tiga', 'toh', 'tuju', 'tunjuk', 'turut', 'tutur', 'tuturnya',\n",
    "           'u', 'ucap', 'ucapnya', 'ujar', 'ujarnya', 'umumnya', 'ungkap', 'ungkapnya', 'untuk', 'usah', 'usai', 'v', 'w',\n",
    "           'waduh', 'wah', 'wahai', 'waktunya', 'walau', 'walaupun', 'wong', 'x', 'y', 'ya', 'yaitu', 'yakin', 'yakni',\n",
    "           'yang', 'z', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    res = []\n",
    "    words = text.split(\" \")\n",
    "    for word in words:\n",
    "        if word not in swlist:\n",
    "            res.append(word)\n",
    "    return ' '.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_keep = ['adalah', 'apa', 'apakah', 'arti', 'artinya', 'bagaimana', 'bagaimanakah', 'berapa', 'berapakah', 'benarkah',\n",
    "           'beri', 'berikan', 'berjumlah', 'betulkah', 'bisakah', 'diantaranya', 'disebut', 'jelaskan', 'kapan',\n",
    "           'karena', 'kenapa', 'mengapa', 'menunjukkan', 'merupakan', 'rupa', 'sebut', 'sebutlah']\n",
    "# dari idf yg nilai kecil\n",
    "df = pd.read_csv('data\\data_test.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casefolding from column 'question'\n",
    "df.question = df.question.str.lower()\n",
    "\n",
    "# Remove punctuation from column 'question'\n",
    "df['punc_remove'] = df.question.str.replace('[^\\w\\s]', ' ')\n",
    "\n",
    "# Remove stopwords\n",
    "df['sw_remove'] = df.apply(lambda row: remove_stopwords(row['punc_remove']), axis = 1) \n",
    "\n",
    "# Stemming\n",
    "stem_factory = StemmerFactory()\n",
    "stemmer = stem_factory.create_stemmer()\n",
    "df['stemmed'] = df.apply(lambda row: stemmer.stem(row['sw_remove']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>414</th>\n",
       "      <th>415</th>\n",
       "      <th>416</th>\n",
       "      <th>417</th>\n",
       "      <th>418</th>\n",
       "      <th>419</th>\n",
       "      <th>420</th>\n",
       "      <th>421</th>\n",
       "      <th>422</th>\n",
       "      <th>423</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.242774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 424 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4         5    6    7    8    9    ...  414  415  \\\n",
       "166  0.0  0.0  0.0  0.0  0.0  0.236960  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "167  0.0  0.0  0.0  0.0  0.0  0.201708  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "168  0.0  0.0  0.0  0.0  0.0  0.276920  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "169  0.0  0.0  0.0  0.0  0.0  0.242774  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "170  0.0  0.0  0.0  0.0  0.0  0.201708  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "     416  417  418  419  420  421  422  423  \n",
       "166  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "167  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "168  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "169  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "170  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 424 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Buat ngitung nilai TF-IDF dari tiap term\n",
    "vectorizer = TfidfVectorizer()\n",
    "term_doc_matrix = vectorizer.fit_transform(df['stemmed'])\n",
    "\n",
    "# Daftar kata yang dipake di corpus\n",
    "# TODO: Bikin list isinya POSTag, urutan sama kaya vocabulary\n",
    "#       Gabungin 2 list itu jadi 1 dict\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "\n",
    "# Convert hasil fit_transform dari sparse matrix ke list\n",
    "tfidf = flatten(term_doc_matrix)\n",
    "\n",
    "# Apply weighting untuk TF-IDF\n",
    "# tfpos_idf = postag_weighting(tfidf, term_dict)\n",
    "\n",
    "# Convert TFPOS-IDF ke dataframe\n",
    "# Ini yang dipake buat model\n",
    "df_dataset = pd.DataFrame(tfidf)\n",
    "df_dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4\n",
      "Precision:  0.6306766917293233\n",
      "Recall:  0.4\n",
      "F1 Score:  0.4895243653341114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Coding\\Software\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_dataset, df['Label'], test_size=0.2, random_state=23)\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "clf_svm.fit(X_train, y_train)\n",
    "y_pred = clf_svm.predict(X_test)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.42857142857142855\n",
      "Precision:  0.6470418470418471\n",
      "Recall:  0.42857142857142855\n",
      "F1 Score:  0.5156196097972325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Coding\\Software\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_dataset, df['Label'], test_size=0.2, random_state=23)\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train, y_train)\n",
    "y_pred = clf_nb.predict(X_test)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "swlist = ['a', 'ada', 'adanya', 'adapun', 'agak', 'agaknya', 'agar', 'akan', \n",
    "           'akankah', 'akhir', 'akhiri', 'akhirnya', 'aku', 'akulah', 'amat', 'amatlah', \n",
    "           'anda', 'andalah', 'antar', 'antara', 'antaranya',  'apaan', 'apabila', \n",
    "           'apalagi', 'apatah',  'asal', 'asalkan', 'atas', 'atau', 'ataukah', 'ataupun', 'awal',\n",
    "           'awalnya', 'b', 'bagai', 'bagaikan', 'bagaimanapun', 'bagi', 'bagian', 'bahkan','bahwa',\n",
    "           'bahwasannya', 'bahwasanya', 'baik', 'baiklah', 'bakal', 'bakalan', 'balik', 'banyak', 'bapak', 'baru', 'bawah',\n",
    "           'beberapa', 'begini', 'beginian', 'beginikah', 'beginilah', 'begitu', 'begitukah',\n",
    "           'begitulah', 'begitupun', 'bekerja', 'belakang', 'belakangan', 'belum', 'belumlah',\n",
    "           'benar', 'benarlah', 'berada', 'berakhir', 'berakhirlah', 'berakhirnya',\n",
    "           'berapalah', 'berapapun', 'berarti', 'berawal', 'berbagai', 'berdatangan', 'berikut',\n",
    "           'berikutnya', 'berkali-kali', 'berkata', 'berkehendak', 'berkeinginan', 'berkenaan',\n",
    "           'berlainan', 'berlalu', 'berlangsung', 'berlebihan', 'bermacam', 'bermacam-macam',\n",
    "           'bermaksud', 'bermula', 'bersama', 'bersama-sama', 'bersiap', 'bersiap-siap',\n",
    "           'bertanya', 'bertanya-tanya', 'berturut', 'berturut-turut', 'bertutur', 'berujar',\n",
    "           'berupa', 'besar', 'betul', 'biasa', 'biasanya', 'bila', 'bilakah', 'bisa', 'boleh', 'bolehkah', 'bolehlah', 'buat',\n",
    "           'bukan', 'bukankah', 'bukanlah', 'bukannya', 'bulan', 'bung', 'c', 'cara', 'caranya', 'cukup', 'cukupkah',\n",
    "           'cukuplah', 'cuma', 'd', 'dahulu', 'dalam', 'dan', 'dapat', 'dari', 'daripada', 'datang', 'dekat', 'demi',\n",
    "           'demikian', 'demikianlah', 'dengan', 'depan', 'di', 'dia', 'diakhiri', 'diakhirinya',\n",
    "           'dialah', 'diantara', 'diberi', 'diberikan', 'diberikannya', 'dibuat', 'dibuatnya', 'didapat',\n",
    "           'didatangkan', 'digunakan', 'diibaratkan', 'diibaratkannya', 'diingat', 'diingatkan', 'diinginkan',\n",
    "           'dijawab', 'dijelaskan', 'dijelaskannya', 'dikarenakan', 'dikatakan', 'dikatakannya', 'dikerjakan',\n",
    "           'diketahui', 'diketahuinya', 'dikira', 'dilakukan', 'dilalui', 'dilihat', 'dimaksud', 'dimaksudkan',\n",
    "           'dimaksudkannya', 'dimaksudnya', 'diminta', 'dimintai', 'dimisalkan', 'dimulai', 'dimulailah',\n",
    "           'dimulainya', 'dimungkinkan', 'dini', 'dipastikan', 'diperbuat', 'diperbuatnya', 'dipergunakan',\n",
    "           'diperkirakan', 'diperlihatkan', 'diperlukan', 'diperlukannya', 'dipersoalkan', 'dipertanyakan',\n",
    "           'dipunyai', 'diri', 'dirinya', 'disampaikan', 'disebutkan', 'disebutkannya', 'disini', 'disinilah',\n",
    "           'ditambahkan', 'ditandaskan', 'ditanya', 'ditanyai', 'ditanyakan', 'ditegaskan', 'ditujukan', 'ditunjuk',\n",
    "           'ditunjuki', 'ditunjukkan', 'ditunjukkannya', 'ditunjuknya', 'dituturkan', 'dituturkannya', 'diucapkan',\n",
    "           'diucapkannya', 'diungkapkan', 'dong', 'dua', 'dulu', 'e', 'empat', 'enak', 'enggak', 'enggaknya',\n",
    "           'entah', 'entahlah', 'f', 'g', 'guna', 'gunakan', 'h', 'hadap', 'hai', 'hal', 'halo', 'hallo',\n",
    "           'hampir', 'hanya', 'hanyalah', 'hari', 'harus', 'haruslah', 'harusnya', 'helo', 'hello', 'hendak',\n",
    "           'hendaklah', 'hendaknya', 'hingga', 'i', 'ia', 'ialah', 'ibarat', 'ibaratkan', 'ibaratnya', 'ibu', 'ikut',\n",
    "           'ingat', 'ingat-ingat', 'ingin', 'inginkah', 'inginkan', 'ini', 'inikah', 'inilah', 'itu', 'itukah', 'itulah',\n",
    "           'j', 'jadi', 'jadilah', 'jadinya', 'jangan', 'jangankan', 'janganlah', 'jauh', 'jawab', 'jawaban',\n",
    "           'jawabnya', 'jelas', 'jelaslah', 'jelasnya', 'jika', 'jikalau', 'juga', 'jumlah', 'jumlahnya', 'justru',\n",
    "           'k', 'kadar', 'kala', 'kalau', 'kalaulah', 'kalaupun', 'kali', 'kalian', 'kami', 'kamilah', 'kamu',\n",
    "           'kamulah', 'kan', 'kapankah', 'kapanpun',  'karenanya', 'kasus', 'kata', 'katakan', 'katakanlah', 'katanya',\n",
    "           'ke', 'keadaan', 'kebetulan', 'kecil', 'kedua', 'keduanya', 'keinginan', 'kelamaan', 'kelihatan',\n",
    "           'kelihatannya', 'kelima', 'keluar', 'kembali', 'kemudian', 'kemungkinan', 'kemungkinannya', 'kena',\n",
    "           'kepada', 'kepadanya', 'kerja', 'kesampaian', 'keseluruhan', 'keseluruhannya', 'keterlaluan', 'ketika',\n",
    "           'khusus', 'khususnya', 'kini', 'kinilah', 'kira', 'kira-kira', 'kiranya', 'kita', 'kitalah', 'kok', 'kurang',\n",
    "           'l', 'lagi', 'lagian', 'lah', 'lain', 'lainnya', 'laku', 'lalu', 'lama', 'lamanya', 'langsung', 'lanjut',\n",
    "           'lanjutnya', 'lebih', 'lewat', 'lihat', 'lima', 'luar', 'm', 'macam', 'maka', 'makanya', 'makin', 'maksud',\n",
    "           'malah', 'malahan', 'mampu', 'mampukah', 'mana', 'manakala', 'manalagi', 'masa', 'masalah', 'masalahnya',\n",
    "           'masih', 'masihkah', 'masing', 'masing-masing', 'masuk', 'mata', 'mau', 'maupun', 'melainkan', 'melakukan',\n",
    "           'melalui', 'melihat', 'melihatnya', 'memang', 'memastikan', 'memberi', 'memberikan', 'membuat',\n",
    "           'memerlukan', 'memihak', 'meminta', 'memintakan', 'memisalkan', 'memperbuat', 'mempergunakan',\n",
    "           'memperkirakan', 'memperlihatkan', 'mempersiapkan', 'mempersoalkan', 'mempertanyakan', 'mempunyai',\n",
    "           'memulai', 'memungkinkan', 'menaiki', 'menambahkan', 'menandaskan', 'menanti', 'menanti-nanti',\n",
    "           'menantikan', 'menanya', 'menanyai', 'menanyakan', 'mendapat', 'mendapatkan', 'mendatang', 'mendatangi',\n",
    "           'mendatangkan', 'menegaskan', 'mengakhiri', 'mengatakan', 'mengatakannya', 'mengenai', 'mengerjakan',\n",
    "           'mengetahui', 'menggunakan', 'menghendaki', 'mengibaratkan', 'mengibaratkannya', 'mengingat', 'mengingatkan',\n",
    "           'menginginkan', 'mengira', 'mengucapkan', 'mengucapkannya', 'mengungkapkan', 'menjadi', 'menjawab',\n",
    "           'menjelaskan', 'menuju', 'menunjuk', 'menunjuki', 'menunjuknya', 'menurut', 'menuturkan', 'menyampaikan',\n",
    "           'menyangkut', 'menyatakan', 'menyebutkan', 'menyeluruh', 'menyiapkan', 'merasa', 'mereka', 'merekalah',\n",
    "           'meski', 'meskipun', 'meyakini', 'meyakinkan', 'minta', 'mirip', 'misal', 'misalkan', 'misalnya',\n",
    "           'mohon', 'mula', 'mulai', 'mulailah', 'mulanya', 'mungkin', 'mungkinkah', 'n', 'nah', 'naik', 'namun',\n",
    "           'nanti', 'nantinya', 'nya', 'nyaris', 'nyata', 'nyatanya', 'o', 'oleh', 'olehnya', 'orang', 'p', 'pada',\n",
    "           'padahal', 'padanya', 'pak', 'paling', 'panjang', 'pantas', 'para', 'pasti', 'pastilah', 'penting',\n",
    "           'pentingnya', 'per', 'percuma', 'perlu', 'perlukah', 'perlunya', 'pernah', 'persoalan', 'pertama',\n",
    "           'pertama-tama', 'pertanyaan', 'pertanyakan', 'pihak', 'pihaknya', 'pukul', 'pula', 'pun', 'punya', 'q', 'r',\n",
    "           'rasa', 'rasanya', 'rupanya', 's', 'saat', 'saatnya', 'saja', 'sajalah', 'salam', 'saling', 'sama',\n",
    "           'sama-sama', 'sambil', 'sampai', 'sampai-sampai', 'sampaikan', 'sana', 'sangat', 'sangatlah', 'sangkut',\n",
    "           'satu', 'saya', 'sayalah', 'se', 'sebab', 'sebabnya', 'sebagai', 'sebagaimana', 'sebagainya', 'sebagian',\n",
    "           'sebaik', 'sebaik-baiknya', 'sebaiknya', 'sebaliknya', 'sebanyak', 'sebegini', 'sebegitu', 'sebelum',\n",
    "           'sebelumnya', 'sebenarnya', 'seberapa', 'sebesar', 'sebetulnya', 'sebisanya', 'sebuah', \n",
    "           'sebutnya', 'secara', 'secukupnya', 'sedang', 'sedangkan', 'sedemikian', 'sedikit', 'sedikitnya', 'seenaknya',\n",
    "           'segala', 'segalanya', 'segera', 'seharusnya', 'sehingga', 'seingat', 'sejak', 'sejauh', 'sejenak', 'sejumlah',\n",
    "           'sekadar', 'sekadarnya', 'sekali', 'sekali-kali', 'sekalian', 'sekaligus', 'sekalipun', 'sekarang', 'sekaranglah',\n",
    "           'sekecil', 'seketika', 'sekiranya', 'sekitar', 'sekitarnya', 'sekurang-kurangnya', 'sekurangnya', 'sela',\n",
    "           'selain', 'selaku', 'selalu', 'selama', 'selama-lamanya', 'selamanya', 'selanjutnya', 'seluruh', 'seluruhnya',\n",
    "           'semacam', 'semakin', 'semampu', 'semampunya', 'semasa', 'semasih', 'semata', 'semata-mata', 'semaunya',\n",
    "           'sementara', 'semisal', 'semisalnya', 'sempat', 'semua', 'semuanya', 'semula', 'sendiri', 'sendirian',\n",
    "           'sendirinya', 'seolah', 'seolah-olah', 'seorang', 'sepanjang', 'sepantasnya', 'sepantasnyalah', 'seperlunya',\n",
    "           'seperti', 'sepertinya', 'sepihak', 'sering', 'seringnya', 'serta', 'serupa', 'sesaat', 'sesama', 'sesampai',\n",
    "           'sesegera', 'sesekali', 'seseorang', 'sesuatu', 'sesuatunya', 'sesudah', 'sesudahnya', 'setelah', 'setempat',\n",
    "           'setengah', 'seterusnya', 'setiap', 'setiba', 'setibanya', 'setidak-tidaknya', 'setidaknya', 'setinggi', 'seusai',\n",
    "           'sewaktu', 'siap', 'siapa', 'siapakah', 'siapapun', 'sini', 'sinilah', 'soal', 'soalnya', 'suatu', 'sudah', \n",
    "           'sudahkah', 'sudahlah', 'supaya', 't', 'tadi', 'tadinya', 'tahu', 'tak', 'tambah', 'tambahnya', 'tampak',\n",
    "           'tampaknya', 'tandas', 'tandasnya', 'tanpa', 'tanya', 'tanyakan', 'tanyanya', 'tapi', 'tegas', 'tegasnya',\n",
    "           'telah', 'tempat', 'tentang', 'tentu', 'tentulah', 'tentunya', 'tepat', 'terakhir', 'terasa', 'terbanyak',\n",
    "           'terdahulu', 'terdapat', 'terdiri', 'terhadap', 'terhadapnya', 'teringat', 'teringat-ingat', 'terjadi',\n",
    "           'terjadilah', 'terjadinya', 'terkira', 'terlalu', 'terlebih', 'terlihat', 'termasuk', 'ternyata', 'tersampaikan',\n",
    "           'tersebut', 'tersebutlah', 'tertentu', 'tertuju', 'terus', 'terutama', 'tetap', 'tetapi', 'tiap', 'tiba',\n",
    "           'tiba-tiba', 'tidak', 'tidakkah', 'tidaklah', 'tiga', 'toh', 'tuju', 'tunjuk', 'turut', 'tutur', 'tuturnya',\n",
    "           'u', 'ucap', 'ucapnya', 'ujar', 'ujarnya', 'umumnya', 'ungkap', 'ungkapnya', 'untuk', 'usah', 'usai', 'v', 'w',\n",
    "           'waduh', 'wah', 'wahai', 'waktunya', 'walau', 'walaupun', 'wong', 'x', 'y', 'ya', 'yaitu', 'yakin', 'yakni',\n",
    "           'yang', 'z']\n",
    "\n",
    "\n",
    "dihapus = ['adalah', 'apa', 'apakah', 'arti', 'artinya', 'bagaimana', 'bagaimanakah', 'berapa', 'berapakah', 'benarkah',\n",
    "           'beri', 'berikan', 'berjumlah', 'betulkah', 'bisakah', 'bolehkah', 'diantaranya', 'disebut', 'jelaskan', 'kapan',\n",
    "           'karena', 'kenapa', 'menunjukkan', 'merupakan', 'rupa', 'sebut', 'sebutlah']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
