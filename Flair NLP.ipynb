{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "en9bUDg3P6Pm",
    "outputId": "828d7fe2-6674-4c2f-ac81-3cd3582657a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "  Downloading flair-0.10-py3-none-any.whl (322 kB)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in d:\\coding\\software\\anaconda\\lib\\site-packages (from flair) (4.61.2)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
      "Collecting gdown==3.12.2\n",
      "  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: torch!=1.8,>=1.5.0 in d:\\coding\\software\\anaconda\\lib\\site-packages (from flair) (1.7.0)\n",
      "Requirement already satisfied: regex in d:\\coding\\software\\anaconda\\lib\\site-packages (from flair) (2020.7.14)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in d:\\coding\\software\\anaconda\\lib\\site-packages (from flair) (2.8.1)\n",
      "Requirement already satisfied: lxml in d:\\coding\\software\\anaconda\\lib\\site-packages (from flair) (4.5.2)\n",
      "Collecting konoha<5.0.0,>=4.0.0\n",
      "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
      "Collecting mpld3==0.3\n",
      "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in d:\\coding\\software\\anaconda\\lib\\site-packages (from flair) (3.4.2)\n",
      "Collecting bpemb>=0.3.2\n",
      "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in d:\\coding\\software\\anaconda\\lib\\site-packages (from flair) (0.23.2)\n",
      "Collecting transformers>=4.0.0\n",
      "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
      "Requirement already satisfied: gensim>=3.4.0 in d:\\coding\\software\\anaconda\\lib\\site-packages (from flair) (3.4.0)\n",
      "Collecting deprecated>=1.2.4\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting sqlitedict>=1.6.0\n",
      "  Downloading sqlitedict-1.7.0.tar.gz (28 kB)\n",
      "Collecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "Collecting more-itertools~=8.8.0\n",
      "  Downloading more_itertools-8.8.0-py3-none-any.whl (48 kB)\n",
      "Collecting wikipedia-api\n",
      "  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
      "Collecting janome\n",
      "  Downloading Janome-0.4.1-py2.py3-none-any.whl (19.7 MB)\n",
      "Collecting segtok>=1.5.7\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Collecting sentencepiece==0.1.95\n",
      "  Downloading sentencepiece-0.1.95-cp37-cp37m-win_amd64.whl (1.2 MB)\n",
      "Collecting conllu>=4.0\n",
      "  Downloading conllu-4.4.1-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tqdm>=4.26.0->flair) (0.4.1)\n",
      "Requirement already satisfied: six in d:\\coding\\software\\anaconda\\lib\\site-packages (from langdetect->flair) (1.15.0)\n",
      "Requirement already satisfied: wcwidth in d:\\coding\\software\\anaconda\\lib\\site-packages (from ftfy->flair) (0.2.5)\n",
      "Requirement already satisfied: requests[socks] in d:\\coding\\software\\anaconda\\lib\\site-packages (from gdown==3.12.2->flair) (2.24.0)\n",
      "Requirement already satisfied: filelock in d:\\coding\\software\\anaconda\\lib\\site-packages (from gdown==3.12.2->flair) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions in d:\\coding\\software\\anaconda\\lib\\site-packages (from torch!=1.8,>=1.5.0->flair) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in d:\\coding\\software\\anaconda\\lib\\site-packages (from torch!=1.8,>=1.5.0->flair) (0.6)\n",
      "Requirement already satisfied: numpy in d:\\coding\\software\\anaconda\\lib\\site-packages (from torch!=1.8,>=1.5.0->flair) (1.19.5)\n",
      "Requirement already satisfied: future in d:\\coding\\software\\anaconda\\lib\\site-packages (from torch!=1.8,>=1.5.0->flair) (0.18.2)\n",
      "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
      "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
      "Collecting overrides<4.0.0,>=3.0.0\n",
      "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\coding\\software\\anaconda\\lib\\site-packages (from matplotlib>=2.2.3->flair) (1.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\coding\\software\\anaconda\\lib\\site-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\coding\\software\\anaconda\\lib\\site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\coding\\software\\anaconda\\lib\\site-packages (from matplotlib>=2.2.3->flair) (8.3.1)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\coding\\software\\anaconda\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\coding\\software\\anaconda\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\coding\\software\\anaconda\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (2.1.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\coding\\software\\anaconda\\lib\\site-packages (from transformers>=4.0.0->flair) (20.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\coding\\software\\anaconda\\lib\\site-packages (from transformers>=4.0.0->flair) (5.3.1)\n",
      "Requirement already satisfied: smart_open>=1.2.1 in d:\\coding\\software\\anaconda\\lib\\site-packages (from gensim>=3.4.0->flair) (2.2.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in d:\\coding\\software\\anaconda\\lib\\site-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in d:\\coding\\software\\anaconda\\lib\\site-packages (from requests[socks]->gdown==3.12.2->flair) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\coding\\software\\anaconda\\lib\\site-packages (from requests[socks]->gdown==3.12.2->flair) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\coding\\software\\anaconda\\lib\\site-packages (from requests[socks]->gdown==3.12.2->flair) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\coding\\software\\anaconda\\lib\\site-packages (from requests[socks]->gdown==3.12.2->flair) (1.25.10)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in d:\\coding\\software\\anaconda\\lib\\site-packages (from requests[socks]->gdown==3.12.2->flair) (1.7.1)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\coding\\software\\anaconda\\lib\\site-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.3.0)\n",
      "Requirement already satisfied: click in d:\\coding\\software\\anaconda\\lib\\site-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n",
      "Requirement already satisfied: boto3 in d:\\coding\\software\\anaconda\\lib\\site-packages (from smart_open>=1.2.1->gensim>=3.4.0->flair) (1.15.12)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in d:\\coding\\software\\anaconda\\lib\\site-packages (from boto3->smart_open>=1.2.1->gensim>=3.4.0->flair) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.19.0,>=1.18.12 in d:\\coding\\software\\anaconda\\lib\\site-packages (from boto3->smart_open>=1.2.1->gensim>=3.4.0->flair) (1.18.12)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in d:\\coding\\software\\anaconda\\lib\\site-packages (from boto3->smart_open>=1.2.1->gensim>=3.4.0->flair) (0.10.0)\n",
      "Building wheels for collected packages: langdetect, ftfy, gdown, mpld3, sqlitedict, wikipedia-api, overrides\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=4f8986a1cb24436cf91674a123d8b2c4c1dc682d54f383d7ccbb1b6284cb0572\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\c5\\96\\8a\\f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
      "  Building wheel for ftfy (setup.py): started\n",
      "  Building wheel for ftfy (setup.py): finished with status 'done'\n",
      "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41920 sha256=6c29bdfed97caa95e41756876cc300e246f1fea9950867b0f9cecfacfe1f2236\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\19\\f5\\38\\273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
      "  Building wheel for gdown (PEP 517): started\n",
      "  Building wheel for gdown (PEP 517): finished with status 'done'\n",
      "  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9692 sha256=96dfd1dfb783ba061e655fe64b9e3859a184dca881c6f85761e14f84b42b5d4e\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\ba\\e0\\7e\\726e872a53f7358b4b96a9975b04e98113b005cd8609a63abc\n",
      "  Building wheel for mpld3 (setup.py): started\n",
      "  Building wheel for mpld3 (setup.py): finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "nxviz 0.6.2 requires hypothesis==4.34.0, which is not installed.\n",
      "nxviz 0.6.2 requires sphinxcontrib-fulltoc==1.2.0, which is not installed.\n",
      "nxviz 0.6.2 requires cryptography==2.7, but you'll have cryptography 3.1.1 which is incompatible.\n",
      "nxviz 0.6.2 requires matplotlib==3.1.1, but you'll have matplotlib 3.4.2 which is incompatible.\n",
      "nxviz 0.6.2 requires more-itertools==7.2.0, but you'll have more-itertools 8.8.0 which is incompatible.\n",
      "nxviz 0.6.2 requires networkx==2.3, but you'll have networkx 2.5 which is incompatible.\n",
      "nxviz 0.6.2 requires numpy==1.17.1, but you'll have numpy 1.19.5 which is incompatible.\n",
      "nxviz 0.6.2 requires palettable==3.1.1, but you'll have palettable 3.3.0 which is incompatible.\n",
      "nxviz 0.6.2 requires pandas==0.25.1, but you'll have pandas 1.1.2 which is incompatible.\n",
      "nxviz 0.6.2 requires pytest==5.1.2, but you'll have pytest 0.0.0 which is incompatible.\n",
      "nxviz 0.6.2 requires PyYAML==5.1.2, but you'll have pyyaml 5.3.1 which is incompatible.\n",
      "nxviz 0.6.2 requires seaborn==0.9.0, but you'll have seaborn 0.11.0 which is incompatible.\n",
      "nxviz 0.6.2 requires setuptools==41.2.0, but you'll have setuptools 50.3.0.post20201006 which is incompatible.\n",
      "konoha 4.6.5 requires requests<3.0.0,>=2.25.1, but you'll have requests 2.24.0 which is incompatible.\n",
      "huggingface-hub 0.4.0 requires packaging>=20.9, but you'll have packaging 20.4 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116683 sha256=a076f09279e4d9d232acafb79569f71710655d600864ddd37b414b07cf24d1f1\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\26\\70\\6a\\1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
      "  Building wheel for sqlitedict (setup.py): started\n",
      "  Building wheel for sqlitedict (setup.py): finished with status 'done'\n",
      "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-py3-none-any.whl size=14381 sha256=32bf0dd88fbbd8def7cdf89a59253b3ff4c3b5a2a9929be0a00b2673616655c8\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\af\\94\\06\\18c0e83e9e227da8f3582810b51f319bbfd181e508676a56c8\n",
      "  Building wheel for wikipedia-api (setup.py): started\n",
      "  Building wheel for wikipedia-api (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13467 sha256=b885e3fe1a8d0bd1ed633d3877c543a3f4d09a288516962588e2138ba9767a92\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\d3\\24\\56\\58ba93cf78be162451144e7a9889603f437976ef1ae7013d04\n",
      "  Building wheel for overrides (setup.py): started\n",
      "  Building wheel for overrides (setup.py): finished with status 'done'\n",
      "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10179 sha256=8d7d24b54ea7d500c1a00e1983ac0cd3fc6291aceedece3612181383f86ea2ec\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\3a\\0d\\38\\01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
      "Successfully built langdetect ftfy gdown mpld3 sqlitedict wikipedia-api overrides\n",
      "Installing collected packages: tabulate, langdetect, ftfy, gdown, importlib-metadata, overrides, konoha, mpld3, sentencepiece, bpemb, sacremoses, tokenizers, huggingface-hub, transformers, deprecated, sqlitedict, more-itertools, wikipedia-api, janome, segtok, conllu, flair\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 1.7.0\n",
      "    Uninstalling importlib-metadata-1.7.0:\n",
      "      Successfully uninstalled importlib-metadata-1.7.0\n",
      "  Attempting uninstall: more-itertools\n",
      "    Found existing installation: more-itertools 8.5.0\n",
      "    Uninstalling more-itertools-8.5.0:\n",
      "      Successfully uninstalled more-itertools-8.5.0\n",
      "Successfully installed bpemb-0.3.3 conllu-4.4.1 deprecated-1.2.13 flair-0.10 ftfy-6.0.3 gdown-3.12.2 huggingface-hub-0.4.0 importlib-metadata-3.10.1 janome-0.4.1 konoha-4.6.5 langdetect-1.0.9 more-itertools-8.8.0 mpld3-0.3 overrides-3.1.0 sacremoses-0.0.47 segtok-1.5.11 sentencepiece-0.1.95 sqlitedict-1.7.0 tabulate-0.8.9 tokenizers-0.10.3 transformers-4.15.0 wikipedia-api-0.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Byjn8iEai1gu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Coding\\Software\\Anaconda\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher, NLPTask\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, BertEmbeddings\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-N8O7y3ezxH2",
    "outputId": "07fcee7a-31f1-4cea-f29a-cbb8ef90211b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Coding\\Software\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated function (or staticmethod) load_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 12:26:33,602 https://raw.githubusercontent.com/UniversalDependencies/UD_Indonesian-GSD/master/id_gsd-ud-dev.conllu not found in cache, downloading to C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmp0lf3s4ny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1044673B [00:00, 8783131.90B/s]                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 12:26:33,850 copying C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmp0lf3s4ny to cache at C:\\Users\\ASUS\\.flair\\datasets\\ud_indonesian\\id_gsd-ud-dev.conllu\n",
      "2022-01-20 12:26:33,885 removing temp file C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmp0lf3s4ny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 12:26:34,373 https://raw.githubusercontent.com/UniversalDependencies/UD_Indonesian-GSD/master/id_gsd-ud-test.conllu not found in cache, downloading to C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmpxy24iwkr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "972869B [00:00, 7281148.17B/s]                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 12:26:34,629 copying C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmpxy24iwkr to cache at C:\\Users\\ASUS\\.flair\\datasets\\ud_indonesian\\id_gsd-ud-test.conllu\n",
      "2022-01-20 12:26:34,676 removing temp file C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmpxy24iwkr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 12:26:35,956 https://raw.githubusercontent.com/UniversalDependencies/UD_Indonesian-GSD/master/id_gsd-ud-train.conllu not found in cache, downloading to C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmp46ghcsgm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8070570B [00:00, 10791022.76B/s]                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 12:26:36,816 copying C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmp46ghcsgm to cache at C:\\Users\\ASUS\\.flair\\datasets\\ud_indonesian\\id_gsd-ud-train.conllu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 12:26:36,934 removing temp file C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmp46ghcsgm\n",
      "2022-01-20 12:26:36,937 Reading data from C:\\Users\\ASUS\\.flair\\datasets\\ud_indonesian\n",
      "2022-01-20 12:26:36,938 Train: C:\\Users\\ASUS\\.flair\\datasets\\ud_indonesian\\id_gsd-ud-train.conllu\n",
      "2022-01-20 12:26:36,939 Dev: C:\\Users\\ASUS\\.flair\\datasets\\ud_indonesian\\id_gsd-ud-dev.conllu\n",
      "2022-01-20 12:26:36,940 Test: C:\\Users\\ASUS\\.flair\\datasets\\ud_indonesian\\id_gsd-ud-test.conllu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Coding\\Software\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated method make_tag_dictionary. (Use 'make_label_dictionary' instead.) -- Deprecated since version 0.8.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'O', b'PROPN', b'AUX', b'DET', b'NOUN', b'PRON', b'VERB', b'ADP', b'PUNCT', b'ADV', b'CCONJ', b'SCONJ', b'NUM', b'ADJ', b'PART', b'SYM', b'INTJ', b'X', b'<START>', b'<STOP>']\n",
      "2022-01-20 12:26:41,069 https://flair.informatik.hu-berlin.de/resources/embeddings/token/id-crawl-fasttext-300d-1M.vectors.npy not found in cache, downloading to C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmpu18w_j_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 1199998928/1199998928 [48:56<00:00, 408629.67B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 13:15:38,414 copying C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmpu18w_j_9 to cache at C:\\Users\\ASUS\\.flair\\embeddings\\id-crawl-fasttext-300d-1M.vectors.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 13:15:39,965 removing temp file C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmpu18w_j_9\n",
      "2022-01-20 13:15:40,804 https://flair.informatik.hu-berlin.de/resources/embeddings/token/id-crawl-fasttext-300d-1M not found in cache, downloading to C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmpxs4vfp51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 39636845/39636845 [02:01<00:00, 326380.92B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 13:17:42,935 copying C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmpxs4vfp51 to cache at C:\\Users\\ASUS\\.flair\\embeddings\\id-crawl-fasttext-300d-1M\n",
      "2022-01-20 13:17:43,002 removing temp file C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmpxs4vfp51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "D:\\Coding\\Software\\Anaconda\\lib\\site-packages\\smart_open\\smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 13:17:47,845 https://flair.informatik.hu-berlin.de/resources/embeddings/token/id-wiki-fasttext-300d-1M.vectors.npy not found in cache, downloading to C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmp17fjfka_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 360822128/360822128 [11:24<00:00, 526833.85B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 13:29:13,454 copying C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmp17fjfka_ to cache at C:\\Users\\ASUS\\.flair\\embeddings\\id-wiki-fasttext-300d-1M.vectors.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 13:29:13,968 removing temp file C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmp17fjfka_\n",
      "2022-01-20 13:29:15,254 https://flair.informatik.hu-berlin.de/resources/embeddings/token/id-wiki-fasttext-300d-1M not found in cache, downloading to C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmplo798ddc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 11638719/11638719 [00:09<00:00, 1269141.43B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 13:29:25,085 copying C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmplo798ddc to cache at C:\\Users\\ASUS\\.flair\\embeddings\\id-wiki-fasttext-300d-1M\n",
      "2022-01-20 13:29:25,119 removing temp file C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmplo798ddc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 13:29:45,234 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:29:45,235 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'id-crawl'\n",
      "      (embedding): Embedding(1000000, 300)\n",
      "    )\n",
      "    (list_embedding_1): WordEmbeddings(\n",
      "      'id'\n",
      "      (embedding): Embedding(300686, 300)\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=600, out_features=600, bias=True)\n",
      "  (rnn): LSTM(600, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2022-01-20 13:29:45,236 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:29:45,237 Corpus: \"Corpus: 4482 train + 559 dev + 557 test sentences\"\n",
      "2022-01-20 13:29:45,238 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:29:45,239 Parameters:\n",
      "2022-01-20 13:29:45,240  - learning_rate: \"0.1\"\n",
      "2022-01-20 13:29:45,241  - mini_batch_size: \"32\"\n",
      "2022-01-20 13:29:45,241  - patience: \"3\"\n",
      "2022-01-20 13:29:45,243  - anneal_factor: \"0.5\"\n",
      "2022-01-20 13:29:45,244  - max_epochs: \"10\"\n",
      "2022-01-20 13:29:45,245  - shuffle: \"True\"\n",
      "2022-01-20 13:29:45,246  - train_with_dev: \"False\"\n",
      "2022-01-20 13:29:45,247  - batch_growth_annealing: \"False\"\n",
      "2022-01-20 13:29:45,249 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:29:45,251 Model training base path: \"resources\\taggers\\example-universal-pos\"\n",
      "2022-01-20 13:29:45,252 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:29:45,253 Device: cuda:0\n",
      "2022-01-20 13:29:45,254 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:29:45,255 Embeddings storage mode: cpu\n",
      "2022-01-20 13:29:45,258 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:29:53,093 epoch 1 - iter 14/141 - loss 2.67529325 - samples/sec: 58.16 - lr: 0.100000\n",
      "2022-01-20 13:29:57,722 epoch 1 - iter 28/141 - loss 2.36246604 - samples/sec: 96.83 - lr: 0.100000\n",
      "2022-01-20 13:30:02,051 epoch 1 - iter 42/141 - loss 2.13582575 - samples/sec: 103.51 - lr: 0.100000\n",
      "2022-01-20 13:30:06,714 epoch 1 - iter 56/141 - loss 1.96247577 - samples/sec: 96.09 - lr: 0.100000\n",
      "2022-01-20 13:30:11,987 epoch 1 - iter 70/141 - loss 1.82616474 - samples/sec: 84.98 - lr: 0.100000\n",
      "2022-01-20 13:30:16,727 epoch 1 - iter 84/141 - loss 1.71868578 - samples/sec: 94.57 - lr: 0.100000\n",
      "2022-01-20 13:30:21,828 epoch 1 - iter 98/141 - loss 1.62018908 - samples/sec: 87.89 - lr: 0.100000\n",
      "2022-01-20 13:30:26,677 epoch 1 - iter 112/141 - loss 1.53976455 - samples/sec: 92.40 - lr: 0.100000\n",
      "2022-01-20 13:30:31,725 epoch 1 - iter 126/141 - loss 1.46926094 - samples/sec: 88.83 - lr: 0.100000\n",
      "2022-01-20 13:30:36,304 epoch 1 - iter 140/141 - loss 1.40890261 - samples/sec: 97.85 - lr: 0.100000\n",
      "2022-01-20 13:30:36,363 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:30:36,364 EPOCH 1 done: loss 1.4088 - lr 0.1000000\n",
      "2022-01-20 13:30:46,088 DEV : loss 0.6664806604385376 - f1-score (micro avg)  0.7842\n",
      "2022-01-20 13:30:46,127 BAD EPOCHS (no improvement): 0\n",
      "2022-01-20 13:30:46,129 saving best model\n",
      "2022-01-20 13:31:43,427 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:31:47,533 epoch 2 - iter 14/141 - loss 0.83366498 - samples/sec: 111.08 - lr: 0.100000\n",
      "2022-01-20 13:31:50,690 epoch 2 - iter 28/141 - loss 0.79635799 - samples/sec: 142.02 - lr: 0.100000\n",
      "2022-01-20 13:31:54,382 epoch 2 - iter 42/141 - loss 0.78014223 - samples/sec: 121.42 - lr: 0.100000\n",
      "2022-01-20 13:31:58,333 epoch 2 - iter 56/141 - loss 0.75547849 - samples/sec: 113.42 - lr: 0.100000\n",
      "2022-01-20 13:32:02,480 epoch 2 - iter 70/141 - loss 0.73974531 - samples/sec: 108.06 - lr: 0.100000\n",
      "2022-01-20 13:32:06,320 epoch 2 - iter 84/141 - loss 0.72434943 - samples/sec: 116.81 - lr: 0.100000\n",
      "2022-01-20 13:32:09,918 epoch 2 - iter 98/141 - loss 0.70997772 - samples/sec: 124.54 - lr: 0.100000\n",
      "2022-01-20 13:32:13,413 epoch 2 - iter 112/141 - loss 0.69686140 - samples/sec: 128.29 - lr: 0.100000\n",
      "2022-01-20 13:32:16,963 epoch 2 - iter 126/141 - loss 0.68196102 - samples/sec: 126.23 - lr: 0.100000\n",
      "2022-01-20 13:32:20,579 epoch 2 - iter 140/141 - loss 0.67129289 - samples/sec: 123.92 - lr: 0.100000\n",
      "2022-01-20 13:32:20,614 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:32:20,615 EPOCH 2 done: loss 0.6712 - lr 0.1000000\n",
      "2022-01-20 13:32:28,832 DEV : loss 0.38958901166915894 - f1-score (micro avg)  0.8677\n",
      "2022-01-20 13:32:28,881 BAD EPOCHS (no improvement): 0\n",
      "2022-01-20 13:32:28,883 saving best model\n",
      "2022-01-20 13:33:00,159 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:33:03,805 epoch 3 - iter 14/141 - loss 0.56083737 - samples/sec: 122.93 - lr: 0.100000\n",
      "2022-01-20 13:33:07,669 epoch 3 - iter 28/141 - loss 0.54916561 - samples/sec: 116.05 - lr: 0.100000\n",
      "2022-01-20 13:33:11,016 epoch 3 - iter 42/141 - loss 0.53975349 - samples/sec: 133.89 - lr: 0.100000\n",
      "2022-01-20 13:33:14,556 epoch 3 - iter 56/141 - loss 0.53833984 - samples/sec: 126.60 - lr: 0.100000\n",
      "2022-01-20 13:33:18,026 epoch 3 - iter 70/141 - loss 0.53726519 - samples/sec: 129.13 - lr: 0.100000\n",
      "2022-01-20 13:33:21,596 epoch 3 - iter 84/141 - loss 0.53129336 - samples/sec: 125.55 - lr: 0.100000\n",
      "2022-01-20 13:33:24,749 epoch 3 - iter 98/141 - loss 0.52798447 - samples/sec: 142.17 - lr: 0.100000\n",
      "2022-01-20 13:33:28,297 epoch 3 - iter 112/141 - loss 0.52290487 - samples/sec: 126.35 - lr: 0.100000\n",
      "2022-01-20 13:33:31,695 epoch 3 - iter 126/141 - loss 0.52251438 - samples/sec: 131.88 - lr: 0.100000\n",
      "2022-01-20 13:33:34,998 epoch 3 - iter 140/141 - loss 0.52138151 - samples/sec: 135.71 - lr: 0.100000\n",
      "2022-01-20 13:33:35,071 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:33:35,072 EPOCH 3 done: loss 0.5213 - lr 0.1000000\n",
      "2022-01-20 13:33:42,660 DEV : loss 0.3002781271934509 - f1-score (micro avg)  0.9032\n",
      "2022-01-20 13:33:42,700 BAD EPOCHS (no improvement): 0\n",
      "2022-01-20 13:33:42,702 saving best model\n",
      "2022-01-20 13:34:03,879 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:34:07,169 epoch 4 - iter 14/141 - loss 0.49873408 - samples/sec: 136.18 - lr: 0.100000\n",
      "2022-01-20 13:34:10,871 epoch 4 - iter 28/141 - loss 0.48802354 - samples/sec: 121.09 - lr: 0.100000\n",
      "2022-01-20 13:34:14,311 epoch 4 - iter 42/141 - loss 0.49006170 - samples/sec: 130.26 - lr: 0.100000\n",
      "2022-01-20 13:34:17,623 epoch 4 - iter 56/141 - loss 0.48520747 - samples/sec: 135.37 - lr: 0.100000\n",
      "2022-01-20 13:34:20,623 epoch 4 - iter 70/141 - loss 0.48345431 - samples/sec: 149.38 - lr: 0.100000\n",
      "2022-01-20 13:34:24,120 epoch 4 - iter 84/141 - loss 0.47930775 - samples/sec: 128.21 - lr: 0.100000\n",
      "2022-01-20 13:34:27,644 epoch 4 - iter 98/141 - loss 0.47686654 - samples/sec: 127.21 - lr: 0.100000\n",
      "2022-01-20 13:34:31,116 epoch 4 - iter 112/141 - loss 0.47744451 - samples/sec: 129.06 - lr: 0.100000\n",
      "2022-01-20 13:34:34,471 epoch 4 - iter 126/141 - loss 0.47499594 - samples/sec: 133.59 - lr: 0.100000\n",
      "2022-01-20 13:34:38,114 epoch 4 - iter 140/141 - loss 0.47320099 - samples/sec: 123.00 - lr: 0.100000\n",
      "2022-01-20 13:34:38,173 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:34:38,175 EPOCH 4 done: loss 0.4732 - lr 0.1000000\n",
      "2022-01-20 13:34:45,925 DEV : loss 0.30502456426620483 - f1-score (micro avg)  0.8996\n",
      "2022-01-20 13:34:45,964 BAD EPOCHS (no improvement): 1\n",
      "2022-01-20 13:34:45,965 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:34:49,942 epoch 5 - iter 14/141 - loss 0.43791824 - samples/sec: 112.73 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 13:34:53,439 epoch 5 - iter 28/141 - loss 0.44649993 - samples/sec: 128.23 - lr: 0.100000\n",
      "2022-01-20 13:34:57,418 epoch 5 - iter 42/141 - loss 0.45222314 - samples/sec: 112.63 - lr: 0.100000\n",
      "2022-01-20 13:35:01,071 epoch 5 - iter 56/141 - loss 0.45245541 - samples/sec: 122.70 - lr: 0.100000\n",
      "2022-01-20 13:35:04,910 epoch 5 - iter 70/141 - loss 0.45201365 - samples/sec: 116.75 - lr: 0.100000\n",
      "2022-01-20 13:35:08,392 epoch 5 - iter 84/141 - loss 0.45146622 - samples/sec: 128.70 - lr: 0.100000\n",
      "2022-01-20 13:35:11,675 epoch 5 - iter 98/141 - loss 0.44889929 - samples/sec: 136.57 - lr: 0.100000\n",
      "2022-01-20 13:35:15,311 epoch 5 - iter 112/141 - loss 0.44738376 - samples/sec: 123.28 - lr: 0.100000\n",
      "2022-01-20 13:35:19,031 epoch 5 - iter 126/141 - loss 0.44397618 - samples/sec: 120.54 - lr: 0.100000\n",
      "2022-01-20 13:35:22,244 epoch 5 - iter 140/141 - loss 0.44462992 - samples/sec: 139.49 - lr: 0.100000\n",
      "2022-01-20 13:35:22,363 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:35:22,364 EPOCH 5 done: loss 0.4446 - lr 0.1000000\n",
      "2022-01-20 13:35:29,933 DEV : loss 0.31617650389671326 - f1-score (micro avg)  0.893\n",
      "2022-01-20 13:35:29,977 BAD EPOCHS (no improvement): 2\n",
      "2022-01-20 13:35:29,978 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:35:33,309 epoch 6 - iter 14/141 - loss 0.42231497 - samples/sec: 134.62 - lr: 0.100000\n",
      "2022-01-20 13:35:36,623 epoch 6 - iter 28/141 - loss 0.42154895 - samples/sec: 135.20 - lr: 0.100000\n",
      "2022-01-20 13:35:40,287 epoch 6 - iter 42/141 - loss 0.42510310 - samples/sec: 122.33 - lr: 0.100000\n",
      "2022-01-20 13:35:43,646 epoch 6 - iter 56/141 - loss 0.42579118 - samples/sec: 133.41 - lr: 0.100000\n",
      "2022-01-20 13:35:47,187 epoch 6 - iter 70/141 - loss 0.42801610 - samples/sec: 126.56 - lr: 0.100000\n",
      "2022-01-20 13:35:50,537 epoch 6 - iter 84/141 - loss 0.42455720 - samples/sec: 133.78 - lr: 0.100000\n",
      "2022-01-20 13:35:54,227 epoch 6 - iter 98/141 - loss 0.42722335 - samples/sec: 121.47 - lr: 0.100000\n",
      "2022-01-20 13:35:57,854 epoch 6 - iter 112/141 - loss 0.42675841 - samples/sec: 123.56 - lr: 0.100000\n",
      "2022-01-20 13:36:01,307 epoch 6 - iter 126/141 - loss 0.42431806 - samples/sec: 129.79 - lr: 0.100000\n",
      "2022-01-20 13:36:04,326 epoch 6 - iter 140/141 - loss 0.42307162 - samples/sec: 148.46 - lr: 0.100000\n",
      "2022-01-20 13:36:04,437 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:36:04,437 EPOCH 6 done: loss 0.4231 - lr 0.1000000\n",
      "2022-01-20 13:36:12,321 DEV : loss 0.2578037977218628 - f1-score (micro avg)  0.9153\n",
      "2022-01-20 13:36:12,357 BAD EPOCHS (no improvement): 0\n",
      "2022-01-20 13:36:12,359 saving best model\n",
      "2022-01-20 13:36:29,434 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:36:32,710 epoch 7 - iter 14/141 - loss 0.38804798 - samples/sec: 136.91 - lr: 0.100000\n",
      "2022-01-20 13:36:36,104 epoch 7 - iter 28/141 - loss 0.40121922 - samples/sec: 132.06 - lr: 0.100000\n",
      "2022-01-20 13:36:39,783 epoch 7 - iter 42/141 - loss 0.40583869 - samples/sec: 121.82 - lr: 0.100000\n",
      "2022-01-20 13:36:43,254 epoch 7 - iter 56/141 - loss 0.41352409 - samples/sec: 129.12 - lr: 0.100000\n",
      "2022-01-20 13:36:46,439 epoch 7 - iter 70/141 - loss 0.41421385 - samples/sec: 140.80 - lr: 0.100000\n",
      "2022-01-20 13:36:50,237 epoch 7 - iter 84/141 - loss 0.40829759 - samples/sec: 117.97 - lr: 0.100000\n",
      "2022-01-20 13:36:53,867 epoch 7 - iter 98/141 - loss 0.40709989 - samples/sec: 123.46 - lr: 0.100000\n",
      "2022-01-20 13:36:57,069 epoch 7 - iter 112/141 - loss 0.40516520 - samples/sec: 139.99 - lr: 0.100000\n",
      "2022-01-20 13:37:00,396 epoch 7 - iter 126/141 - loss 0.40798931 - samples/sec: 134.82 - lr: 0.100000\n",
      "2022-01-20 13:37:03,976 epoch 7 - iter 140/141 - loss 0.40676754 - samples/sec: 125.15 - lr: 0.100000\n",
      "2022-01-20 13:37:04,107 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:37:04,108 EPOCH 7 done: loss 0.4070 - lr 0.1000000\n",
      "2022-01-20 13:37:11,689 DEV : loss 0.24914167821407318 - f1-score (micro avg)  0.9182\n",
      "2022-01-20 13:37:11,735 BAD EPOCHS (no improvement): 0\n",
      "2022-01-20 13:37:11,737 saving best model\n",
      "2022-01-20 13:37:24,448 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:37:27,830 epoch 8 - iter 14/141 - loss 0.37774801 - samples/sec: 132.59 - lr: 0.100000\n",
      "2022-01-20 13:37:31,088 epoch 8 - iter 28/141 - loss 0.38024391 - samples/sec: 137.57 - lr: 0.100000\n",
      "2022-01-20 13:37:34,678 epoch 8 - iter 42/141 - loss 0.38333736 - samples/sec: 124.79 - lr: 0.100000\n",
      "2022-01-20 13:37:38,092 epoch 8 - iter 56/141 - loss 0.38923373 - samples/sec: 131.30 - lr: 0.100000\n",
      "2022-01-20 13:37:41,635 epoch 8 - iter 70/141 - loss 0.39299723 - samples/sec: 126.47 - lr: 0.100000\n",
      "2022-01-20 13:37:44,952 epoch 8 - iter 84/141 - loss 0.39457079 - samples/sec: 135.12 - lr: 0.100000\n",
      "2022-01-20 13:37:48,195 epoch 8 - iter 98/141 - loss 0.39505911 - samples/sec: 138.23 - lr: 0.100000\n",
      "2022-01-20 13:37:51,916 epoch 8 - iter 112/141 - loss 0.39475554 - samples/sec: 120.44 - lr: 0.100000\n",
      "2022-01-20 13:37:55,782 epoch 8 - iter 126/141 - loss 0.39595726 - samples/sec: 115.93 - lr: 0.100000\n",
      "2022-01-20 13:37:59,142 epoch 8 - iter 140/141 - loss 0.39668537 - samples/sec: 133.41 - lr: 0.100000\n",
      "2022-01-20 13:37:59,206 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:37:59,207 EPOCH 8 done: loss 0.3966 - lr 0.1000000\n",
      "2022-01-20 13:38:07,275 DEV : loss 0.23914691805839539 - f1-score (micro avg)  0.9186\n",
      "2022-01-20 13:38:07,318 BAD EPOCHS (no improvement): 0\n",
      "2022-01-20 13:38:07,327 saving best model\n",
      "2022-01-20 13:38:18,718 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:38:22,277 epoch 9 - iter 14/141 - loss 0.38763804 - samples/sec: 125.92 - lr: 0.100000\n",
      "2022-01-20 13:38:25,906 epoch 9 - iter 28/141 - loss 0.38312305 - samples/sec: 123.50 - lr: 0.100000\n",
      "2022-01-20 13:38:29,448 epoch 9 - iter 42/141 - loss 0.38598652 - samples/sec: 126.57 - lr: 0.100000\n",
      "2022-01-20 13:38:32,699 epoch 9 - iter 56/141 - loss 0.38571820 - samples/sec: 137.87 - lr: 0.100000\n",
      "2022-01-20 13:38:36,595 epoch 9 - iter 70/141 - loss 0.38155568 - samples/sec: 115.06 - lr: 0.100000\n",
      "2022-01-20 13:38:39,843 epoch 9 - iter 84/141 - loss 0.38461005 - samples/sec: 137.95 - lr: 0.100000\n",
      "2022-01-20 13:38:43,297 epoch 9 - iter 98/141 - loss 0.38588357 - samples/sec: 129.74 - lr: 0.100000\n",
      "2022-01-20 13:38:47,127 epoch 9 - iter 112/141 - loss 0.38586501 - samples/sec: 116.98 - lr: 0.100000\n",
      "2022-01-20 13:38:50,737 epoch 9 - iter 126/141 - loss 0.38555388 - samples/sec: 124.16 - lr: 0.100000\n",
      "2022-01-20 13:38:54,179 epoch 9 - iter 140/141 - loss 0.38574542 - samples/sec: 130.27 - lr: 0.100000\n",
      "2022-01-20 13:38:54,244 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:38:54,245 EPOCH 9 done: loss 0.3857 - lr 0.1000000\n",
      "2022-01-20 13:39:02,087 DEV : loss 0.25023341178894043 - f1-score (micro avg)  0.9173\n",
      "2022-01-20 13:39:02,126 BAD EPOCHS (no improvement): 1\n",
      "2022-01-20 13:39:02,128 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:39:05,312 epoch 10 - iter 14/141 - loss 0.38071896 - samples/sec: 140.83 - lr: 0.100000\n",
      "2022-01-20 13:39:08,769 epoch 10 - iter 28/141 - loss 0.37000029 - samples/sec: 129.65 - lr: 0.100000\n",
      "2022-01-20 13:39:12,399 epoch 10 - iter 42/141 - loss 0.37623617 - samples/sec: 123.44 - lr: 0.100000\n",
      "2022-01-20 13:39:15,835 epoch 10 - iter 56/141 - loss 0.37735155 - samples/sec: 130.46 - lr: 0.100000\n",
      "2022-01-20 13:39:19,434 epoch 10 - iter 70/141 - loss 0.37727372 - samples/sec: 124.56 - lr: 0.100000\n",
      "2022-01-20 13:39:22,752 epoch 10 - iter 84/141 - loss 0.37818240 - samples/sec: 135.00 - lr: 0.100000\n",
      "2022-01-20 13:39:26,174 epoch 10 - iter 98/141 - loss 0.37514755 - samples/sec: 130.99 - lr: 0.100000\n",
      "2022-01-20 13:39:30,395 epoch 10 - iter 112/141 - loss 0.37713686 - samples/sec: 106.16 - lr: 0.100000\n",
      "2022-01-20 13:39:33,889 epoch 10 - iter 126/141 - loss 0.37732732 - samples/sec: 128.25 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 13:39:37,890 epoch 10 - iter 140/141 - loss 0.37738283 - samples/sec: 111.99 - lr: 0.100000\n",
      "2022-01-20 13:39:38,004 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-20 13:39:38,006 EPOCH 10 done: loss 0.3773 - lr 0.1000000\n",
      "2022-01-20 13:39:45,795 DEV : loss 0.23624204099178314 - f1-score (micro avg)  0.9223\n",
      "2022-01-20 13:39:45,839 BAD EPOCHS (no improvement): 0\n",
      "2022-01-20 13:39:45,841 saving best model\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\caffe2\\serialize\\inline_container.cc:274] . unexpected pos 382584000 vs 382583920",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mD:\\Coding\\Software\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m                 \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Coding\\Software\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    486\u001b[0m             \u001b[0mnum_bytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m             \u001b[0mzip_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f0bc038bc053>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m               \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m               \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m               max_epochs=10)\n\u001b[0m",
      "\u001b[1;32mD:\\Coding\\Software\\Anaconda\\lib\\site-packages\\flair\\trainers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, base_path, learning_rate, mini_batch_size, mini_batch_chunk_size, max_epochs, train_with_dev, train_with_test, monitor_train, monitor_test, main_evaluation_metric, scheduler, anneal_factor, patience, min_learning_rate, initial_extra_patience, optimizer, cycle_momentum, warmup_fraction, embeddings_storage_mode, checkpoint, save_final_model, anneal_with_restarts, anneal_with_prestarts, anneal_against_dev_loss, batch_growth_annealing, shuffle, param_selection_mode, write_weights, num_workers, sampler, use_amp, amp_opt_level, eval_on_train_fraction, eval_on_train_shuffle, save_model_each_k_epochs, tensorboard_comment, use_swa, use_final_model_for_eval, gold_label_dictionary_for_eval, create_file_logs, create_loss_file, epoch, use_tensorboard, tensorboard_log_dir, metrics_for_tensorboard, optimizer_state_dict, scheduler_state_dict, save_optimizer_state, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m             \u001b[1;31m# if we do not use dev data for model selection, save final model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msave_final_model\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mparam_selection_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_path\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m\"final-model.pt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_optimizer_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Coding\\Software\\Anaconda\\lib\\site-packages\\flair\\nn\\model.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, model_file, checkpoint)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;31m# save model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;31m# restore optimizer and scheduler to model card if set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Coding\\Software\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Coding\\Software\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\caffe2\\serialize\\inline_container.cc:274] . unexpected pos 382584000 vs 382583920"
     ]
    }
   ],
   "source": [
    "# 1. get the corpus\n",
    "corpus = NLPTaskDataFetcher.load_corpus(NLPTask.UD_INDONESIAN)\n",
    "\n",
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'upos'\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary.idx2item)\n",
    "\n",
    "# 4. initialize embeddings\n",
    "embedding_types: List[TokenEmbeddings] = [\n",
    "    WordEmbeddings('id-crawl'),\n",
    "    WordEmbeddings('id'),\n",
    "    #WordEmbeddings('glove'),\n",
    "    #BertEmbeddings('bert-base-multilingual-cased')\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "# 5. initialize sequence tagger\n",
    "from flair.models import SequenceTagger\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)\n",
    "\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "# 7. start training\n",
    "trainer.train('resources/taggers/example-universal-pos',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "LqvmmuVf7cPs",
    "outputId": "154b4971-f37b-4973-e420-8395bc18c049"
   },
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "\n",
    "sentence = Sentence('saya dan dia kemarin pergi ke pasar bersama untuk membeli jeruk')\n",
    "tag_pos = SequenceTagger.load('resources/taggers/example-universal-pos/best-model.pt')\n",
    "tag_pos.predict(sentence)\n",
    "print(sentence.to_tagged_string())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Flair 2.0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
